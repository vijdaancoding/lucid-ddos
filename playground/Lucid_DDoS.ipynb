{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Running Python Scripts**"
      ],
      "metadata": {
        "id": "Ygfwwjjzsh1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkEvHR8SzNIX",
        "outputId": "b63985b8-3ad5-4d3c-f013-346ee037615a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.1\n",
            "Uninstalling tensorflow-2.17.1:\n",
            "  Successfully uninstalled tensorflow-2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iE4fHauzzYvw",
        "outputId": "caa752a7-02c3-4de0-d898-208f6962769a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.10.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.68.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.12.1)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.2)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.45.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
            "Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.71.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.15.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.27.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.13.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.24.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.7 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "google",
                  "google_auth_oauthlib",
                  "keras",
                  "tensorflow"
                ]
              },
              "id": "f6c9e090e4e54cbaa801cc50a7ed176d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn h5py pyshark protobuf==3.19.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oCreSHF0Hy4",
        "outputId": "35e416ca-41c9-410c-936c-e92206f31909"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\n",
            "Collecting pyshark\n",
            "  Downloading pyshark-0.6-py3-none-any.whl.metadata (806 bytes)\n",
            "Requirement already satisfied: protobuf==3.19.6 in /usr/local/lib/python3.10/dist-packages (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pyshark) (5.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyshark) (2.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyshark) (24.2)\n",
            "Collecting appdirs (from pyshark)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Downloading pyshark-0.6-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs, pyshark\n",
            "Successfully installed appdirs-1.4.4 pyshark-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/'Lucid DDoS'/lucid_cnn.py --train /content/drive/MyDrive/'Lucid DDoS'/sample-dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0vaXa71whvN",
        "outputId": "b9bbee6f-3971-4cac-bcee-704ff2f0759a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0486 - accuracy: 0.9888 - val_loss: 0.1101 - val_accuracy: 0.9681\n",
            "Epoch 336/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9893\n",
            "Epoch 336: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0487 - accuracy: 0.9885 - val_loss: 0.1099 - val_accuracy: 0.9705\n",
            "Epoch 337/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0546 - accuracy: 0.9873\n",
            "Epoch 337: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0504 - accuracy: 0.9888 - val_loss: 0.1098 - val_accuracy: 0.9705\n",
            "Epoch 338/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9897\n",
            "Epoch 338: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0471 - accuracy: 0.9888 - val_loss: 0.1098 - val_accuracy: 0.9681\n",
            "Epoch 339/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9878\n",
            "Epoch 339: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0481 - accuracy: 0.9885 - val_loss: 0.1097 - val_accuracy: 0.9705\n",
            "Epoch 340/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0548 - accuracy: 0.9868\n",
            "Epoch 340: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0498 - accuracy: 0.9894 - val_loss: 0.1091 - val_accuracy: 0.9681\n",
            "Epoch 341/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0443 - accuracy: 0.9883\n",
            "Epoch 341: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0477 - accuracy: 0.9883 - val_loss: 0.1085 - val_accuracy: 0.9681\n",
            "Epoch 342/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9893\n",
            "Epoch 342: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0483 - accuracy: 0.9888 - val_loss: 0.1080 - val_accuracy: 0.9681\n",
            "Epoch 343/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0450 - accuracy: 0.9888\n",
            "Epoch 343: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0452 - accuracy: 0.9894 - val_loss: 0.1075 - val_accuracy: 0.9681\n",
            "Epoch 344/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0547 - accuracy: 0.9883\n",
            "Epoch 344: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0518 - accuracy: 0.9880 - val_loss: 0.1074 - val_accuracy: 0.9681\n",
            "Epoch 345/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0605 - accuracy: 0.9888\n",
            "Epoch 345: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0523 - accuracy: 0.9891 - val_loss: 0.1072 - val_accuracy: 0.9681\n",
            "Epoch 346/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0465 - accuracy: 0.9893\n",
            "Epoch 346: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0459 - accuracy: 0.9891 - val_loss: 0.1071 - val_accuracy: 0.9681\n",
            "Epoch 347/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0519 - accuracy: 0.9878\n",
            "Epoch 347: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0474 - accuracy: 0.9896 - val_loss: 0.1070 - val_accuracy: 0.9681\n",
            "Epoch 348/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0420 - accuracy: 0.9922\n",
            "Epoch 348: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0453 - accuracy: 0.9904 - val_loss: 0.1071 - val_accuracy: 0.9681\n",
            "Epoch 349/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0496 - accuracy: 0.9878\n",
            "Epoch 349: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0463 - accuracy: 0.9891 - val_loss: 0.1067 - val_accuracy: 0.9681\n",
            "Epoch 350/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0488 - accuracy: 0.9883\n",
            "Epoch 350: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0502 - accuracy: 0.9888 - val_loss: 0.1065 - val_accuracy: 0.9681\n",
            "Epoch 351/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9888\n",
            "Epoch 351: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0500 - accuracy: 0.9891 - val_loss: 0.1066 - val_accuracy: 0.9681\n",
            "Epoch 352/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9888\n",
            "Epoch 352: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0454 - accuracy: 0.9894 - val_loss: 0.1064 - val_accuracy: 0.9681\n",
            "Epoch 353/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0463 - accuracy: 0.9907\n",
            "Epoch 353: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0467 - accuracy: 0.9902 - val_loss: 0.1061 - val_accuracy: 0.9681\n",
            "Epoch 354/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0564 - accuracy: 0.9873\n",
            "Epoch 354: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0481 - accuracy: 0.9896 - val_loss: 0.1060 - val_accuracy: 0.9681\n",
            "Epoch 355/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0467 - accuracy: 0.9893\n",
            "Epoch 355: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0465 - accuracy: 0.9894 - val_loss: 0.1066 - val_accuracy: 0.9681\n",
            "Epoch 356/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0665 - accuracy: 0.9863\n",
            "Epoch 356: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0545 - accuracy: 0.9883 - val_loss: 0.1060 - val_accuracy: 0.9681\n",
            "Epoch 357/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0427 - accuracy: 0.9907\n",
            "Epoch 357: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0482 - accuracy: 0.9899 - val_loss: 0.1062 - val_accuracy: 0.9705\n",
            "Epoch 358/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0429 - accuracy: 0.9917\n",
            "Epoch 358: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0445 - accuracy: 0.9891 - val_loss: 0.1062 - val_accuracy: 0.9681\n",
            "Epoch 359/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9912\n",
            "Epoch 359: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0441 - accuracy: 0.9902 - val_loss: 0.1065 - val_accuracy: 0.9681\n",
            "Epoch 360/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0366 - accuracy: 0.9907\n",
            "Epoch 360: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0462 - accuracy: 0.9891 - val_loss: 0.1058 - val_accuracy: 0.9681\n",
            "Epoch 361/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0454 - accuracy: 0.9897\n",
            "Epoch 361: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0456 - accuracy: 0.9896 - val_loss: 0.1059 - val_accuracy: 0.9705\n",
            "Epoch 362/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0557 - accuracy: 0.9878\n",
            "Epoch 362: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0451 - accuracy: 0.9899 - val_loss: 0.1058 - val_accuracy: 0.9681\n",
            "Epoch 363/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0460 - accuracy: 0.9902\n",
            "Epoch 363: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0440 - accuracy: 0.9904 - val_loss: 0.1065 - val_accuracy: 0.9681\n",
            "Epoch 364/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0344 - accuracy: 0.9922\n",
            "Epoch 364: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0464 - accuracy: 0.9883 - val_loss: 0.1057 - val_accuracy: 0.9681\n",
            "Epoch 365/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0474 - accuracy: 0.9888\n",
            "Epoch 365: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0431 - accuracy: 0.9904 - val_loss: 0.1058 - val_accuracy: 0.9705\n",
            "Epoch 366/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0532 - accuracy: 0.9893\n",
            "Epoch 366: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0467 - accuracy: 0.9902 - val_loss: 0.1055 - val_accuracy: 0.9681\n",
            "Epoch 367/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0379 - accuracy: 0.9917\n",
            "Epoch 367: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0452 - accuracy: 0.9899 - val_loss: 0.1056 - val_accuracy: 0.9681\n",
            "Epoch 368/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0367 - accuracy: 0.9922\n",
            "Epoch 368: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0474 - accuracy: 0.9902 - val_loss: 0.1052 - val_accuracy: 0.9681\n",
            "Epoch 369/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9893\n",
            "Epoch 369: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0444 - accuracy: 0.9902 - val_loss: 0.1050 - val_accuracy: 0.9681\n",
            "Epoch 370/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0437 - accuracy: 0.9912\n",
            "Epoch 370: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0474 - accuracy: 0.9891 - val_loss: 0.1048 - val_accuracy: 0.9681\n",
            "Epoch 371/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0397 - accuracy: 0.9912\n",
            "Epoch 371: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0424 - accuracy: 0.9904 - val_loss: 0.1049 - val_accuracy: 0.9681\n",
            "Epoch 372/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0420 - accuracy: 0.9902\n",
            "Epoch 372: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0445 - accuracy: 0.9899 - val_loss: 0.1049 - val_accuracy: 0.9681\n",
            "Epoch 373/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9927\n",
            "Epoch 373: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0435 - accuracy: 0.9902 - val_loss: 0.1049 - val_accuracy: 0.9681\n",
            "Epoch 374/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0562 - accuracy: 0.9873\n",
            "Epoch 374: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0489 - accuracy: 0.9896 - val_loss: 0.1047 - val_accuracy: 0.9681\n",
            "Epoch 375/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9902\n",
            "Epoch 375: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0469 - accuracy: 0.9899 - val_loss: 0.1043 - val_accuracy: 0.9705\n",
            "Epoch 376/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0521 - accuracy: 0.9888\n",
            "Epoch 376: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0466 - accuracy: 0.9904 - val_loss: 0.1039 - val_accuracy: 0.9681\n",
            "Epoch 377/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0399 - accuracy: 0.9893\n",
            "Epoch 377: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0546 - accuracy: 0.9880 - val_loss: 0.1039 - val_accuracy: 0.9681\n",
            "Epoch 378/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9893\n",
            "Epoch 378: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0459 - accuracy: 0.9902 - val_loss: 0.1041 - val_accuracy: 0.9705\n",
            "Epoch 379/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9912\n",
            "Epoch 379: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0439 - accuracy: 0.9899 - val_loss: 0.1037 - val_accuracy: 0.9705\n",
            "Epoch 380/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0590 - accuracy: 0.9868\n",
            "Epoch 380: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0487 - accuracy: 0.9891 - val_loss: 0.1035 - val_accuracy: 0.9681\n",
            "Epoch 381/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0441 - accuracy: 0.9912\n",
            "Epoch 381: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.1034 - val_accuracy: 0.9681\n",
            "Epoch 382/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0453 - accuracy: 0.9907\n",
            "Epoch 382: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0456 - accuracy: 0.9902 - val_loss: 0.1034 - val_accuracy: 0.9705\n",
            "Epoch 383/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0388 - accuracy: 0.9902\n",
            "Epoch 383: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0433 - accuracy: 0.9899 - val_loss: 0.1034 - val_accuracy: 0.9705\n",
            "Epoch 384/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0347 - accuracy: 0.9922\n",
            "Epoch 384: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0420 - accuracy: 0.9899 - val_loss: 0.1034 - val_accuracy: 0.9681\n",
            "Epoch 385/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9897\n",
            "Epoch 385: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0474 - accuracy: 0.9891 - val_loss: 0.1034 - val_accuracy: 0.9681\n",
            "Epoch 386/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0491 - accuracy: 0.9888\n",
            "Epoch 386: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0425 - accuracy: 0.9896 - val_loss: 0.1032 - val_accuracy: 0.9681\n",
            "Epoch 387/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0431 - accuracy: 0.9897\n",
            "Epoch 387: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0407 - accuracy: 0.9902 - val_loss: 0.1033 - val_accuracy: 0.9681\n",
            "Epoch 388/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0287 - accuracy: 0.9941\n",
            "Epoch 388: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0470 - accuracy: 0.9896 - val_loss: 0.1033 - val_accuracy: 0.9681\n",
            "Epoch 389/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0487 - accuracy: 0.9873\n",
            "Epoch 389: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0434 - accuracy: 0.9896 - val_loss: 0.1031 - val_accuracy: 0.9681\n",
            "Epoch 390/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0566 - accuracy: 0.9873\n",
            "Epoch 390: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0456 - accuracy: 0.9907 - val_loss: 0.1029 - val_accuracy: 0.9681\n",
            "Epoch 391/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0373 - accuracy: 0.9922\n",
            "Epoch 391: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0429 - accuracy: 0.9907 - val_loss: 0.1028 - val_accuracy: 0.9705\n",
            "Epoch 392/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0308 - accuracy: 0.9922\n",
            "Epoch 392: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0415 - accuracy: 0.9896 - val_loss: 0.1026 - val_accuracy: 0.9681\n",
            "Epoch 393/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0511 - accuracy: 0.9883\n",
            "Epoch 393: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0492 - accuracy: 0.9896 - val_loss: 0.1023 - val_accuracy: 0.9681\n",
            "Epoch 394/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0346 - accuracy: 0.9907\n",
            "Epoch 394: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0408 - accuracy: 0.9899 - val_loss: 0.1024 - val_accuracy: 0.9705\n",
            "Epoch 395/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0398 - accuracy: 0.9907\n",
            "Epoch 395: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0427 - accuracy: 0.9902 - val_loss: 0.1023 - val_accuracy: 0.9705\n",
            "Epoch 396/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0464 - accuracy: 0.9883\n",
            "Epoch 396: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0427 - accuracy: 0.9899 - val_loss: 0.1020 - val_accuracy: 0.9681\n",
            "Epoch 397/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0487 - accuracy: 0.9883\n",
            "Epoch 397: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0418 - accuracy: 0.9899 - val_loss: 0.1018 - val_accuracy: 0.9705\n",
            "Epoch 398/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0517 - accuracy: 0.9878\n",
            "Epoch 398: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0454 - accuracy: 0.9896 - val_loss: 0.1015 - val_accuracy: 0.9705\n",
            "Epoch 399/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0467 - accuracy: 0.9893\n",
            "Epoch 399: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0437 - accuracy: 0.9899 - val_loss: 0.1011 - val_accuracy: 0.9705\n",
            "Epoch 400/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0386 - accuracy: 0.9917\n",
            "Epoch 400: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0418 - accuracy: 0.9902 - val_loss: 0.1003 - val_accuracy: 0.9705\n",
            "Epoch 401/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0390 - accuracy: 0.9902\n",
            "Epoch 401: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0419 - accuracy: 0.9899 - val_loss: 0.0995 - val_accuracy: 0.9705\n",
            "Epoch 402/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0419 - accuracy: 0.9897\n",
            "Epoch 402: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0409 - accuracy: 0.9902 - val_loss: 0.0987 - val_accuracy: 0.9705\n",
            "Epoch 403/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9883\n",
            "Epoch 403: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0425 - accuracy: 0.9902 - val_loss: 0.0984 - val_accuracy: 0.9705\n",
            "Epoch 404/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0394 - accuracy: 0.9932\n",
            "Epoch 404: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0432 - accuracy: 0.9902 - val_loss: 0.0972 - val_accuracy: 0.9705\n",
            "Epoch 405/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9888\n",
            "Epoch 405: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0453 - accuracy: 0.9904 - val_loss: 0.0962 - val_accuracy: 0.9705\n",
            "Epoch 406/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0529 - accuracy: 0.9868\n",
            "Epoch 406: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0420 - accuracy: 0.9896 - val_loss: 0.0956 - val_accuracy: 0.9705\n",
            "Epoch 407/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0384 - accuracy: 0.9902\n",
            "Epoch 407: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0419 - accuracy: 0.9899 - val_loss: 0.0956 - val_accuracy: 0.9705\n",
            "Epoch 408/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0331 - accuracy: 0.9922\n",
            "Epoch 408: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0409 - accuracy: 0.9910 - val_loss: 0.0954 - val_accuracy: 0.9705\n",
            "Epoch 409/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0386 - accuracy: 0.9907\n",
            "Epoch 409: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0422 - accuracy: 0.9904 - val_loss: 0.0946 - val_accuracy: 0.9705\n",
            "Epoch 410/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0486 - accuracy: 0.9888\n",
            "Epoch 410: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0427 - accuracy: 0.9891 - val_loss: 0.0944 - val_accuracy: 0.9705\n",
            "Epoch 411/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0336 - accuracy: 0.9932\n",
            "Epoch 411: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0452 - accuracy: 0.9894 - val_loss: 0.0948 - val_accuracy: 0.9705\n",
            "Epoch 412/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0415 - accuracy: 0.9907\n",
            "Epoch 412: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0418 - accuracy: 0.9899 - val_loss: 0.0955 - val_accuracy: 0.9705\n",
            "Epoch 413/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0389 - accuracy: 0.9907\n",
            "Epoch 413: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0411 - accuracy: 0.9904 - val_loss: 0.0952 - val_accuracy: 0.9705\n",
            "Epoch 414/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0463 - accuracy: 0.9893\n",
            "Epoch 414: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0410 - accuracy: 0.9902 - val_loss: 0.0952 - val_accuracy: 0.9705\n",
            "Epoch 415/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0500 - accuracy: 0.9888\n",
            "Epoch 415: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0443 - accuracy: 0.9899 - val_loss: 0.0956 - val_accuracy: 0.9705\n",
            "Epoch 416/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0435 - accuracy: 0.9912\n",
            "Epoch 416: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0397 - accuracy: 0.9907 - val_loss: 0.0961 - val_accuracy: 0.9705\n",
            "Epoch 417/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0313 - accuracy: 0.9922\n",
            "Epoch 417: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0411 - accuracy: 0.9896 - val_loss: 0.0961 - val_accuracy: 0.9705\n",
            "Epoch 418/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0404 - accuracy: 0.9888\n",
            "Epoch 418: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0449 - accuracy: 0.9904 - val_loss: 0.0959 - val_accuracy: 0.9705\n",
            "Epoch 419/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0384 - accuracy: 0.9907\n",
            "Epoch 419: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0414 - accuracy: 0.9907 - val_loss: 0.0959 - val_accuracy: 0.9705\n",
            "Epoch 420/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0463 - accuracy: 0.9883\n",
            "Epoch 420: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0402 - accuracy: 0.9902 - val_loss: 0.0964 - val_accuracy: 0.9705\n",
            "Epoch 420: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9907\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0428 - accuracy: 0.9907\n",
            "Model: \"DOS2019-LUCID\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv0 (Conv2D)              (None, 8, 1, 32)          1088      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 1, 32)          0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8, 1, 32)          0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 32)               0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,121\n",
            "Trainable params: 1,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/2 [==============>...............] - ETA: 1s - loss: 1.0778 - accuracy: 0.4902\n",
            "Epoch 1: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 1s 372ms/step - loss: 1.0375 - accuracy: 0.4889 - val_loss: 0.9076 - val_accuracy: 0.6486\n",
            "Epoch 2/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.9074 - accuracy: 0.5776\n",
            "Epoch 2: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.8791 - accuracy: 0.6683 - val_loss: 0.8023 - val_accuracy: 0.7150\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7974 - accuracy: 0.7471\n",
            "Epoch 3: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.7860 - accuracy: 0.7366 - val_loss: 0.7641 - val_accuracy: 0.5823\n",
            "Epoch 4/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7566 - accuracy: 0.7017\n",
            "Epoch 4: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.7555 - accuracy: 0.7024 - val_loss: 0.7753 - val_accuracy: 0.5749\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7652 - accuracy: 0.6353\n",
            "Epoch 5: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.7658 - accuracy: 0.6729 - val_loss: 0.7730 - val_accuracy: 0.7150\n",
            "Epoch 6/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7615 - accuracy: 0.7363\n",
            "Epoch 6: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.7581 - accuracy: 0.7428 - val_loss: 0.7539 - val_accuracy: 0.7420\n",
            "Epoch 7/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7400 - accuracy: 0.7603\n",
            "Epoch 7: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.7379 - accuracy: 0.7573 - val_loss: 0.7381 - val_accuracy: 0.7174\n",
            "Epoch 8/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7251 - accuracy: 0.7515\n",
            "Epoch 8: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.7208 - accuracy: 0.7434 - val_loss: 0.7289 - val_accuracy: 0.7150\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7109 - accuracy: 0.7368\n",
            "Epoch 9: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.7090 - accuracy: 0.7314 - val_loss: 0.7225 - val_accuracy: 0.7150\n",
            "Epoch 10/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7018 - accuracy: 0.7319\n",
            "Epoch 10: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.7018 - accuracy: 0.7295 - val_loss: 0.7182 - val_accuracy: 0.7150\n",
            "Epoch 11/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6988 - accuracy: 0.7251\n",
            "Epoch 11: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6956 - accuracy: 0.7322 - val_loss: 0.7084 - val_accuracy: 0.7150\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6864 - accuracy: 0.7393\n",
            "Epoch 12: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6859 - accuracy: 0.7379 - val_loss: 0.6993 - val_accuracy: 0.7150\n",
            "Epoch 13/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6801 - accuracy: 0.7422\n",
            "Epoch 13: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.6758 - accuracy: 0.7417 - val_loss: 0.6937 - val_accuracy: 0.7150\n",
            "Epoch 14/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6704 - accuracy: 0.7412\n",
            "Epoch 14: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6687 - accuracy: 0.7336 - val_loss: 0.6886 - val_accuracy: 0.7125\n",
            "Epoch 15/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6618 - accuracy: 0.7354\n",
            "Epoch 15: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.6624 - accuracy: 0.7284 - val_loss: 0.6840 - val_accuracy: 0.7125\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6564 - accuracy: 0.7300\n",
            "Epoch 16: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6562 - accuracy: 0.7278 - val_loss: 0.6776 - val_accuracy: 0.7125\n",
            "Epoch 17/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6466 - accuracy: 0.7324\n",
            "Epoch 17: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6515 - accuracy: 0.7292 - val_loss: 0.6728 - val_accuracy: 0.7125\n",
            "Epoch 18/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6445 - accuracy: 0.7402\n",
            "Epoch 18: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6457 - accuracy: 0.7286 - val_loss: 0.6695 - val_accuracy: 0.7125\n",
            "Epoch 19/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6465 - accuracy: 0.7227\n",
            "Epoch 19: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.6402 - accuracy: 0.7275 - val_loss: 0.6662 - val_accuracy: 0.7125\n",
            "Epoch 20/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6379 - accuracy: 0.7236\n",
            "Epoch 20: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.6369 - accuracy: 0.7273 - val_loss: 0.6623 - val_accuracy: 0.7125\n",
            "Epoch 21/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6319 - accuracy: 0.7310\n",
            "Epoch 21: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6327 - accuracy: 0.7275 - val_loss: 0.6609 - val_accuracy: 0.7125\n",
            "Epoch 22/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6348 - accuracy: 0.7217\n",
            "Epoch 22: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.6302 - accuracy: 0.7273 - val_loss: 0.6576 - val_accuracy: 0.7125\n",
            "Epoch 23/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6277 - accuracy: 0.7241\n",
            "Epoch 23: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6263 - accuracy: 0.7270 - val_loss: 0.6546 - val_accuracy: 0.7125\n",
            "Epoch 24/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6220 - accuracy: 0.7314\n",
            "Epoch 24: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6249 - accuracy: 0.7270 - val_loss: 0.6534 - val_accuracy: 0.7125\n",
            "Epoch 25/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6203 - accuracy: 0.7300\n",
            "Epoch 25: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.6221 - accuracy: 0.7275 - val_loss: 0.6522 - val_accuracy: 0.7125\n",
            "Epoch 26/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6191 - accuracy: 0.7300\n",
            "Epoch 26: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6209 - accuracy: 0.7267 - val_loss: 0.6502 - val_accuracy: 0.7125\n",
            "Epoch 27/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6219 - accuracy: 0.7212\n",
            "Epoch 27: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6192 - accuracy: 0.7273 - val_loss: 0.6486 - val_accuracy: 0.7125\n",
            "Epoch 28/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6169 - accuracy: 0.7275\n",
            "Epoch 28: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.6174 - accuracy: 0.7273 - val_loss: 0.6484 - val_accuracy: 0.7125\n",
            "Epoch 29/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6177 - accuracy: 0.7256\n",
            "Epoch 29: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6166 - accuracy: 0.7273 - val_loss: 0.6471 - val_accuracy: 0.7125\n",
            "Epoch 30/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6107 - accuracy: 0.7349\n",
            "Epoch 30: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6138 - accuracy: 0.7275 - val_loss: 0.6461 - val_accuracy: 0.7125\n",
            "Epoch 31/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6125 - accuracy: 0.7266\n",
            "Epoch 31: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6124 - accuracy: 0.7270 - val_loss: 0.6433 - val_accuracy: 0.7125\n",
            "Epoch 32/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6025 - accuracy: 0.7368\n",
            "Epoch 32: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6106 - accuracy: 0.7284 - val_loss: 0.6413 - val_accuracy: 0.7125\n",
            "Epoch 33/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6155 - accuracy: 0.7266\n",
            "Epoch 33: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6095 - accuracy: 0.7281 - val_loss: 0.6423 - val_accuracy: 0.7125\n",
            "Epoch 34/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6129 - accuracy: 0.7241\n",
            "Epoch 34: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6079 - accuracy: 0.7275 - val_loss: 0.6410 - val_accuracy: 0.7125\n",
            "Epoch 35/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6000 - accuracy: 0.7354\n",
            "Epoch 35: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.6070 - accuracy: 0.7275 - val_loss: 0.6400 - val_accuracy: 0.7125\n",
            "Epoch 36/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6058 - accuracy: 0.7344\n",
            "Epoch 36: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6065 - accuracy: 0.7278 - val_loss: 0.6404 - val_accuracy: 0.7125\n",
            "Epoch 37/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5997 - accuracy: 0.7324\n",
            "Epoch 37: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6052 - accuracy: 0.7278 - val_loss: 0.6379 - val_accuracy: 0.7125\n",
            "Epoch 38/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6051 - accuracy: 0.7388\n",
            "Epoch 38: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6033 - accuracy: 0.7368 - val_loss: 0.6370 - val_accuracy: 0.7125\n",
            "Epoch 39/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5972 - accuracy: 0.7471\n",
            "Epoch 39: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6032 - accuracy: 0.7346 - val_loss: 0.6367 - val_accuracy: 0.7125\n",
            "Epoch 40/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5970 - accuracy: 0.7363\n",
            "Epoch 40: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6006 - accuracy: 0.7278 - val_loss: 0.6358 - val_accuracy: 0.7125\n",
            "Epoch 41/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5985 - accuracy: 0.7300\n",
            "Epoch 41: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5997 - accuracy: 0.7338 - val_loss: 0.6333 - val_accuracy: 0.7125\n",
            "Epoch 42/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6060 - accuracy: 0.7368\n",
            "Epoch 42: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6003 - accuracy: 0.7420 - val_loss: 0.6337 - val_accuracy: 0.7125\n",
            "Epoch 43/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5910 - accuracy: 0.7456\n",
            "Epoch 43: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6004 - accuracy: 0.7406 - val_loss: 0.6352 - val_accuracy: 0.7125\n",
            "Epoch 44/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6054 - accuracy: 0.7202\n",
            "Epoch 44: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5983 - accuracy: 0.7284 - val_loss: 0.6342 - val_accuracy: 0.7125\n",
            "Epoch 45/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5854 - accuracy: 0.7388\n",
            "Epoch 45: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5949 - accuracy: 0.7303 - val_loss: 0.6317 - val_accuracy: 0.7125\n",
            "Epoch 46/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5998 - accuracy: 0.7349\n",
            "Epoch 46: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5948 - accuracy: 0.7376 - val_loss: 0.6293 - val_accuracy: 0.7150\n",
            "Epoch 47/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5851 - accuracy: 0.7529\n",
            "Epoch 47: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.5945 - accuracy: 0.7467 - val_loss: 0.6303 - val_accuracy: 0.7150\n",
            "Epoch 48/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5948 - accuracy: 0.7490\n",
            "Epoch 48: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5937 - accuracy: 0.7431 - val_loss: 0.6310 - val_accuracy: 0.7125\n",
            "Epoch 49/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6017 - accuracy: 0.7285\n",
            "Epoch 49: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5916 - accuracy: 0.7431 - val_loss: 0.6270 - val_accuracy: 0.7396\n",
            "Epoch 50/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5846 - accuracy: 0.7510\n",
            "Epoch 50: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5910 - accuracy: 0.7518 - val_loss: 0.6268 - val_accuracy: 0.7420\n",
            "Epoch 51/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5968 - accuracy: 0.7456\n",
            "Epoch 51: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5896 - accuracy: 0.7453 - val_loss: 0.6297 - val_accuracy: 0.7125\n",
            "Epoch 52/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5874 - accuracy: 0.7471\n",
            "Epoch 52: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5878 - accuracy: 0.7458 - val_loss: 0.6257 - val_accuracy: 0.7420\n",
            "Epoch 53/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5861 - accuracy: 0.7500\n",
            "Epoch 53: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5855 - accuracy: 0.7535 - val_loss: 0.6236 - val_accuracy: 0.7420\n",
            "Epoch 54/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5819 - accuracy: 0.7666\n",
            "Epoch 54: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5854 - accuracy: 0.7603 - val_loss: 0.6257 - val_accuracy: 0.7420\n",
            "Epoch 55/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5742 - accuracy: 0.7695\n",
            "Epoch 55: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5863 - accuracy: 0.7538 - val_loss: 0.6252 - val_accuracy: 0.7420\n",
            "Epoch 56/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5926 - accuracy: 0.7422\n",
            "Epoch 56: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5841 - accuracy: 0.7518 - val_loss: 0.6240 - val_accuracy: 0.7420\n",
            "Epoch 57/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5828 - accuracy: 0.7534\n",
            "Epoch 57: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5832 - accuracy: 0.7559 - val_loss: 0.6219 - val_accuracy: 0.7420\n",
            "Epoch 58/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5707 - accuracy: 0.7720\n",
            "Epoch 58: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5815 - accuracy: 0.7592 - val_loss: 0.6196 - val_accuracy: 0.7445\n",
            "Epoch 59/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5779 - accuracy: 0.7617\n",
            "Epoch 59: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5784 - accuracy: 0.7630 - val_loss: 0.6193 - val_accuracy: 0.7445\n",
            "Epoch 60/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5816 - accuracy: 0.7563\n",
            "Epoch 60: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5790 - accuracy: 0.7603 - val_loss: 0.6219 - val_accuracy: 0.7420\n",
            "Epoch 61/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5814 - accuracy: 0.7573\n",
            "Epoch 61: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5789 - accuracy: 0.7565 - val_loss: 0.6193 - val_accuracy: 0.7420\n",
            "Epoch 62/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5745 - accuracy: 0.7705\n",
            "Epoch 62: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5778 - accuracy: 0.7617 - val_loss: 0.6169 - val_accuracy: 0.7469\n",
            "Epoch 63/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5682 - accuracy: 0.7690\n",
            "Epoch 63: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5774 - accuracy: 0.7595 - val_loss: 0.6195 - val_accuracy: 0.7420\n",
            "Epoch 64/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5816 - accuracy: 0.7583\n",
            "Epoch 64: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5762 - accuracy: 0.7578 - val_loss: 0.6176 - val_accuracy: 0.7445\n",
            "Epoch 65/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5689 - accuracy: 0.7637\n",
            "Epoch 65: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5738 - accuracy: 0.7603 - val_loss: 0.6160 - val_accuracy: 0.7469\n",
            "Epoch 66/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5688 - accuracy: 0.7671\n",
            "Epoch 66: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5733 - accuracy: 0.7614 - val_loss: 0.6165 - val_accuracy: 0.7445\n",
            "Epoch 67/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5800 - accuracy: 0.7471\n",
            "Epoch 67: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5730 - accuracy: 0.7609 - val_loss: 0.6148 - val_accuracy: 0.7469\n",
            "Epoch 68/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5691 - accuracy: 0.7603\n",
            "Epoch 68: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5711 - accuracy: 0.7603 - val_loss: 0.6120 - val_accuracy: 0.7469\n",
            "Epoch 69/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5649 - accuracy: 0.7686\n",
            "Epoch 69: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5713 - accuracy: 0.7636 - val_loss: 0.6135 - val_accuracy: 0.7445\n",
            "Epoch 70/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5748 - accuracy: 0.7544\n",
            "Epoch 70: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5708 - accuracy: 0.7587 - val_loss: 0.6153 - val_accuracy: 0.7445\n",
            "Epoch 71/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5622 - accuracy: 0.7593\n",
            "Epoch 71: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5702 - accuracy: 0.7578 - val_loss: 0.6092 - val_accuracy: 0.7469\n",
            "Epoch 72/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5661 - accuracy: 0.7661\n",
            "Epoch 72: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5677 - accuracy: 0.7644 - val_loss: 0.6103 - val_accuracy: 0.7469\n",
            "Epoch 73/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5665 - accuracy: 0.7603\n",
            "Epoch 73: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5666 - accuracy: 0.7606 - val_loss: 0.6116 - val_accuracy: 0.7469\n",
            "Epoch 74/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5653 - accuracy: 0.7642\n",
            "Epoch 74: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.5672 - accuracy: 0.7617 - val_loss: 0.6096 - val_accuracy: 0.7469\n",
            "Epoch 75/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5678 - accuracy: 0.7607\n",
            "Epoch 75: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5636 - accuracy: 0.7636 - val_loss: 0.6099 - val_accuracy: 0.7469\n",
            "Epoch 76/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5685 - accuracy: 0.7603\n",
            "Epoch 76: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5668 - accuracy: 0.7609 - val_loss: 0.6088 - val_accuracy: 0.7469\n",
            "Epoch 77/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5609 - accuracy: 0.7729\n",
            "Epoch 77: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5630 - accuracy: 0.7633 - val_loss: 0.6092 - val_accuracy: 0.7469\n",
            "Epoch 78/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5621 - accuracy: 0.7446\n",
            "Epoch 78: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5644 - accuracy: 0.7619 - val_loss: 0.6068 - val_accuracy: 0.7469\n",
            "Epoch 79/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5681 - accuracy: 0.7603\n",
            "Epoch 79: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5630 - accuracy: 0.7647 - val_loss: 0.6096 - val_accuracy: 0.7469\n",
            "Epoch 80/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5664 - accuracy: 0.7534\n",
            "Epoch 80: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5626 - accuracy: 0.7606 - val_loss: 0.6074 - val_accuracy: 0.7469\n",
            "Epoch 81/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5569 - accuracy: 0.7676\n",
            "Epoch 81: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5636 - accuracy: 0.7614 - val_loss: 0.6022 - val_accuracy: 0.7469\n",
            "Epoch 82/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5689 - accuracy: 0.7627\n",
            "Epoch 82: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5619 - accuracy: 0.7660 - val_loss: 0.6073 - val_accuracy: 0.7469\n",
            "Epoch 83/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5577 - accuracy: 0.7642\n",
            "Epoch 83: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5608 - accuracy: 0.7589 - val_loss: 0.6054 - val_accuracy: 0.7469\n",
            "Epoch 84/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5645 - accuracy: 0.7520\n",
            "Epoch 84: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5587 - accuracy: 0.7647 - val_loss: 0.6027 - val_accuracy: 0.7469\n",
            "Epoch 85/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5625 - accuracy: 0.7603\n",
            "Epoch 85: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5611 - accuracy: 0.7630 - val_loss: 0.6059 - val_accuracy: 0.7469\n",
            "Epoch 86/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5593 - accuracy: 0.7568\n",
            "Epoch 86: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5563 - accuracy: 0.7628 - val_loss: 0.6041 - val_accuracy: 0.7469\n",
            "Epoch 87/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5588 - accuracy: 0.7593\n",
            "Epoch 87: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5585 - accuracy: 0.7628 - val_loss: 0.6018 - val_accuracy: 0.7469\n",
            "Epoch 88/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5563 - accuracy: 0.7622\n",
            "Epoch 88: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5562 - accuracy: 0.7639 - val_loss: 0.6009 - val_accuracy: 0.7469\n",
            "Epoch 89/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5546 - accuracy: 0.7686\n",
            "Epoch 89: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5546 - accuracy: 0.7633 - val_loss: 0.6031 - val_accuracy: 0.7469\n",
            "Epoch 90/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5575 - accuracy: 0.7676\n",
            "Epoch 90: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5542 - accuracy: 0.7633 - val_loss: 0.6007 - val_accuracy: 0.7469\n",
            "Epoch 91/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5606 - accuracy: 0.7646\n",
            "Epoch 91: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5558 - accuracy: 0.7669 - val_loss: 0.6008 - val_accuracy: 0.7469\n",
            "Epoch 92/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5540 - accuracy: 0.7651\n",
            "Epoch 92: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5564 - accuracy: 0.7652 - val_loss: 0.6024 - val_accuracy: 0.7469\n",
            "Epoch 93/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5516 - accuracy: 0.7588\n",
            "Epoch 93: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5528 - accuracy: 0.7649 - val_loss: 0.5998 - val_accuracy: 0.7469\n",
            "Epoch 94/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5576 - accuracy: 0.7603\n",
            "Epoch 94: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5540 - accuracy: 0.7666 - val_loss: 0.5989 - val_accuracy: 0.7469\n",
            "Epoch 95/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5610 - accuracy: 0.7656\n",
            "Epoch 95: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5529 - accuracy: 0.7679 - val_loss: 0.5991 - val_accuracy: 0.7469\n",
            "Epoch 96/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5502 - accuracy: 0.7661\n",
            "Epoch 96: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5510 - accuracy: 0.7658 - val_loss: 0.5980 - val_accuracy: 0.7469\n",
            "Epoch 97/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5403 - accuracy: 0.7783\n",
            "Epoch 97: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5502 - accuracy: 0.7704 - val_loss: 0.5962 - val_accuracy: 0.7469\n",
            "Epoch 98/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5534 - accuracy: 0.7720\n",
            "Epoch 98: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.5520 - accuracy: 0.7688 - val_loss: 0.5995 - val_accuracy: 0.7469\n",
            "Epoch 99/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5560 - accuracy: 0.7651\n",
            "Epoch 99: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5492 - accuracy: 0.7693 - val_loss: 0.5964 - val_accuracy: 0.7469\n",
            "Epoch 100/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5425 - accuracy: 0.7861\n",
            "Epoch 100: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5481 - accuracy: 0.7707 - val_loss: 0.5977 - val_accuracy: 0.7469\n",
            "Epoch 101/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5515 - accuracy: 0.7710\n",
            "Epoch 101: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.5505 - accuracy: 0.7710 - val_loss: 0.5954 - val_accuracy: 0.7543\n",
            "Epoch 102/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5593 - accuracy: 0.7632\n",
            "Epoch 102: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5508 - accuracy: 0.7690 - val_loss: 0.5959 - val_accuracy: 0.7469\n",
            "Epoch 103/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5494 - accuracy: 0.7720\n",
            "Epoch 103: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5505 - accuracy: 0.7677 - val_loss: 0.5966 - val_accuracy: 0.7469\n",
            "Epoch 104/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5524 - accuracy: 0.7646\n",
            "Epoch 104: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5506 - accuracy: 0.7682 - val_loss: 0.5966 - val_accuracy: 0.7469\n",
            "Epoch 105/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5455 - accuracy: 0.7734\n",
            "Epoch 105: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5477 - accuracy: 0.7707 - val_loss: 0.5949 - val_accuracy: 0.7494\n",
            "Epoch 106/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5495 - accuracy: 0.7690\n",
            "Epoch 106: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5493 - accuracy: 0.7685 - val_loss: 0.5936 - val_accuracy: 0.7518\n",
            "Epoch 107/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5462 - accuracy: 0.7725\n",
            "Epoch 107: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.5474 - accuracy: 0.7699 - val_loss: 0.5933 - val_accuracy: 0.7494\n",
            "Epoch 108/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5432 - accuracy: 0.7754\n",
            "Epoch 108: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5445 - accuracy: 0.7729 - val_loss: 0.5934 - val_accuracy: 0.7469\n",
            "Epoch 109/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5420 - accuracy: 0.7681\n",
            "Epoch 109: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5448 - accuracy: 0.7696 - val_loss: 0.5939 - val_accuracy: 0.7469\n",
            "Epoch 110/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5591 - accuracy: 0.7676\n",
            "Epoch 110: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5465 - accuracy: 0.7649 - val_loss: 0.5935 - val_accuracy: 0.7469\n",
            "Epoch 111/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5520 - accuracy: 0.7559\n",
            "Epoch 111: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.5461 - accuracy: 0.7764 - val_loss: 0.5889 - val_accuracy: 0.7543\n",
            "Epoch 112/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5437 - accuracy: 0.7769\n",
            "Epoch 112: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.5447 - accuracy: 0.7737 - val_loss: 0.5967 - val_accuracy: 0.7469\n",
            "Epoch 113/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5428 - accuracy: 0.7646\n",
            "Epoch 113: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5447 - accuracy: 0.7682 - val_loss: 0.5927 - val_accuracy: 0.7518\n",
            "Epoch 114/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5474 - accuracy: 0.7734\n",
            "Epoch 114: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5428 - accuracy: 0.7707 - val_loss: 0.5897 - val_accuracy: 0.7543\n",
            "Epoch 115/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5509 - accuracy: 0.7568\n",
            "Epoch 115: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5435 - accuracy: 0.7723 - val_loss: 0.5919 - val_accuracy: 0.7543\n",
            "Epoch 116/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5463 - accuracy: 0.7700\n",
            "Epoch 116: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5419 - accuracy: 0.7704 - val_loss: 0.5933 - val_accuracy: 0.7469\n",
            "Epoch 117/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5420 - accuracy: 0.7700\n",
            "Epoch 117: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5441 - accuracy: 0.7710 - val_loss: 0.5866 - val_accuracy: 0.7543\n",
            "Epoch 118/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5451 - accuracy: 0.7725\n",
            "Epoch 118: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.5418 - accuracy: 0.7726 - val_loss: 0.5924 - val_accuracy: 0.7469\n",
            "Epoch 119/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5489 - accuracy: 0.7642\n",
            "Epoch 119: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5423 - accuracy: 0.7682 - val_loss: 0.5901 - val_accuracy: 0.7543\n",
            "Epoch 120/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5353 - accuracy: 0.7749\n",
            "Epoch 120: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5399 - accuracy: 0.7723 - val_loss: 0.5865 - val_accuracy: 0.7543\n",
            "Epoch 121/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5344 - accuracy: 0.7725\n",
            "Epoch 121: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5411 - accuracy: 0.7756 - val_loss: 0.5928 - val_accuracy: 0.7469\n",
            "Epoch 122/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5419 - accuracy: 0.7700\n",
            "Epoch 122: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.5419 - accuracy: 0.7685 - val_loss: 0.5927 - val_accuracy: 0.7469\n",
            "Epoch 123/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5404 - accuracy: 0.7671\n",
            "Epoch 123: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.5406 - accuracy: 0.7742 - val_loss: 0.5857 - val_accuracy: 0.7543\n",
            "Epoch 124/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5492 - accuracy: 0.7749\n",
            "Epoch 124: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.5417 - accuracy: 0.7786 - val_loss: 0.5906 - val_accuracy: 0.7543\n",
            "Epoch 125/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5357 - accuracy: 0.7754\n",
            "Epoch 125: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5397 - accuracy: 0.7685 - val_loss: 0.5924 - val_accuracy: 0.7543\n",
            "Epoch 126/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5388 - accuracy: 0.7676\n",
            "Epoch 126: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.5398 - accuracy: 0.7688 - val_loss: 0.5857 - val_accuracy: 0.7543\n",
            "Epoch 127/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5341 - accuracy: 0.7734\n",
            "Epoch 127: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5403 - accuracy: 0.7729 - val_loss: 0.5872 - val_accuracy: 0.7568\n",
            "Epoch 128/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5484 - accuracy: 0.7739\n",
            "Epoch 128: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.5408 - accuracy: 0.7726 - val_loss: 0.5896 - val_accuracy: 0.7543\n",
            "Epoch 129/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5364 - accuracy: 0.7705\n",
            "Epoch 129: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5357 - accuracy: 0.7677 - val_loss: 0.5864 - val_accuracy: 0.7543\n",
            "Epoch 130/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5350 - accuracy: 0.7764\n",
            "Epoch 130: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.5372 - accuracy: 0.7710 - val_loss: 0.5851 - val_accuracy: 0.7543\n",
            "Epoch 131/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5348 - accuracy: 0.7715\n",
            "Epoch 131: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.5359 - accuracy: 0.7742 - val_loss: 0.5840 - val_accuracy: 0.7543\n",
            "Epoch 132/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5410 - accuracy: 0.7744\n",
            "Epoch 132: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5366 - accuracy: 0.7745 - val_loss: 0.5875 - val_accuracy: 0.7543\n",
            "Epoch 133/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5414 - accuracy: 0.7734\n",
            "Epoch 133: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.5379 - accuracy: 0.7682 - val_loss: 0.5876 - val_accuracy: 0.7543\n",
            "Epoch 134/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5375 - accuracy: 0.7705\n",
            "Epoch 134: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.5364 - accuracy: 0.7720 - val_loss: 0.5829 - val_accuracy: 0.7543\n",
            "Epoch 135/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5225 - accuracy: 0.7866\n",
            "Epoch 135: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5346 - accuracy: 0.7748 - val_loss: 0.5864 - val_accuracy: 0.7543\n",
            "Epoch 136/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5263 - accuracy: 0.7773\n",
            "Epoch 136: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.5353 - accuracy: 0.7715 - val_loss: 0.5848 - val_accuracy: 0.7543\n",
            "Epoch 137/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5348 - accuracy: 0.7744\n",
            "Epoch 137: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5353 - accuracy: 0.7720 - val_loss: 0.5854 - val_accuracy: 0.7568\n",
            "Epoch 138/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5352 - accuracy: 0.7769\n",
            "Epoch 138: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.5346 - accuracy: 0.7704 - val_loss: 0.5853 - val_accuracy: 0.7568\n",
            "Epoch 139/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5331 - accuracy: 0.7720\n",
            "Epoch 139: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.5332 - accuracy: 0.7707 - val_loss: 0.5825 - val_accuracy: 0.7543\n",
            "Epoch 140/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5428 - accuracy: 0.7695\n",
            "Epoch 140: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5364 - accuracy: 0.7729 - val_loss: 0.5847 - val_accuracy: 0.7543\n",
            "Epoch 141/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5279 - accuracy: 0.7842\n",
            "Epoch 141: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5336 - accuracy: 0.7756 - val_loss: 0.5833 - val_accuracy: 0.7543\n",
            "Epoch 142/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5408 - accuracy: 0.7778\n",
            "Epoch 142: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5357 - accuracy: 0.7710 - val_loss: 0.5832 - val_accuracy: 0.7543\n",
            "Epoch 143/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5282 - accuracy: 0.7749\n",
            "Epoch 143: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.5312 - accuracy: 0.7759 - val_loss: 0.5805 - val_accuracy: 0.7543\n",
            "Epoch 144/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5372 - accuracy: 0.7754\n",
            "Epoch 144: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.5335 - accuracy: 0.7704 - val_loss: 0.5840 - val_accuracy: 0.7568\n",
            "Epoch 145/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5385 - accuracy: 0.7612\n",
            "Epoch 145: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.5359 - accuracy: 0.7707 - val_loss: 0.5808 - val_accuracy: 0.7543\n",
            "Epoch 146/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5438 - accuracy: 0.7749\n",
            "Epoch 146: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5355 - accuracy: 0.7742 - val_loss: 0.5817 - val_accuracy: 0.7543\n",
            "Epoch 147/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5374 - accuracy: 0.7666\n",
            "Epoch 147: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.5331 - accuracy: 0.7718 - val_loss: 0.5839 - val_accuracy: 0.7568\n",
            "Epoch 148/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5356 - accuracy: 0.7710\n",
            "Epoch 148: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5325 - accuracy: 0.7685 - val_loss: 0.5801 - val_accuracy: 0.7543\n",
            "Epoch 149/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5307 - accuracy: 0.7764\n",
            "Epoch 149: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5296 - accuracy: 0.7756 - val_loss: 0.5810 - val_accuracy: 0.7543\n",
            "Epoch 150/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5316 - accuracy: 0.7700\n",
            "Epoch 150: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5305 - accuracy: 0.7704 - val_loss: 0.5848 - val_accuracy: 0.7568\n",
            "Epoch 151/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5400 - accuracy: 0.7529\n",
            "Epoch 151: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.5332 - accuracy: 0.7679 - val_loss: 0.5798 - val_accuracy: 0.7543\n",
            "Epoch 152/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5434 - accuracy: 0.7690\n",
            "Epoch 152: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.5290 - accuracy: 0.7748 - val_loss: 0.5801 - val_accuracy: 0.7543\n",
            "Epoch 153/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5413 - accuracy: 0.7686\n",
            "Epoch 153: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.5300 - accuracy: 0.7742 - val_loss: 0.5805 - val_accuracy: 0.7543\n",
            "Epoch 154/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5339 - accuracy: 0.7695\n",
            "Epoch 154: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5319 - accuracy: 0.7729 - val_loss: 0.5820 - val_accuracy: 0.7543\n",
            "Epoch 155/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5335 - accuracy: 0.7549\n",
            "Epoch 155: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.5284 - accuracy: 0.7690 - val_loss: 0.5804 - val_accuracy: 0.7543\n",
            "Epoch 156/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5318 - accuracy: 0.7744\n",
            "Epoch 156: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.5330 - accuracy: 0.7707 - val_loss: 0.5787 - val_accuracy: 0.7543\n",
            "Epoch 157/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5292 - accuracy: 0.7725\n",
            "Epoch 157: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.5290 - accuracy: 0.7756 - val_loss: 0.5800 - val_accuracy: 0.7543\n",
            "Epoch 158/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5430 - accuracy: 0.7617\n",
            "Epoch 158: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.5303 - accuracy: 0.7737 - val_loss: 0.5807 - val_accuracy: 0.7543\n",
            "Epoch 159/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5280 - accuracy: 0.7720\n",
            "Epoch 159: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.5296 - accuracy: 0.7655 - val_loss: 0.5790 - val_accuracy: 0.7543\n",
            "Epoch 160/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5370 - accuracy: 0.7646\n",
            "Epoch 160: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.5314 - accuracy: 0.7696 - val_loss: 0.5782 - val_accuracy: 0.7543\n",
            "Epoch 161/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5317 - accuracy: 0.7729\n",
            "Epoch 161: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.5283 - accuracy: 0.7898 - val_loss: 0.5775 - val_accuracy: 0.7543\n",
            "Epoch 162/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5190 - accuracy: 0.7734\n",
            "Epoch 162: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5291 - accuracy: 0.7663 - val_loss: 0.5819 - val_accuracy: 0.7543\n",
            "Epoch 163/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5319 - accuracy: 0.7588\n",
            "Epoch 163: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5294 - accuracy: 0.7660 - val_loss: 0.5781 - val_accuracy: 0.7543\n",
            "Epoch 164/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5250 - accuracy: 0.7812\n",
            "Epoch 164: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.5300 - accuracy: 0.7729 - val_loss: 0.5780 - val_accuracy: 0.7543\n",
            "Epoch 165/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5347 - accuracy: 0.7725\n",
            "Epoch 165: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.5282 - accuracy: 0.7710 - val_loss: 0.5784 - val_accuracy: 0.7543\n",
            "Epoch 166/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5251 - accuracy: 0.7725\n",
            "Epoch 166: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5289 - accuracy: 0.7718 - val_loss: 0.5763 - val_accuracy: 0.7543\n",
            "Epoch 167/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5164 - accuracy: 0.7856\n",
            "Epoch 167: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.5256 - accuracy: 0.7750 - val_loss: 0.5783 - val_accuracy: 0.7543\n",
            "Epoch 168/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5262 - accuracy: 0.7681\n",
            "Epoch 168: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5283 - accuracy: 0.7674 - val_loss: 0.5769 - val_accuracy: 0.7543\n",
            "Epoch 169/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5252 - accuracy: 0.7764\n",
            "Epoch 169: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5269 - accuracy: 0.7710 - val_loss: 0.5755 - val_accuracy: 0.7543\n",
            "Epoch 170/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5219 - accuracy: 0.7861\n",
            "Epoch 170: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.5757 - val_accuracy: 0.7543\n",
            "Epoch 171/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5348 - accuracy: 0.7725\n",
            "Epoch 171: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5270 - accuracy: 0.7740 - val_loss: 0.5778 - val_accuracy: 0.7543\n",
            "Epoch 172/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5231 - accuracy: 0.7729\n",
            "Epoch 172: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5260 - accuracy: 0.7704 - val_loss: 0.5761 - val_accuracy: 0.7543\n",
            "Epoch 173/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5339 - accuracy: 0.7671\n",
            "Epoch 173: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5244 - accuracy: 0.7720 - val_loss: 0.5768 - val_accuracy: 0.7543\n",
            "Epoch 174/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5251 - accuracy: 0.7612\n",
            "Epoch 174: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5264 - accuracy: 0.7682 - val_loss: 0.5753 - val_accuracy: 0.7543\n",
            "Epoch 175/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5160 - accuracy: 0.7690\n",
            "Epoch 175: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5242 - accuracy: 0.7734 - val_loss: 0.5763 - val_accuracy: 0.7543\n",
            "Epoch 176/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5272 - accuracy: 0.7617\n",
            "Epoch 176: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5256 - accuracy: 0.7647 - val_loss: 0.5755 - val_accuracy: 0.7543\n",
            "Epoch 177/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5176 - accuracy: 0.7725\n",
            "Epoch 177: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5229 - accuracy: 0.7737 - val_loss: 0.5731 - val_accuracy: 0.7543\n",
            "Epoch 178/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5300 - accuracy: 0.7612\n",
            "Epoch 178: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5283 - accuracy: 0.7734 - val_loss: 0.5771 - val_accuracy: 0.7543\n",
            "Epoch 179/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5264 - accuracy: 0.7764\n",
            "Epoch 179: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5238 - accuracy: 0.7679 - val_loss: 0.5749 - val_accuracy: 0.7543\n",
            "Epoch 180/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5238 - accuracy: 0.7744\n",
            "Epoch 180: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5273 - accuracy: 0.8179 - val_loss: 0.5718 - val_accuracy: 0.7543\n",
            "Epoch 181/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5218 - accuracy: 0.7852\n",
            "Epoch 181: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5252 - accuracy: 0.7726 - val_loss: 0.5784 - val_accuracy: 0.7543\n",
            "Epoch 182/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5120 - accuracy: 0.7783\n",
            "Epoch 182: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5255 - accuracy: 0.7674 - val_loss: 0.5718 - val_accuracy: 0.7543\n",
            "Epoch 183/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5149 - accuracy: 0.7783\n",
            "Epoch 183: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.5225 - accuracy: 0.7786 - val_loss: 0.5740 - val_accuracy: 0.7543\n",
            "Epoch 184/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5271 - accuracy: 0.7651\n",
            "Epoch 184: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5258 - accuracy: 0.7628 - val_loss: 0.5756 - val_accuracy: 0.7543\n",
            "Epoch 185/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5196 - accuracy: 0.7651\n",
            "Epoch 185: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5259 - accuracy: 0.7674 - val_loss: 0.5716 - val_accuracy: 0.7543\n",
            "Epoch 186/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5259 - accuracy: 0.7729\n",
            "Epoch 186: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5253 - accuracy: 0.7674 - val_loss: 0.5730 - val_accuracy: 0.7543\n",
            "Epoch 187/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5215 - accuracy: 0.7607\n",
            "Epoch 187: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5220 - accuracy: 0.7690 - val_loss: 0.5707 - val_accuracy: 0.7543\n",
            "Epoch 188/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5240 - accuracy: 0.7754\n",
            "Epoch 188: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5250 - accuracy: 0.7718 - val_loss: 0.5732 - val_accuracy: 0.7543\n",
            "Epoch 189/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5263 - accuracy: 0.7632\n",
            "Epoch 189: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5241 - accuracy: 0.7636 - val_loss: 0.5716 - val_accuracy: 0.7543\n",
            "Epoch 190/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5152 - accuracy: 0.7715\n",
            "Epoch 190: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5236 - accuracy: 0.7759 - val_loss: 0.5697 - val_accuracy: 0.7543\n",
            "Epoch 191/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5315 - accuracy: 0.7671\n",
            "Epoch 191: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5221 - accuracy: 0.7696 - val_loss: 0.5731 - val_accuracy: 0.7543\n",
            "Epoch 192/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5172 - accuracy: 0.7686\n",
            "Epoch 192: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5236 - accuracy: 0.7674 - val_loss: 0.5711 - val_accuracy: 0.7543\n",
            "Epoch 193/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5240 - accuracy: 0.7710\n",
            "Epoch 193: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5218 - accuracy: 0.7679 - val_loss: 0.5708 - val_accuracy: 0.7543\n",
            "Epoch 194/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5253 - accuracy: 0.7627\n",
            "Epoch 194: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5222 - accuracy: 0.7666 - val_loss: 0.5690 - val_accuracy: 0.7543\n",
            "Epoch 195/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5188 - accuracy: 0.7656\n",
            "Epoch 195: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5231 - accuracy: 0.7813 - val_loss: 0.5711 - val_accuracy: 0.7543\n",
            "Epoch 196/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5216 - accuracy: 0.7695\n",
            "Epoch 196: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5221 - accuracy: 0.7639 - val_loss: 0.5703 - val_accuracy: 0.7543\n",
            "Epoch 197/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5148 - accuracy: 0.7705\n",
            "Epoch 197: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5218 - accuracy: 0.8179 - val_loss: 0.5672 - val_accuracy: 0.7543\n",
            "Epoch 198/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5151 - accuracy: 0.7808\n",
            "Epoch 198: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5222 - accuracy: 0.7726 - val_loss: 0.5740 - val_accuracy: 0.7543\n",
            "Epoch 199/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5254 - accuracy: 0.7632\n",
            "Epoch 199: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5213 - accuracy: 0.7639 - val_loss: 0.5666 - val_accuracy: 0.7543\n",
            "Epoch 200/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5186 - accuracy: 0.7832\n",
            "Epoch 200: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5207 - accuracy: 0.8261 - val_loss: 0.5678 - val_accuracy: 0.7543\n",
            "Epoch 201/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5204 - accuracy: 0.7642\n",
            "Epoch 201: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.5214 - accuracy: 0.7649 - val_loss: 0.5717 - val_accuracy: 0.7543\n",
            "Epoch 202/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5310 - accuracy: 0.7651\n",
            "Epoch 202: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5222 - accuracy: 0.7625 - val_loss: 0.5650 - val_accuracy: 0.7518\n",
            "Epoch 203/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5255 - accuracy: 0.8784\n",
            "Epoch 203: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5202 - accuracy: 0.8804 - val_loss: 0.5655 - val_accuracy: 0.7518\n",
            "Epoch 204/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5272 - accuracy: 0.7905\n",
            "Epoch 204: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5198 - accuracy: 0.7802 - val_loss: 0.5688 - val_accuracy: 0.7543\n",
            "Epoch 205/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5163 - accuracy: 0.7627\n",
            "Epoch 205: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5195 - accuracy: 0.8097 - val_loss: 0.5642 - val_accuracy: 0.7518\n",
            "Epoch 206/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5236 - accuracy: 0.8789\n",
            "Epoch 206: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5187 - accuracy: 0.8376 - val_loss: 0.5715 - val_accuracy: 0.7543\n",
            "Epoch 207/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5295 - accuracy: 0.7539\n",
            "Epoch 207: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5197 - accuracy: 0.7639 - val_loss: 0.5684 - val_accuracy: 0.7543\n",
            "Epoch 208/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5348 - accuracy: 0.7593\n",
            "Epoch 208: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5199 - accuracy: 0.7660 - val_loss: 0.5631 - val_accuracy: 0.7543\n",
            "Epoch 209/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5301 - accuracy: 0.8711\n",
            "Epoch 209: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5189 - accuracy: 0.8793 - val_loss: 0.5670 - val_accuracy: 0.7543\n",
            "Epoch 210/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5234 - accuracy: 0.7671\n",
            "Epoch 210: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5205 - accuracy: 0.7666 - val_loss: 0.5707 - val_accuracy: 0.7543\n",
            "Epoch 211/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5190 - accuracy: 0.7646\n",
            "Epoch 211: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5202 - accuracy: 0.7679 - val_loss: 0.5630 - val_accuracy: 0.7518\n",
            "Epoch 212/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5265 - accuracy: 0.8730\n",
            "Epoch 212: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5193 - accuracy: 0.8791 - val_loss: 0.5651 - val_accuracy: 0.7543\n",
            "Epoch 213/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5194 - accuracy: 0.7632\n",
            "Epoch 213: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5196 - accuracy: 0.7644 - val_loss: 0.5707 - val_accuracy: 0.7543\n",
            "Epoch 214/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5192 - accuracy: 0.7656\n",
            "Epoch 214: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5200 - accuracy: 0.7630 - val_loss: 0.5614 - val_accuracy: 0.7592\n",
            "Epoch 215/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5094 - accuracy: 0.8843\n",
            "Epoch 215: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5184 - accuracy: 0.8791 - val_loss: 0.5658 - val_accuracy: 0.7543\n",
            "Epoch 216/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5176 - accuracy: 0.7622\n",
            "Epoch 216: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5195 - accuracy: 0.7630 - val_loss: 0.5687 - val_accuracy: 0.7543\n",
            "Epoch 217/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5129 - accuracy: 0.7690\n",
            "Epoch 217: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5186 - accuracy: 0.7639 - val_loss: 0.5614 - val_accuracy: 0.7617\n",
            "Epoch 218/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5276 - accuracy: 0.8784\n",
            "Epoch 218: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5192 - accuracy: 0.8821 - val_loss: 0.5647 - val_accuracy: 0.7543\n",
            "Epoch 219/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5118 - accuracy: 0.7754\n",
            "Epoch 219: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5196 - accuracy: 0.7639 - val_loss: 0.5671 - val_accuracy: 0.7543\n",
            "Epoch 220/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5286 - accuracy: 0.7505\n",
            "Epoch 220: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5175 - accuracy: 0.7753 - val_loss: 0.5619 - val_accuracy: 0.7518\n",
            "Epoch 221/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5148 - accuracy: 0.8433\n",
            "Epoch 221: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5173 - accuracy: 0.8288 - val_loss: 0.5672 - val_accuracy: 0.7543\n",
            "Epoch 222/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5312 - accuracy: 0.7529\n",
            "Epoch 222: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.5195 - accuracy: 0.7633 - val_loss: 0.5651 - val_accuracy: 0.7543\n",
            "Epoch 223/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5184 - accuracy: 0.7676\n",
            "Epoch 223: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5178 - accuracy: 0.7720 - val_loss: 0.5610 - val_accuracy: 0.7518\n",
            "Epoch 224/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5147 - accuracy: 0.8779\n",
            "Epoch 224: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5172 - accuracy: 0.8275 - val_loss: 0.5648 - val_accuracy: 0.7543\n",
            "Epoch 225/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5129 - accuracy: 0.7773\n",
            "Epoch 225: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5147 - accuracy: 0.7669 - val_loss: 0.5619 - val_accuracy: 0.7518\n",
            "Epoch 226/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5114 - accuracy: 0.7725\n",
            "Epoch 226: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5176 - accuracy: 0.8201 - val_loss: 0.5611 - val_accuracy: 0.7518\n",
            "Epoch 227/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5091 - accuracy: 0.7817\n",
            "Epoch 227: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.5139 - accuracy: 0.7715 - val_loss: 0.5661 - val_accuracy: 0.7543\n",
            "Epoch 228/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5298 - accuracy: 0.7485\n",
            "Epoch 228: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5188 - accuracy: 0.7614 - val_loss: 0.5596 - val_accuracy: 0.7617\n",
            "Epoch 229/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5139 - accuracy: 0.8882\n",
            "Epoch 229: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5156 - accuracy: 0.8834 - val_loss: 0.5620 - val_accuracy: 0.7543\n",
            "Epoch 230/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5083 - accuracy: 0.7686\n",
            "Epoch 230: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5159 - accuracy: 0.7636 - val_loss: 0.5660 - val_accuracy: 0.7543\n",
            "Epoch 231/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5160 - accuracy: 0.7715\n",
            "Epoch 231: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.5152 - accuracy: 0.8026 - val_loss: 0.5586 - val_accuracy: 0.7690\n",
            "Epoch 232/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5139 - accuracy: 0.8833\n",
            "Epoch 232: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5142 - accuracy: 0.8433 - val_loss: 0.5630 - val_accuracy: 0.7543\n",
            "Epoch 233/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5002 - accuracy: 0.7788\n",
            "Epoch 233: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5132 - accuracy: 0.7677 - val_loss: 0.5619 - val_accuracy: 0.7543\n",
            "Epoch 234/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5103 - accuracy: 0.7695\n",
            "Epoch 234: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5181 - accuracy: 0.8130 - val_loss: 0.5581 - val_accuracy: 0.7543\n",
            "Epoch 235/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5178 - accuracy: 0.8735\n",
            "Epoch 235: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5138 - accuracy: 0.8316 - val_loss: 0.5684 - val_accuracy: 0.7543\n",
            "Epoch 236/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5263 - accuracy: 0.7510\n",
            "Epoch 236: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5157 - accuracy: 0.7644 - val_loss: 0.5593 - val_accuracy: 0.7518\n",
            "Epoch 237/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5227 - accuracy: 0.7778\n",
            "Epoch 237: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5121 - accuracy: 0.8225 - val_loss: 0.5567 - val_accuracy: 0.8894\n",
            "Epoch 238/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5076 - accuracy: 0.8853\n",
            "Epoch 238: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5140 - accuracy: 0.8425 - val_loss: 0.5664 - val_accuracy: 0.7543\n",
            "Epoch 239/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5126 - accuracy: 0.7715\n",
            "Epoch 239: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5133 - accuracy: 0.7699 - val_loss: 0.5619 - val_accuracy: 0.7543\n",
            "Epoch 240/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5089 - accuracy: 0.7617\n",
            "Epoch 240: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5148 - accuracy: 0.7740 - val_loss: 0.5572 - val_accuracy: 0.7518\n",
            "Epoch 241/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5130 - accuracy: 0.8687\n",
            "Epoch 241: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5163 - accuracy: 0.8223 - val_loss: 0.5611 - val_accuracy: 0.7543\n",
            "Epoch 242/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5224 - accuracy: 0.7539\n",
            "Epoch 242: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.5144 - accuracy: 0.7649 - val_loss: 0.5590 - val_accuracy: 0.7518\n",
            "Epoch 243/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5112 - accuracy: 0.7739\n",
            "Epoch 243: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5135 - accuracy: 0.8228 - val_loss: 0.5589 - val_accuracy: 0.7518\n",
            "Epoch 244/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5149 - accuracy: 0.7803\n",
            "Epoch 244: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5136 - accuracy: 0.7767 - val_loss: 0.5615 - val_accuracy: 0.7543\n",
            "Epoch 245/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5220 - accuracy: 0.7573\n",
            "Epoch 245: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5109 - accuracy: 0.7658 - val_loss: 0.5584 - val_accuracy: 0.7518\n",
            "Epoch 246/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5152 - accuracy: 0.7939\n",
            "Epoch 246: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.5124 - accuracy: 0.7955 - val_loss: 0.5590 - val_accuracy: 0.7518\n",
            "Epoch 247/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5154 - accuracy: 0.7725\n",
            "Epoch 247: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5132 - accuracy: 0.7835 - val_loss: 0.5603 - val_accuracy: 0.7543\n",
            "Epoch 247: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5166 - accuracy: 0.7775\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5166 - accuracy: 0.7775\n",
            "Model: \"DOS2019-LUCID\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv0 (Conv2D)              (None, 8, 1, 64)          2176      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 64)               0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,241\n",
            "Trainable params: 2,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6955 - accuracy: 0.5098\n",
            "Epoch 1: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.7009 - accuracy: 0.5007 - val_loss: 0.6533 - val_accuracy: 0.5799\n",
            "Epoch 2/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6154 - accuracy: 0.6333\n",
            "Epoch 2: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.6050 - accuracy: 0.6391 - val_loss: 0.5787 - val_accuracy: 0.7518\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5436 - accuracy: 0.7783\n",
            "Epoch 3: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5525 - accuracy: 0.7437 - val_loss: 0.5495 - val_accuracy: 0.7641\n",
            "Epoch 4/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5236 - accuracy: 0.7939\n",
            "Epoch 4: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5123 - accuracy: 0.7748 - val_loss: 0.5593 - val_accuracy: 0.7273\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5034 - accuracy: 0.7378\n",
            "Epoch 5: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4906 - accuracy: 0.7543 - val_loss: 0.5152 - val_accuracy: 0.7690\n",
            "Epoch 6/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4814 - accuracy: 0.7988\n",
            "Epoch 6: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4719 - accuracy: 0.7950 - val_loss: 0.5133 - val_accuracy: 0.7420\n",
            "Epoch 7/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4350 - accuracy: 0.7725\n",
            "Epoch 7: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4510 - accuracy: 0.7669 - val_loss: 0.4945 - val_accuracy: 0.7420\n",
            "Epoch 8/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4320 - accuracy: 0.7686\n",
            "Epoch 8: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4292 - accuracy: 0.7890 - val_loss: 0.4723 - val_accuracy: 0.7666\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4172 - accuracy: 0.8135\n",
            "Epoch 9: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4164 - accuracy: 0.7999 - val_loss: 0.4692 - val_accuracy: 0.7862\n",
            "Epoch 10/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4010 - accuracy: 0.8262\n",
            "Epoch 10: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.3945 - accuracy: 0.8283 - val_loss: 0.4401 - val_accuracy: 0.8894\n",
            "Epoch 11/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3822 - accuracy: 0.8574\n",
            "Epoch 11: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.3835 - accuracy: 0.8643 - val_loss: 0.4284 - val_accuracy: 0.9361\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3555 - accuracy: 0.8853\n",
            "Epoch 12: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.3654 - accuracy: 0.8679 - val_loss: 0.4077 - val_accuracy: 0.9337\n",
            "Epoch 13/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3433 - accuracy: 0.8945\n",
            "Epoch 13: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.3438 - accuracy: 0.8900 - val_loss: 0.3802 - val_accuracy: 0.8821\n",
            "Epoch 14/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3168 - accuracy: 0.8838\n",
            "Epoch 14: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.3110 - accuracy: 0.8856 - val_loss: 0.3639 - val_accuracy: 0.9386\n",
            "Epoch 15/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2960 - accuracy: 0.9058\n",
            "Epoch 15: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.2912 - accuracy: 0.9225 - val_loss: 0.3413 - val_accuracy: 0.9631\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2805 - accuracy: 0.9048\n",
            "Epoch 16: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.2685 - accuracy: 0.9271 - val_loss: 0.3382 - val_accuracy: 0.9337\n",
            "Epoch 17/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2446 - accuracy: 0.9644\n",
            "Epoch 17: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2426 - accuracy: 0.9563 - val_loss: 0.3078 - val_accuracy: 0.9607\n",
            "Epoch 18/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2141 - accuracy: 0.9683\n",
            "Epoch 18: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2146 - accuracy: 0.9675 - val_loss: 0.2790 - val_accuracy: 0.9607\n",
            "Epoch 19/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2017 - accuracy: 0.9565\n",
            "Epoch 19: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1894 - accuracy: 0.9623 - val_loss: 0.2621 - val_accuracy: 0.9582\n",
            "Epoch 20/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1701 - accuracy: 0.9746\n",
            "Epoch 20: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1736 - accuracy: 0.9771 - val_loss: 0.2507 - val_accuracy: 0.9631\n",
            "Epoch 21/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1664 - accuracy: 0.9766\n",
            "Epoch 21: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1579 - accuracy: 0.9784 - val_loss: 0.2258 - val_accuracy: 0.9582\n",
            "Epoch 22/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1361 - accuracy: 0.9814\n",
            "Epoch 22: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.1405 - accuracy: 0.9823 - val_loss: 0.2152 - val_accuracy: 0.9631\n",
            "Epoch 23/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1269 - accuracy: 0.9868\n",
            "Epoch 23: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1293 - accuracy: 0.9847 - val_loss: 0.2015 - val_accuracy: 0.9631\n",
            "Epoch 24/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1270 - accuracy: 0.9854\n",
            "Epoch 24: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1212 - accuracy: 0.9844 - val_loss: 0.1862 - val_accuracy: 0.9631\n",
            "Epoch 25/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1073 - accuracy: 0.9839\n",
            "Epoch 25: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.1072 - accuracy: 0.9853 - val_loss: 0.1808 - val_accuracy: 0.9631\n",
            "Epoch 26/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1077 - accuracy: 0.9834\n",
            "Epoch 26: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.1038 - accuracy: 0.9844 - val_loss: 0.1702 - val_accuracy: 0.9656\n",
            "Epoch 27/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0844 - accuracy: 0.9858\n",
            "Epoch 27: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0946 - accuracy: 0.9850 - val_loss: 0.1674 - val_accuracy: 0.9656\n",
            "Epoch 28/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0930 - accuracy: 0.9844\n",
            "Epoch 28: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0988 - accuracy: 0.9850 - val_loss: 0.1643 - val_accuracy: 0.9656\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9861\n",
            "Epoch 29: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.0880 - accuracy: 0.9861 - val_loss: 0.1527 - val_accuracy: 0.9656\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9842\n",
            "Epoch 30: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.0928 - accuracy: 0.9842 - val_loss: 0.1500 - val_accuracy: 0.9656\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9858\n",
            "Epoch 31: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.0783 - accuracy: 0.9858 - val_loss: 0.1480 - val_accuracy: 0.9656\n",
            "Epoch 32/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0766 - accuracy: 0.9854\n",
            "Epoch 32: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.0765 - accuracy: 0.9858 - val_loss: 0.1498 - val_accuracy: 0.9656\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9863\n",
            "Epoch 33: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.0823 - accuracy: 0.9863 - val_loss: 0.1472 - val_accuracy: 0.9656\n",
            "Epoch 34/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0971 - accuracy: 0.9858\n",
            "Epoch 34: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0843 - accuracy: 0.9869 - val_loss: 0.1463 - val_accuracy: 0.9705\n",
            "Epoch 35/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0849 - accuracy: 0.9858\n",
            "Epoch 35: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.0786 - accuracy: 0.9872 - val_loss: 0.1427 - val_accuracy: 0.9656\n",
            "Epoch 36/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0794 - accuracy: 0.9834\n",
            "Epoch 36: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0754 - accuracy: 0.9863 - val_loss: 0.1424 - val_accuracy: 0.9656\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9874\n",
            "Epoch 37: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.0673 - accuracy: 0.9874 - val_loss: 0.1364 - val_accuracy: 0.9730\n",
            "Epoch 38/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0724 - accuracy: 0.9858\n",
            "Epoch 38: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.0657 - accuracy: 0.9872 - val_loss: 0.1390 - val_accuracy: 0.9730\n",
            "Epoch 39/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0679 - accuracy: 0.9883\n",
            "Epoch 39: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0759 - accuracy: 0.9855 - val_loss: 0.1433 - val_accuracy: 0.9681\n",
            "Epoch 40/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0672 - accuracy: 0.9893\n",
            "Epoch 40: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.0728 - accuracy: 0.9880 - val_loss: 0.1432 - val_accuracy: 0.9681\n",
            "Epoch 41/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0587 - accuracy: 0.9878\n",
            "Epoch 41: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.0641 - accuracy: 0.9880 - val_loss: 0.1382 - val_accuracy: 0.9730\n",
            "Epoch 42/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0666 - accuracy: 0.9863\n",
            "Epoch 42: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.0624 - accuracy: 0.9883 - val_loss: 0.1442 - val_accuracy: 0.9681\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9888\n",
            "Epoch 43: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.0684 - accuracy: 0.9888 - val_loss: 0.1409 - val_accuracy: 0.9681\n",
            "Epoch 44/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0705 - accuracy: 0.9873\n",
            "Epoch 44: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.0669 - accuracy: 0.9866 - val_loss: 0.1329 - val_accuracy: 0.9730\n",
            "Epoch 45/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0505 - accuracy: 0.9883\n",
            "Epoch 45: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0556 - accuracy: 0.9885 - val_loss: 0.1280 - val_accuracy: 0.9730\n",
            "Epoch 46/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0788 - accuracy: 0.9839\n",
            "Epoch 46: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0643 - accuracy: 0.9877 - val_loss: 0.1304 - val_accuracy: 0.9681\n",
            "Epoch 47/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0596 - accuracy: 0.9902\n",
            "Epoch 47: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.0675 - accuracy: 0.9877 - val_loss: 0.1324 - val_accuracy: 0.9681\n",
            "Epoch 48/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0614 - accuracy: 0.9888\n",
            "Epoch 48: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0679 - accuracy: 0.9874 - val_loss: 0.1222 - val_accuracy: 0.9730\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9861\n",
            "Epoch 49: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.0672 - accuracy: 0.9861 - val_loss: 0.1180 - val_accuracy: 0.9730\n",
            "Epoch 50/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0609 - accuracy: 0.9858\n",
            "Epoch 50: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0597 - accuracy: 0.9874 - val_loss: 0.1279 - val_accuracy: 0.9681\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9883\n",
            "Epoch 51: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.0597 - accuracy: 0.9883 - val_loss: 0.1241 - val_accuracy: 0.9681\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9880\n",
            "Epoch 52: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.0632 - accuracy: 0.9880 - val_loss: 0.1210 - val_accuracy: 0.9730\n",
            "Epoch 53/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0573 - accuracy: 0.9888\n",
            "Epoch 53: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.0578 - accuracy: 0.9883 - val_loss: 0.1171 - val_accuracy: 0.9730\n",
            "Epoch 54/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0579 - accuracy: 0.9873\n",
            "Epoch 54: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 0.0589 - accuracy: 0.9877 - val_loss: 0.1168 - val_accuracy: 0.9730\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9866\n",
            "Epoch 55: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 0.0552 - accuracy: 0.9866 - val_loss: 0.1183 - val_accuracy: 0.9730\n",
            "Epoch 56/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0578 - accuracy: 0.9878\n",
            "Epoch 56: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.0546 - accuracy: 0.9883 - val_loss: 0.1209 - val_accuracy: 0.9681\n",
            "Epoch 57/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0479 - accuracy: 0.9912\n",
            "Epoch 57: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.0585 - accuracy: 0.9888 - val_loss: 0.1223 - val_accuracy: 0.9681\n",
            "Epoch 58/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0522 - accuracy: 0.9902\n",
            "Epoch 58: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0524 - accuracy: 0.9888 - val_loss: 0.1175 - val_accuracy: 0.9730\n",
            "Epoch 59/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0465 - accuracy: 0.9883\n",
            "Epoch 59: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.0518 - accuracy: 0.9874 - val_loss: 0.1160 - val_accuracy: 0.9730\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9872\n",
            "Epoch 60: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.0583 - accuracy: 0.9872 - val_loss: 0.1215 - val_accuracy: 0.9730\n",
            "Epoch 61/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0578 - accuracy: 0.9873\n",
            "Epoch 61: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0548 - accuracy: 0.9880 - val_loss: 0.1218 - val_accuracy: 0.9681\n",
            "Epoch 62/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0506 - accuracy: 0.9878\n",
            "Epoch 62: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.0513 - accuracy: 0.9883 - val_loss: 0.1173 - val_accuracy: 0.9730\n",
            "Epoch 63/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0525 - accuracy: 0.9878\n",
            "Epoch 63: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 0.0512 - accuracy: 0.9888 - val_loss: 0.1126 - val_accuracy: 0.9730\n",
            "Epoch 64/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0465 - accuracy: 0.9902\n",
            "Epoch 64: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 0.0483 - accuracy: 0.9885 - val_loss: 0.1142 - val_accuracy: 0.9730\n",
            "Epoch 65/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0499 - accuracy: 0.9888\n",
            "Epoch 65: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0515 - accuracy: 0.9888 - val_loss: 0.1124 - val_accuracy: 0.9730\n",
            "Epoch 66/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0570 - accuracy: 0.9883\n",
            "Epoch 66: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0562 - accuracy: 0.9883 - val_loss: 0.1082 - val_accuracy: 0.9730\n",
            "Epoch 67/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0516 - accuracy: 0.9878\n",
            "Epoch 67: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0500 - accuracy: 0.9880 - val_loss: 0.1059 - val_accuracy: 0.9730\n",
            "Epoch 68/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0483 - accuracy: 0.9897\n",
            "Epoch 68: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0537 - accuracy: 0.9885 - val_loss: 0.1097 - val_accuracy: 0.9730\n",
            "Epoch 69/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0592 - accuracy: 0.9854\n",
            "Epoch 69: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0523 - accuracy: 0.9877 - val_loss: 0.1060 - val_accuracy: 0.9730\n",
            "Epoch 70/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0535 - accuracy: 0.9883\n",
            "Epoch 70: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0487 - accuracy: 0.9888 - val_loss: 0.1023 - val_accuracy: 0.9730\n",
            "Epoch 71/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0402 - accuracy: 0.9907\n",
            "Epoch 71: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0483 - accuracy: 0.9891 - val_loss: 0.1021 - val_accuracy: 0.9754\n",
            "Epoch 72/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0561 - accuracy: 0.9868\n",
            "Epoch 72: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0554 - accuracy: 0.9872 - val_loss: 0.0989 - val_accuracy: 0.9730\n",
            "Epoch 73/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9873\n",
            "Epoch 73: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0473 - accuracy: 0.9891 - val_loss: 0.0991 - val_accuracy: 0.9730\n",
            "Epoch 74/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0487 - accuracy: 0.9888\n",
            "Epoch 74: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0459 - accuracy: 0.9899 - val_loss: 0.1002 - val_accuracy: 0.9730\n",
            "Epoch 75/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0496 - accuracy: 0.9868\n",
            "Epoch 75: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0448 - accuracy: 0.9888 - val_loss: 0.0940 - val_accuracy: 0.9779\n",
            "Epoch 76/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0551 - accuracy: 0.9854\n",
            "Epoch 76: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0455 - accuracy: 0.9880 - val_loss: 0.0960 - val_accuracy: 0.9754\n",
            "Epoch 77/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0539 - accuracy: 0.9883\n",
            "Epoch 77: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0456 - accuracy: 0.9896 - val_loss: 0.0961 - val_accuracy: 0.9779\n",
            "Epoch 78/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0414 - accuracy: 0.9902\n",
            "Epoch 78: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0455 - accuracy: 0.9894 - val_loss: 0.0940 - val_accuracy: 0.9754\n",
            "Epoch 79/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0409 - accuracy: 0.9897\n",
            "Epoch 79: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.0946 - val_accuracy: 0.9754\n",
            "Epoch 80/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9878\n",
            "Epoch 80: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0449 - accuracy: 0.9894 - val_loss: 0.0980 - val_accuracy: 0.9779\n",
            "Epoch 81/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0385 - accuracy: 0.9912\n",
            "Epoch 81: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0408 - accuracy: 0.9902 - val_loss: 0.0916 - val_accuracy: 0.9754\n",
            "Epoch 82/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0375 - accuracy: 0.9893\n",
            "Epoch 82: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 0.0896 - val_accuracy: 0.9779\n",
            "Epoch 83/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0392 - accuracy: 0.9888\n",
            "Epoch 83: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0463 - accuracy: 0.9880 - val_loss: 0.0929 - val_accuracy: 0.9754\n",
            "Epoch 84/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0371 - accuracy: 0.9907\n",
            "Epoch 84: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0444 - accuracy: 0.9885 - val_loss: 0.0882 - val_accuracy: 0.9779\n",
            "Epoch 85/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0428 - accuracy: 0.9888\n",
            "Epoch 85: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0445 - accuracy: 0.9885 - val_loss: 0.0872 - val_accuracy: 0.9779\n",
            "Epoch 86/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0467 - accuracy: 0.9893\n",
            "Epoch 86: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0434 - accuracy: 0.9904 - val_loss: 0.0929 - val_accuracy: 0.9705\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9894\n",
            "Epoch 87: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0455 - accuracy: 0.9894 - val_loss: 0.0947 - val_accuracy: 0.9779\n",
            "Epoch 88/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0408 - accuracy: 0.9893\n",
            "Epoch 88: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0466 - accuracy: 0.9888 - val_loss: 0.0881 - val_accuracy: 0.9754\n",
            "Epoch 89/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0416 - accuracy: 0.9878\n",
            "Epoch 89: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.0914 - val_accuracy: 0.9754\n",
            "Epoch 90/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9878\n",
            "Epoch 90: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0421 - accuracy: 0.9891 - val_loss: 0.0968 - val_accuracy: 0.9681\n",
            "Epoch 91/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0390 - accuracy: 0.9917\n",
            "Epoch 91: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0441 - accuracy: 0.9899 - val_loss: 0.0930 - val_accuracy: 0.9754\n",
            "Epoch 92/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0401 - accuracy: 0.9907\n",
            "Epoch 92: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 0.0855 - val_accuracy: 0.9779\n",
            "Epoch 93/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0489 - accuracy: 0.9888\n",
            "Epoch 93: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0511 - accuracy: 0.9896 - val_loss: 0.0854 - val_accuracy: 0.9779\n",
            "Epoch 94/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0327 - accuracy: 0.9927\n",
            "Epoch 94: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0440 - accuracy: 0.9894 - val_loss: 0.0853 - val_accuracy: 0.9779\n",
            "Epoch 95/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0443 - accuracy: 0.9888\n",
            "Epoch 95: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0415 - accuracy: 0.9899 - val_loss: 0.0809 - val_accuracy: 0.9779\n",
            "Epoch 96/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0447 - accuracy: 0.9888\n",
            "Epoch 96: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0432 - accuracy: 0.9883 - val_loss: 0.0884 - val_accuracy: 0.9779\n",
            "Epoch 97/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0382 - accuracy: 0.9902\n",
            "Epoch 97: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0402 - accuracy: 0.9896 - val_loss: 0.0907 - val_accuracy: 0.9681\n",
            "Epoch 98/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9893\n",
            "Epoch 98: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0441 - accuracy: 0.9891 - val_loss: 0.0875 - val_accuracy: 0.9754\n",
            "Epoch 99/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0465 - accuracy: 0.9863\n",
            "Epoch 99: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0388 - accuracy: 0.9888 - val_loss: 0.0816 - val_accuracy: 0.9754\n",
            "Epoch 100/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0475 - accuracy: 0.9907\n",
            "Epoch 100: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0410 - accuracy: 0.9904 - val_loss: 0.0825 - val_accuracy: 0.9779\n",
            "Epoch 101/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0420 - accuracy: 0.9883\n",
            "Epoch 101: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.0862 - val_accuracy: 0.9681\n",
            "Epoch 102/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0585 - accuracy: 0.9878\n",
            "Epoch 102: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0439 - accuracy: 0.9904 - val_loss: 0.0821 - val_accuracy: 0.9779\n",
            "Epoch 103/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0417 - accuracy: 0.9897\n",
            "Epoch 103: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0358 - accuracy: 0.9907 - val_loss: 0.0805 - val_accuracy: 0.9754\n",
            "Epoch 104/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0419 - accuracy: 0.9883\n",
            "Epoch 104: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0384 - accuracy: 0.9899 - val_loss: 0.0826 - val_accuracy: 0.9754\n",
            "Epoch 105/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0273 - accuracy: 0.9922\n",
            "Epoch 105: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0871 - val_accuracy: 0.9779\n",
            "Epoch 106/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0410 - accuracy: 0.9893\n",
            "Epoch 106: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0346 - accuracy: 0.9904 - val_loss: 0.0822 - val_accuracy: 0.9754\n",
            "Epoch 107/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0308 - accuracy: 0.9927\n",
            "Epoch 107: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.0839 - val_accuracy: 0.9754\n",
            "Epoch 108/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0278 - accuracy: 0.9927\n",
            "Epoch 108: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.0852 - val_accuracy: 0.9754\n",
            "Epoch 109/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0338 - accuracy: 0.9897\n",
            "Epoch 109: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0366 - accuracy: 0.9907 - val_loss: 0.0836 - val_accuracy: 0.9754\n",
            "Epoch 110/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0365 - accuracy: 0.9897\n",
            "Epoch 110: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0362 - accuracy: 0.9899 - val_loss: 0.0852 - val_accuracy: 0.9754\n",
            "Epoch 111/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0373 - accuracy: 0.9897\n",
            "Epoch 111: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0365 - accuracy: 0.9894 - val_loss: 0.0855 - val_accuracy: 0.9754\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9907\n",
            "Epoch 112: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0351 - accuracy: 0.9907 - val_loss: 0.0896 - val_accuracy: 0.9754\n",
            "Epoch 113/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - accuracy: 0.9893\n",
            "Epoch 113: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0380 - accuracy: 0.9894 - val_loss: 0.0831 - val_accuracy: 0.9754\n",
            "Epoch 113: early stopping\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0326 - accuracy: 0.9921\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.9921\n",
            "Model: \"DOS2019-LUCID\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv0 (Conv2D)              (None, 8, 1, 64)          2176      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 64)               0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,241\n",
            "Trainable params: 2,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.2513 - accuracy: 0.4990\n",
            "Epoch 1: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 1s 269ms/step - loss: 1.6989 - accuracy: 0.4947 - val_loss: 2.1520 - val_accuracy: 0.4865\n",
            "Epoch 2/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.1234 - accuracy: 0.5679\n",
            "Epoch 2: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1.7568 - accuracy: 0.6080 - val_loss: 1.3086 - val_accuracy: 0.5725\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.3257 - accuracy: 0.4941\n",
            "Epoch 3: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.4733 - accuracy: 0.6129 - val_loss: 1.6159 - val_accuracy: 0.5160\n",
            "Epoch 4/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.5747 - accuracy: 0.5898\n",
            "Epoch 4: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 1.3864 - accuracy: 0.6536 - val_loss: 1.0382 - val_accuracy: 0.7543\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0316 - accuracy: 0.7007\n",
            "Epoch 5: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.1355 - accuracy: 0.7243 - val_loss: 1.3046 - val_accuracy: 0.7125\n",
            "Epoch 6/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.2686 - accuracy: 0.7314\n",
            "Epoch 6: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.2114 - accuracy: 0.7248 - val_loss: 1.0999 - val_accuracy: 0.7150\n",
            "Epoch 7/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0588 - accuracy: 0.7368\n",
            "Epoch 7: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 1.0969 - accuracy: 0.7486 - val_loss: 1.0981 - val_accuracy: 0.7518\n",
            "Epoch 8/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0820 - accuracy: 0.7646\n",
            "Epoch 8: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1.0465 - accuracy: 0.7472 - val_loss: 1.1056 - val_accuracy: 0.7101\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0619 - accuracy: 0.7251\n",
            "Epoch 9: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1.0645 - accuracy: 0.7259 - val_loss: 1.0325 - val_accuracy: 0.7518\n",
            "Epoch 10/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0315 - accuracy: 0.7603\n",
            "Epoch 10: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.9944 - accuracy: 0.7477 - val_loss: 0.9929 - val_accuracy: 0.7101\n",
            "Epoch 11/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.9555 - accuracy: 0.7183\n",
            "Epoch 11: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.9752 - accuracy: 0.7262 - val_loss: 1.0440 - val_accuracy: 0.7248\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.0165 - accuracy: 0.7666\n",
            "Epoch 12: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1.0023 - accuracy: 0.7589 - val_loss: 0.9946 - val_accuracy: 0.7101\n",
            "Epoch 13/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.9504 - accuracy: 0.7119\n",
            "Epoch 13: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.9321 - accuracy: 0.7218 - val_loss: 0.9094 - val_accuracy: 0.7248\n",
            "Epoch 14/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8901 - accuracy: 0.7646\n",
            "Epoch 14: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.8868 - accuracy: 0.7502 - val_loss: 0.9637 - val_accuracy: 0.7125\n",
            "Epoch 15/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.9272 - accuracy: 0.7378\n",
            "Epoch 15: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.9395 - accuracy: 0.7254 - val_loss: 0.9266 - val_accuracy: 0.7248\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.9084 - accuracy: 0.7529\n",
            "Epoch 16: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.8802 - accuracy: 0.7442 - val_loss: 0.8760 - val_accuracy: 0.7150\n",
            "Epoch 17/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8269 - accuracy: 0.7280\n",
            "Epoch 17: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.8496 - accuracy: 0.7286 - val_loss: 0.9343 - val_accuracy: 0.7150\n",
            "Epoch 18/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8922 - accuracy: 0.7451\n",
            "Epoch 18: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.8844 - accuracy: 0.7349 - val_loss: 0.9135 - val_accuracy: 0.7248\n",
            "Epoch 19/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8899 - accuracy: 0.7373\n",
            "Epoch 19: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.8741 - accuracy: 0.7393 - val_loss: 0.8741 - val_accuracy: 0.7248\n",
            "Epoch 20/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8337 - accuracy: 0.7314\n",
            "Epoch 20: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.8374 - accuracy: 0.7406 - val_loss: 0.9195 - val_accuracy: 0.7248\n",
            "Epoch 21/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8835 - accuracy: 0.7334\n",
            "Epoch 21: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.8949 - accuracy: 0.7333 - val_loss: 0.8958 - val_accuracy: 0.7273\n",
            "Epoch 22/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8766 - accuracy: 0.7407\n",
            "Epoch 22: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.8389 - accuracy: 0.7387 - val_loss: 0.8228 - val_accuracy: 0.7248\n",
            "Epoch 23/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7831 - accuracy: 0.7368\n",
            "Epoch 23: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.8074 - accuracy: 0.7477 - val_loss: 0.9050 - val_accuracy: 0.7248\n",
            "Epoch 24/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8605 - accuracy: 0.7373\n",
            "Epoch 24: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.8462 - accuracy: 0.7336 - val_loss: 0.8684 - val_accuracy: 0.7248\n",
            "Epoch 25/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8266 - accuracy: 0.7617\n",
            "Epoch 25: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.8370 - accuracy: 0.7532 - val_loss: 0.8491 - val_accuracy: 0.7224\n",
            "Epoch 26/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8000 - accuracy: 0.7275\n",
            "Epoch 26: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.7948 - accuracy: 0.7437 - val_loss: 0.8775 - val_accuracy: 0.7273\n",
            "Epoch 27/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8419 - accuracy: 0.7373\n",
            "Epoch 27: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.8529 - accuracy: 0.7439 - val_loss: 0.9173 - val_accuracy: 0.7224\n",
            "Epoch 28/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8680 - accuracy: 0.7222\n",
            "Epoch 28: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.8435 - accuracy: 0.7437 - val_loss: 0.8525 - val_accuracy: 0.7150\n",
            "Epoch 29/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8003 - accuracy: 0.7290\n",
            "Epoch 29: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.8138 - accuracy: 0.7450 - val_loss: 0.8893 - val_accuracy: 0.7297\n",
            "Epoch 30/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8505 - accuracy: 0.7681\n",
            "Epoch 30: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.8404 - accuracy: 0.7469 - val_loss: 0.8547 - val_accuracy: 0.7543\n",
            "Epoch 31/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8246 - accuracy: 0.7690\n",
            "Epoch 31: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.8252 - accuracy: 0.7609 - val_loss: 0.8210 - val_accuracy: 0.7518\n",
            "Epoch 32/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7783 - accuracy: 0.7700\n",
            "Epoch 32: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.7775 - accuracy: 0.7587 - val_loss: 0.8738 - val_accuracy: 0.7248\n",
            "Epoch 33/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8284 - accuracy: 0.7300\n",
            "Epoch 33: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.8340 - accuracy: 0.7486 - val_loss: 0.8702 - val_accuracy: 0.7543\n",
            "Epoch 34/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8443 - accuracy: 0.7720\n",
            "Epoch 34: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.8101 - accuracy: 0.7644 - val_loss: 0.8051 - val_accuracy: 0.7543\n",
            "Epoch 35/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7566 - accuracy: 0.7749\n",
            "Epoch 35: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.7976 - accuracy: 0.8220 - val_loss: 0.9479 - val_accuracy: 0.7150\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8475 - accuracy: 0.7409\n",
            "Epoch 36: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.8475 - accuracy: 0.7409 - val_loss: 0.8528 - val_accuracy: 0.7838\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8385 - accuracy: 0.7658\n",
            "Epoch 37: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.8385 - accuracy: 0.7658 - val_loss: 0.8472 - val_accuracy: 0.7568\n",
            "Epoch 38/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7967 - accuracy: 0.7627\n",
            "Epoch 38: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.7897 - accuracy: 0.7811 - val_loss: 0.8508 - val_accuracy: 0.7297\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8398 - accuracy: 0.7453\n",
            "Epoch 39: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.8398 - accuracy: 0.7453 - val_loss: 0.8716 - val_accuracy: 0.7518\n",
            "Epoch 40/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8405 - accuracy: 0.8921\n",
            "Epoch 40: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.8070 - accuracy: 0.8234 - val_loss: 0.7961 - val_accuracy: 0.7273\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7726 - accuracy: 0.7614\n",
            "Epoch 41: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.7726 - accuracy: 0.7614 - val_loss: 0.8753 - val_accuracy: 0.7543\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8086 - accuracy: 0.7641\n",
            "Epoch 42: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.8086 - accuracy: 0.7641 - val_loss: 0.8327 - val_accuracy: 0.7297\n",
            "Epoch 43/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7826 - accuracy: 0.7671\n",
            "Epoch 43: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.8012 - accuracy: 0.8141 - val_loss: 0.8456 - val_accuracy: 0.7199\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.7595\n",
            "Epoch 44: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 0.7829 - accuracy: 0.7595 - val_loss: 0.8502 - val_accuracy: 0.7543\n",
            "Epoch 45/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7978 - accuracy: 0.7690\n",
            "Epoch 45: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.8219 - accuracy: 0.7598 - val_loss: 0.8838 - val_accuracy: 0.7543\n",
            "Epoch 46/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8432 - accuracy: 0.7612\n",
            "Epoch 46: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.8079 - accuracy: 0.8182 - val_loss: 0.8030 - val_accuracy: 0.7297\n",
            "Epoch 47/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7449 - accuracy: 0.7715\n",
            "Epoch 47: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.7716 - accuracy: 0.7679 - val_loss: 0.8688 - val_accuracy: 0.7322\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8048 - accuracy: 0.7633\n",
            "Epoch 48: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.8048 - accuracy: 0.7633 - val_loss: 0.8313 - val_accuracy: 0.8649\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.7764\n",
            "Epoch 49: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.7965 - accuracy: 0.7764 - val_loss: 0.7924 - val_accuracy: 0.7297\n",
            "Epoch 50/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7344 - accuracy: 0.7681\n",
            "Epoch 50: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.7600 - accuracy: 0.7800 - val_loss: 0.8791 - val_accuracy: 0.7297\n",
            "Epoch 51/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8279 - accuracy: 0.7290\n",
            "Epoch 51: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.8263 - accuracy: 0.7475 - val_loss: 0.8633 - val_accuracy: 0.7838\n",
            "Epoch 52/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8636 - accuracy: 0.7822\n",
            "Epoch 52: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.8210 - accuracy: 0.7587 - val_loss: 0.8228 - val_accuracy: 0.7224\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.7546\n",
            "Epoch 53: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.7933 - accuracy: 0.7546 - val_loss: 0.8817 - val_accuracy: 0.7273\n",
            "Epoch 54/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8367 - accuracy: 0.8682\n",
            "Epoch 54: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.8282 - accuracy: 0.8032 - val_loss: 0.8554 - val_accuracy: 0.7297\n",
            "Epoch 55/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7979 - accuracy: 0.7749\n",
            "Epoch 55: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.8252 - accuracy: 0.7772 - val_loss: 0.8425 - val_accuracy: 0.7273\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7719 - accuracy: 0.7554\n",
            "Epoch 56: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 0.7719 - accuracy: 0.7554 - val_loss: 0.8421 - val_accuracy: 0.7543\n",
            "Epoch 57/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8059 - accuracy: 0.7871\n",
            "Epoch 57: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.8234 - accuracy: 0.7663 - val_loss: 0.8689 - val_accuracy: 0.7297\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7908 - accuracy: 0.7404\n",
            "Epoch 58: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.7908 - accuracy: 0.7404 - val_loss: 0.7850 - val_accuracy: 0.8649\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7756 - accuracy: 0.7742\n",
            "Epoch 59: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.7756 - accuracy: 0.7742 - val_loss: 0.8859 - val_accuracy: 0.7273\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8072 - accuracy: 0.7977\n",
            "Epoch 60: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.8072 - accuracy: 0.7977 - val_loss: 0.8250 - val_accuracy: 0.7543\n",
            "Epoch 61/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7926 - accuracy: 0.8838\n",
            "Epoch 61: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 0.7919 - accuracy: 0.8179 - val_loss: 0.8050 - val_accuracy: 0.7518\n",
            "Epoch 62/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7680 - accuracy: 0.8809\n",
            "Epoch 62: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.7671 - accuracy: 0.8793 - val_loss: 0.8858 - val_accuracy: 0.7224\n",
            "Epoch 63/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8209 - accuracy: 0.7368\n",
            "Epoch 63: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.8386 - accuracy: 0.7423 - val_loss: 0.8649 - val_accuracy: 0.8894\n",
            "Epoch 64/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8495 - accuracy: 0.8916\n",
            "Epoch 64: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.8031 - accuracy: 0.8359 - val_loss: 0.8180 - val_accuracy: 0.7297\n",
            "Epoch 65/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7533 - accuracy: 0.7524\n",
            "Epoch 65: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.7770 - accuracy: 0.8108 - val_loss: 0.8496 - val_accuracy: 0.7838\n",
            "Epoch 66/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8078 - accuracy: 0.8789\n",
            "Epoch 66: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.7991 - accuracy: 0.8239 - val_loss: 0.8199 - val_accuracy: 0.7543\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7711 - accuracy: 0.8174\n",
            "Epoch 67: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.7711 - accuracy: 0.8174 - val_loss: 0.7831 - val_accuracy: 0.7248\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7435 - accuracy: 0.7559\n",
            "Epoch 68: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.7435 - accuracy: 0.7559 - val_loss: 0.8207 - val_accuracy: 0.7248\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8040 - accuracy: 0.8141\n",
            "Epoch 69: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.8040 - accuracy: 0.8141 - val_loss: 0.8749 - val_accuracy: 0.7273\n",
            "Epoch 70/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8191 - accuracy: 0.7324\n",
            "Epoch 70: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.7758 - accuracy: 0.8004 - val_loss: 0.7670 - val_accuracy: 0.8894\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7691 - accuracy: 0.7775\n",
            "Epoch 71: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.7691 - accuracy: 0.7775 - val_loss: 0.8662 - val_accuracy: 0.7273\n",
            "Epoch 72/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8245 - accuracy: 0.7368\n",
            "Epoch 72: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.8046 - accuracy: 0.7985 - val_loss: 0.8194 - val_accuracy: 0.8649\n",
            "Epoch 73/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7953 - accuracy: 0.8574\n",
            "Epoch 73: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.7988 - accuracy: 0.8037 - val_loss: 0.7960 - val_accuracy: 0.7273\n",
            "Epoch 74/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7572 - accuracy: 0.7930\n",
            "Epoch 74: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.7558 - accuracy: 0.8365 - val_loss: 0.8321 - val_accuracy: 0.7518\n",
            "Epoch 75/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7985 - accuracy: 0.7817\n",
            "Epoch 75: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.8053 - accuracy: 0.7658 - val_loss: 0.8284 - val_accuracy: 0.8894\n",
            "Epoch 76/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8076 - accuracy: 0.8857\n",
            "Epoch 76: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.7784 - accuracy: 0.8903 - val_loss: 0.7811 - val_accuracy: 0.7125\n",
            "Epoch 77/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7307 - accuracy: 0.7388\n",
            "Epoch 77: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.7499 - accuracy: 0.7379 - val_loss: 0.8243 - val_accuracy: 0.8894\n",
            "Epoch 78/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7975 - accuracy: 0.8921\n",
            "Epoch 78: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.7902 - accuracy: 0.8864 - val_loss: 0.8558 - val_accuracy: 0.7150\n",
            "Epoch 79/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8090 - accuracy: 0.7324\n",
            "Epoch 79: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.7962 - accuracy: 0.8010 - val_loss: 0.7628 - val_accuracy: 0.8649\n",
            "Epoch 80/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7492 - accuracy: 0.8799\n",
            "Epoch 80: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.7574 - accuracy: 0.8157 - val_loss: 0.8268 - val_accuracy: 0.7494\n",
            "Epoch 81/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7918 - accuracy: 0.8667\n",
            "Epoch 81: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.8210 - accuracy: 0.8741 - val_loss: 0.8581 - val_accuracy: 0.7248\n",
            "Epoch 82/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8208 - accuracy: 0.7261\n",
            "Epoch 82: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.7905 - accuracy: 0.7322 - val_loss: 0.7684 - val_accuracy: 0.8894\n",
            "Epoch 83/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7532 - accuracy: 0.8853\n",
            "Epoch 83: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.7659 - accuracy: 0.8892 - val_loss: 0.8586 - val_accuracy: 0.7273\n",
            "Epoch 84/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8138 - accuracy: 0.7588\n",
            "Epoch 84: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.7898 - accuracy: 0.7786 - val_loss: 0.8052 - val_accuracy: 0.8894\n",
            "Epoch 85/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7770 - accuracy: 0.8882\n",
            "Epoch 85: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.7774 - accuracy: 0.8739 - val_loss: 0.7797 - val_accuracy: 0.7224\n",
            "Epoch 86/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7311 - accuracy: 0.7739\n",
            "Epoch 86: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.7208 - accuracy: 0.8225 - val_loss: 0.8021 - val_accuracy: 0.7740\n",
            "Epoch 87/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7655 - accuracy: 0.8823\n",
            "Epoch 87: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.7885 - accuracy: 0.8204 - val_loss: 0.8342 - val_accuracy: 0.7494\n",
            "Epoch 88/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8004 - accuracy: 0.8618\n",
            "Epoch 88: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.7610 - accuracy: 0.8733 - val_loss: 0.7534 - val_accuracy: 0.7346\n",
            "Epoch 89/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7068 - accuracy: 0.8848\n",
            "Epoch 89: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.7369 - accuracy: 0.8782 - val_loss: 0.8388 - val_accuracy: 0.8894\n",
            "Epoch 90/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8126 - accuracy: 0.8813\n",
            "Epoch 90: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.7779 - accuracy: 0.8389 - val_loss: 0.8045 - val_accuracy: 0.7273\n",
            "Epoch 91/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7675 - accuracy: 0.8291\n",
            "Epoch 91: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.7710 - accuracy: 0.8460 - val_loss: 0.7813 - val_accuracy: 0.7273\n",
            "Epoch 92/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7371 - accuracy: 0.8647\n",
            "Epoch 92: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.7308 - accuracy: 0.8681 - val_loss: 0.8062 - val_accuracy: 0.7568\n",
            "Epoch 93/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7645 - accuracy: 0.8853\n",
            "Epoch 93: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.7895 - accuracy: 0.8812 - val_loss: 0.8337 - val_accuracy: 0.7297\n",
            "Epoch 94/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7936 - accuracy: 0.7480\n",
            "Epoch 94: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.7569 - accuracy: 0.8062 - val_loss: 0.7414 - val_accuracy: 0.8894\n",
            "Epoch 95/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7210 - accuracy: 0.8867\n",
            "Epoch 95: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.7355 - accuracy: 0.8299 - val_loss: 0.8344 - val_accuracy: 0.7297\n",
            "Epoch 96/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7996 - accuracy: 0.7573\n",
            "Epoch 96: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.7832 - accuracy: 0.7999 - val_loss: 0.7945 - val_accuracy: 0.8894\n",
            "Epoch 97/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7604 - accuracy: 0.8833\n",
            "Epoch 97: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.7701 - accuracy: 0.8804 - val_loss: 0.7799 - val_accuracy: 0.7297\n",
            "Epoch 98/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7357 - accuracy: 0.7681\n",
            "Epoch 98: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.7257 - accuracy: 0.8100 - val_loss: 0.8070 - val_accuracy: 0.8649\n",
            "Epoch 99/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7898 - accuracy: 0.8604\n",
            "Epoch 99: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.7937 - accuracy: 0.8591 - val_loss: 0.8502 - val_accuracy: 0.7273\n",
            "Epoch 100/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7962 - accuracy: 0.7520\n",
            "Epoch 100: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.7739 - accuracy: 0.8100 - val_loss: 0.7450 - val_accuracy: 0.8894\n",
            "Epoch 101/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7124 - accuracy: 0.8818\n",
            "Epoch 101: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.7428 - accuracy: 0.8149 - val_loss: 0.8051 - val_accuracy: 0.8894\n",
            "Epoch 102/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7934 - accuracy: 0.8848\n",
            "Epoch 102: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.7676 - accuracy: 0.8892 - val_loss: 0.8186 - val_accuracy: 0.7297\n",
            "Epoch 103/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7732 - accuracy: 0.7383\n",
            "Epoch 103: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.7659 - accuracy: 0.7991 - val_loss: 0.7431 - val_accuracy: 0.8649\n",
            "Epoch 104/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7149 - accuracy: 0.8628\n",
            "Epoch 104: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.7177 - accuracy: 0.8580 - val_loss: 0.8084 - val_accuracy: 0.7224\n",
            "Epoch 104: early stopping\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7668 - accuracy: 0.7464\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7668 - accuracy: 0.7464\n",
            "Model: \"DOS2019-LUCID\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv0 (Conv2D)              (None, 8, 1, 64)          2176      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 64)               0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,241\n",
            "Trainable params: 2,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6939 - accuracy: 0.5083\n",
            "Epoch 1: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 1s 399ms/step - loss: 0.6896 - accuracy: 0.5850 - val_loss: 0.6805 - val_accuracy: 0.6216\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.6729\n",
            "Epoch 2: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.6710 - accuracy: 0.6729 - val_loss: 0.6693 - val_accuracy: 0.6216\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6578 - accuracy: 0.6719\n",
            "Epoch 3: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.6545 - accuracy: 0.6721 - val_loss: 0.6563 - val_accuracy: 0.6192\n",
            "Epoch 4/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6413 - accuracy: 0.6680\n",
            "Epoch 4: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.6367 - accuracy: 0.6738 - val_loss: 0.6437 - val_accuracy: 0.6192\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6224 - accuracy: 0.6743\n",
            "Epoch 5: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.6186 - accuracy: 0.6833 - val_loss: 0.6314 - val_accuracy: 0.6192\n",
            "Epoch 6/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6041 - accuracy: 0.6831\n",
            "Epoch 6: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.6014 - accuracy: 0.6790 - val_loss: 0.6202 - val_accuracy: 0.6216\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7164\n",
            "Epoch 7: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.5847 - accuracy: 0.7164 - val_loss: 0.6070 - val_accuracy: 0.5921\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7649\n",
            "Epoch 8: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.5683 - accuracy: 0.7649 - val_loss: 0.5954 - val_accuracy: 0.7543\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5570 - accuracy: 0.7749\n",
            "Epoch 9: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.5537 - accuracy: 0.7731 - val_loss: 0.5858 - val_accuracy: 0.7518\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.7756\n",
            "Epoch 10: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.5393 - accuracy: 0.7756 - val_loss: 0.5744 - val_accuracy: 0.7518\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.7756\n",
            "Epoch 11: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.5264 - accuracy: 0.7756 - val_loss: 0.5652 - val_accuracy: 0.7518\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5119 - accuracy: 0.7832\n",
            "Epoch 12: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.5141 - accuracy: 0.7756 - val_loss: 0.5564 - val_accuracy: 0.7518\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.7750\n",
            "Epoch 13: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 0.5029 - accuracy: 0.7750 - val_loss: 0.5497 - val_accuracy: 0.7518\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.7710\n",
            "Epoch 14: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.4921 - accuracy: 0.7710 - val_loss: 0.5380 - val_accuracy: 0.7568\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.7895\n",
            "Epoch 15: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.4823 - accuracy: 0.7895 - val_loss: 0.5271 - val_accuracy: 0.7690\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4800 - accuracy: 0.7993\n",
            "Epoch 16: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.4743 - accuracy: 0.7980 - val_loss: 0.5222 - val_accuracy: 0.7690\n",
            "Epoch 17/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4551 - accuracy: 0.8057\n",
            "Epoch 17: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.4639 - accuracy: 0.7936 - val_loss: 0.5181 - val_accuracy: 0.7666\n",
            "Epoch 18/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4553 - accuracy: 0.7964\n",
            "Epoch 18: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.4555 - accuracy: 0.7865 - val_loss: 0.5078 - val_accuracy: 0.7666\n",
            "Epoch 19/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4561 - accuracy: 0.7822\n",
            "Epoch 19: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.4477 - accuracy: 0.7909 - val_loss: 0.4968 - val_accuracy: 0.7666\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7958\n",
            "Epoch 20: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 0.4422 - accuracy: 0.7958 - val_loss: 0.4936 - val_accuracy: 0.7666\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7873\n",
            "Epoch 21: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 0.4339 - accuracy: 0.7873 - val_loss: 0.4887 - val_accuracy: 0.7666\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.7860\n",
            "Epoch 22: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.4261 - accuracy: 0.7860 - val_loss: 0.4761 - val_accuracy: 0.7666\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.8187\n",
            "Epoch 23: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.4233 - accuracy: 0.8187 - val_loss: 0.4708 - val_accuracy: 0.7666\n",
            "Epoch 24/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4127 - accuracy: 0.8149\n",
            "Epoch 24: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.4137 - accuracy: 0.7993 - val_loss: 0.4702 - val_accuracy: 0.7420\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.7846\n",
            "Epoch 25: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.4108 - accuracy: 0.7846 - val_loss: 0.4603 - val_accuracy: 0.7420\n",
            "Epoch 26/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4028 - accuracy: 0.8218\n",
            "Epoch 26: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.4063 - accuracy: 0.8239 - val_loss: 0.4535 - val_accuracy: 0.7568\n",
            "Epoch 27/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3985 - accuracy: 0.8350\n",
            "Epoch 27: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.3984 - accuracy: 0.8351 - val_loss: 0.4522 - val_accuracy: 0.7518\n",
            "Epoch 28/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3870 - accuracy: 0.8232\n",
            "Epoch 28: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.3947 - accuracy: 0.8209 - val_loss: 0.4468 - val_accuracy: 0.7617\n",
            "Epoch 29/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3940 - accuracy: 0.8403\n",
            "Epoch 29: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.3907 - accuracy: 0.8496 - val_loss: 0.4387 - val_accuracy: 0.8624\n",
            "Epoch 30/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3825 - accuracy: 0.8599\n",
            "Epoch 30: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3849 - accuracy: 0.8575 - val_loss: 0.4389 - val_accuracy: 0.7862\n",
            "Epoch 31/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3806 - accuracy: 0.8540\n",
            "Epoch 31: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3792 - accuracy: 0.8564 - val_loss: 0.4305 - val_accuracy: 0.8624\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8703\n",
            "Epoch 32: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.3740 - accuracy: 0.8703 - val_loss: 0.4244 - val_accuracy: 0.8624\n",
            "Epoch 33/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3832 - accuracy: 0.8711\n",
            "Epoch 33: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.3702 - accuracy: 0.8720 - val_loss: 0.4274 - val_accuracy: 0.8624\n",
            "Epoch 34/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3740 - accuracy: 0.8755\n",
            "Epoch 34: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.3664 - accuracy: 0.8755 - val_loss: 0.4153 - val_accuracy: 0.8624\n",
            "Epoch 35/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3462 - accuracy: 0.8794\n",
            "Epoch 35: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.3611 - accuracy: 0.8722 - val_loss: 0.4132 - val_accuracy: 0.8649\n",
            "Epoch 36/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3621 - accuracy: 0.8745\n",
            "Epoch 36: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.3565 - accuracy: 0.8766 - val_loss: 0.4168 - val_accuracy: 0.8771\n",
            "Epoch 37/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3440 - accuracy: 0.8901\n",
            "Epoch 37: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.3494 - accuracy: 0.8829 - val_loss: 0.4010 - val_accuracy: 0.8624\n",
            "Epoch 38/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3543 - accuracy: 0.8706\n",
            "Epoch 38: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3463 - accuracy: 0.8731 - val_loss: 0.4011 - val_accuracy: 0.8649\n",
            "Epoch 39/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3332 - accuracy: 0.8813\n",
            "Epoch 39: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.3424 - accuracy: 0.8807 - val_loss: 0.4018 - val_accuracy: 0.8698\n",
            "Epoch 40/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3336 - accuracy: 0.8945\n",
            "Epoch 40: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.3374 - accuracy: 0.8875 - val_loss: 0.3899 - val_accuracy: 0.8649\n",
            "Epoch 41/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3367 - accuracy: 0.8804\n",
            "Epoch 41: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.3324 - accuracy: 0.8796 - val_loss: 0.3884 - val_accuracy: 0.8649\n",
            "Epoch 42/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3309 - accuracy: 0.8750\n",
            "Epoch 42: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.3274 - accuracy: 0.8900 - val_loss: 0.3923 - val_accuracy: 0.9361\n",
            "Epoch 43/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3186 - accuracy: 0.9175\n",
            "Epoch 43: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.3251 - accuracy: 0.9025 - val_loss: 0.3790 - val_accuracy: 0.8673\n",
            "Epoch 44/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3257 - accuracy: 0.8784\n",
            "Epoch 44: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.3191 - accuracy: 0.8862 - val_loss: 0.3780 - val_accuracy: 0.8698\n",
            "Epoch 45/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3064 - accuracy: 0.8975\n",
            "Epoch 45: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.3133 - accuracy: 0.8957 - val_loss: 0.3772 - val_accuracy: 0.9361\n",
            "Epoch 46/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3228 - accuracy: 0.8950\n",
            "Epoch 46: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.3077 - accuracy: 0.9034 - val_loss: 0.3683 - val_accuracy: 0.8673\n",
            "Epoch 47/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2958 - accuracy: 0.9053\n",
            "Epoch 47: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.3034 - accuracy: 0.8954 - val_loss: 0.3656 - val_accuracy: 0.8845\n",
            "Epoch 48/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2953 - accuracy: 0.9092\n",
            "Epoch 48: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.2982 - accuracy: 0.9162 - val_loss: 0.3648 - val_accuracy: 0.9386\n",
            "Epoch 49/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3031 - accuracy: 0.9146\n",
            "Epoch 49: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.2956 - accuracy: 0.9099 - val_loss: 0.3558 - val_accuracy: 0.8673\n",
            "Epoch 50/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2790 - accuracy: 0.9092\n",
            "Epoch 50: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.2896 - accuracy: 0.8995 - val_loss: 0.3568 - val_accuracy: 0.9386\n",
            "Epoch 51/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2977 - accuracy: 0.9150\n",
            "Epoch 51: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.2881 - accuracy: 0.9282 - val_loss: 0.3548 - val_accuracy: 0.9386\n",
            "Epoch 52/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2886 - accuracy: 0.9272\n",
            "Epoch 52: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2822 - accuracy: 0.9208 - val_loss: 0.3444 - val_accuracy: 0.8919\n",
            "Epoch 53/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2812 - accuracy: 0.8970\n",
            "Epoch 53: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2805 - accuracy: 0.9012 - val_loss: 0.3448 - val_accuracy: 0.9386\n",
            "Epoch 54/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2667 - accuracy: 0.9341\n",
            "Epoch 54: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2735 - accuracy: 0.9369 - val_loss: 0.3432 - val_accuracy: 0.9386\n",
            "Epoch 55/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2632 - accuracy: 0.9526\n",
            "Epoch 55: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2711 - accuracy: 0.9312 - val_loss: 0.3337 - val_accuracy: 0.9091\n",
            "Epoch 56/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2775 - accuracy: 0.9033\n",
            "Epoch 56: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.2636 - accuracy: 0.9200 - val_loss: 0.3354 - val_accuracy: 0.9361\n",
            "Epoch 57/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2523 - accuracy: 0.9521\n",
            "Epoch 57: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2582 - accuracy: 0.9528 - val_loss: 0.3288 - val_accuracy: 0.9631\n",
            "Epoch 58/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2490 - accuracy: 0.9448\n",
            "Epoch 58: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2560 - accuracy: 0.9408 - val_loss: 0.3235 - val_accuracy: 0.9631\n",
            "Epoch 59/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2503 - accuracy: 0.9360\n",
            "Epoch 59: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2508 - accuracy: 0.9388 - val_loss: 0.3234 - val_accuracy: 0.9631\n",
            "Epoch 60/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2425 - accuracy: 0.9585\n",
            "Epoch 60: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.2454 - accuracy: 0.9580 - val_loss: 0.3191 - val_accuracy: 0.9631\n",
            "Epoch 61/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2472 - accuracy: 0.9531\n",
            "Epoch 61: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2428 - accuracy: 0.9541 - val_loss: 0.3132 - val_accuracy: 0.9631\n",
            "Epoch 62/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2441 - accuracy: 0.9399\n",
            "Epoch 62: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.2416 - accuracy: 0.9378 - val_loss: 0.3128 - val_accuracy: 0.9607\n",
            "Epoch 63/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2275 - accuracy: 0.9639\n",
            "Epoch 63: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2357 - accuracy: 0.9569 - val_loss: 0.3115 - val_accuracy: 0.9607\n",
            "Epoch 64/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2440 - accuracy: 0.9556\n",
            "Epoch 64: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2347 - accuracy: 0.9571 - val_loss: 0.3038 - val_accuracy: 0.9631\n",
            "Epoch 65/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2265 - accuracy: 0.9463\n",
            "Epoch 65: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.2302 - accuracy: 0.9511 - val_loss: 0.3043 - val_accuracy: 0.9607\n",
            "Epoch 66/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2232 - accuracy: 0.9609\n",
            "Epoch 66: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2255 - accuracy: 0.9621 - val_loss: 0.3030 - val_accuracy: 0.9607\n",
            "Epoch 67/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2201 - accuracy: 0.9658\n",
            "Epoch 67: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.2211 - accuracy: 0.9659 - val_loss: 0.2964 - val_accuracy: 0.9631\n",
            "Epoch 68/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2171 - accuracy: 0.9668\n",
            "Epoch 68: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2212 - accuracy: 0.9631 - val_loss: 0.2946 - val_accuracy: 0.9607\n",
            "Epoch 69/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2163 - accuracy: 0.9604\n",
            "Epoch 69: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.2161 - accuracy: 0.9621 - val_loss: 0.2946 - val_accuracy: 0.9656\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9612\n",
            "Epoch 70: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.2129 - accuracy: 0.9612 - val_loss: 0.2880 - val_accuracy: 0.9631\n",
            "Epoch 71/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1953 - accuracy: 0.9727\n",
            "Epoch 71: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2092 - accuracy: 0.9689 - val_loss: 0.2863 - val_accuracy: 0.9607\n",
            "Epoch 72/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2011 - accuracy: 0.9688\n",
            "Epoch 72: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.2084 - accuracy: 0.9656 - val_loss: 0.2860 - val_accuracy: 0.9656\n",
            "Epoch 73/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2111 - accuracy: 0.9619\n",
            "Epoch 73: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2050 - accuracy: 0.9637 - val_loss: 0.2792 - val_accuracy: 0.9631\n",
            "Epoch 74/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2008 - accuracy: 0.9653\n",
            "Epoch 74: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2006 - accuracy: 0.9661 - val_loss: 0.2778 - val_accuracy: 0.9656\n",
            "Epoch 75/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2105 - accuracy: 0.9648\n",
            "Epoch 75: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1976 - accuracy: 0.9686 - val_loss: 0.2774 - val_accuracy: 0.9656\n",
            "Epoch 76/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1988 - accuracy: 0.9683\n",
            "Epoch 76: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1936 - accuracy: 0.9705 - val_loss: 0.2725 - val_accuracy: 0.9656\n",
            "Epoch 77/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1971 - accuracy: 0.9712\n",
            "Epoch 77: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.1919 - accuracy: 0.9735 - val_loss: 0.2707 - val_accuracy: 0.9656\n",
            "Epoch 78/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1785 - accuracy: 0.9736\n",
            "Epoch 78: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1894 - accuracy: 0.9694 - val_loss: 0.2688 - val_accuracy: 0.9656\n",
            "Epoch 79/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1879 - accuracy: 0.9741\n",
            "Epoch 79: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1871 - accuracy: 0.9724 - val_loss: 0.2651 - val_accuracy: 0.9656\n",
            "Epoch 80/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1831 - accuracy: 0.9692\n",
            "Epoch 80: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.1849 - accuracy: 0.9689 - val_loss: 0.2635 - val_accuracy: 0.9656\n",
            "Epoch 81/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1749 - accuracy: 0.9712\n",
            "Epoch 81: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1812 - accuracy: 0.9722 - val_loss: 0.2611 - val_accuracy: 0.9656\n",
            "Epoch 82/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1863 - accuracy: 0.9731\n",
            "Epoch 82: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1797 - accuracy: 0.9719 - val_loss: 0.2587 - val_accuracy: 0.9656\n",
            "Epoch 83/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1722 - accuracy: 0.9702\n",
            "Epoch 83: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.1767 - accuracy: 0.9694 - val_loss: 0.2562 - val_accuracy: 0.9656\n",
            "Epoch 84/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1697 - accuracy: 0.9785\n",
            "Epoch 84: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1745 - accuracy: 0.9762 - val_loss: 0.2546 - val_accuracy: 0.9656\n",
            "Epoch 85/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1722 - accuracy: 0.9717\n",
            "Epoch 85: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1713 - accuracy: 0.9716 - val_loss: 0.2528 - val_accuracy: 0.9656\n",
            "Epoch 86/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1761 - accuracy: 0.9712\n",
            "Epoch 86: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.1714 - accuracy: 0.9730 - val_loss: 0.2501 - val_accuracy: 0.9656\n",
            "Epoch 87/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1630 - accuracy: 0.9810\n",
            "Epoch 87: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1662 - accuracy: 0.9782 - val_loss: 0.2485 - val_accuracy: 0.9656\n",
            "Epoch 88/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1619 - accuracy: 0.9736\n",
            "Epoch 88: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1663 - accuracy: 0.9738 - val_loss: 0.2466 - val_accuracy: 0.9656\n",
            "Epoch 89/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1645 - accuracy: 0.9746\n",
            "Epoch 89: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.1637 - accuracy: 0.9738 - val_loss: 0.2443 - val_accuracy: 0.9656\n",
            "Epoch 90/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1715 - accuracy: 0.9741\n",
            "Epoch 90: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1621 - accuracy: 0.9746 - val_loss: 0.2428 - val_accuracy: 0.9656\n",
            "Epoch 91/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1606 - accuracy: 0.9741\n",
            "Epoch 91: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.1599 - accuracy: 0.9757 - val_loss: 0.2414 - val_accuracy: 0.9656\n",
            "Epoch 92/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1504 - accuracy: 0.9771\n",
            "Epoch 92: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1564 - accuracy: 0.9752 - val_loss: 0.2395 - val_accuracy: 0.9656\n",
            "Epoch 93/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1596 - accuracy: 0.9727\n",
            "Epoch 93: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.1564 - accuracy: 0.9752 - val_loss: 0.2371 - val_accuracy: 0.9656\n",
            "Epoch 94/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1493 - accuracy: 0.9805\n",
            "Epoch 94: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1534 - accuracy: 0.9762 - val_loss: 0.2359 - val_accuracy: 0.9656\n",
            "Epoch 95/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1639 - accuracy: 0.9683\n",
            "Epoch 95: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.1518 - accuracy: 0.9752 - val_loss: 0.2335 - val_accuracy: 0.9656\n",
            "Epoch 96/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1522 - accuracy: 0.9805\n",
            "Epoch 96: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1519 - accuracy: 0.9768 - val_loss: 0.2320 - val_accuracy: 0.9656\n",
            "Epoch 97/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1438 - accuracy: 0.9746\n",
            "Epoch 97: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1475 - accuracy: 0.9762 - val_loss: 0.2304 - val_accuracy: 0.9656\n",
            "Epoch 98/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1468 - accuracy: 0.9795\n",
            "Epoch 98: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.1471 - accuracy: 0.9779 - val_loss: 0.2292 - val_accuracy: 0.9656\n",
            "Epoch 99/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1599 - accuracy: 0.9727\n",
            "Epoch 99: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1450 - accuracy: 0.9787 - val_loss: 0.2270 - val_accuracy: 0.9656\n",
            "Epoch 100/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1413 - accuracy: 0.9849\n",
            "Epoch 100: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1436 - accuracy: 0.9801 - val_loss: 0.2252 - val_accuracy: 0.9656\n",
            "Epoch 101/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1376 - accuracy: 0.9780\n",
            "Epoch 101: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.1424 - accuracy: 0.9776 - val_loss: 0.2233 - val_accuracy: 0.9656\n",
            "Epoch 102/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1474 - accuracy: 0.9727\n",
            "Epoch 102: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1396 - accuracy: 0.9795 - val_loss: 0.2220 - val_accuracy: 0.9656\n",
            "Epoch 103/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1469 - accuracy: 0.9756\n",
            "Epoch 103: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1386 - accuracy: 0.9776 - val_loss: 0.2204 - val_accuracy: 0.9656\n",
            "Epoch 104/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1361 - accuracy: 0.9819\n",
            "Epoch 104: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1351 - accuracy: 0.9817 - val_loss: 0.2187 - val_accuracy: 0.9656\n",
            "Epoch 105/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1343 - accuracy: 0.9795\n",
            "Epoch 105: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.1362 - accuracy: 0.9798 - val_loss: 0.2175 - val_accuracy: 0.9656\n",
            "Epoch 106/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1337 - accuracy: 0.9785\n",
            "Epoch 106: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1335 - accuracy: 0.9787 - val_loss: 0.2154 - val_accuracy: 0.9656\n",
            "Epoch 107/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1283 - accuracy: 0.9800\n",
            "Epoch 107: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1316 - accuracy: 0.9803 - val_loss: 0.2137 - val_accuracy: 0.9656\n",
            "Epoch 108/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1301 - accuracy: 0.9819\n",
            "Epoch 108: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.1303 - accuracy: 0.9814 - val_loss: 0.2129 - val_accuracy: 0.9656\n",
            "Epoch 109/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1294 - accuracy: 0.9790\n",
            "Epoch 109: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.1296 - accuracy: 0.9809 - val_loss: 0.2111 - val_accuracy: 0.9656\n",
            "Epoch 110/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1432 - accuracy: 0.9771\n",
            "Epoch 110: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1286 - accuracy: 0.9803 - val_loss: 0.2092 - val_accuracy: 0.9656\n",
            "Epoch 111/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1252 - accuracy: 0.9834\n",
            "Epoch 111: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.1273 - accuracy: 0.9823 - val_loss: 0.2077 - val_accuracy: 0.9656\n",
            "Epoch 112/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1234 - accuracy: 0.9834\n",
            "Epoch 112: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1250 - accuracy: 0.9831 - val_loss: 0.2070 - val_accuracy: 0.9656\n",
            "Epoch 113/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1122 - accuracy: 0.9839\n",
            "Epoch 113: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.1214 - accuracy: 0.9823 - val_loss: 0.2051 - val_accuracy: 0.9656\n",
            "Epoch 114/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1300 - accuracy: 0.9824\n",
            "Epoch 114: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.1228 - accuracy: 0.9803 - val_loss: 0.2038 - val_accuracy: 0.9656\n",
            "Epoch 115/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1253 - accuracy: 0.9814\n",
            "Epoch 115: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1223 - accuracy: 0.9831 - val_loss: 0.2034 - val_accuracy: 0.9656\n",
            "Epoch 116/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1197 - accuracy: 0.9854\n",
            "Epoch 116: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1226 - accuracy: 0.9809 - val_loss: 0.2024 - val_accuracy: 0.9656\n",
            "Epoch 117/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1147 - accuracy: 0.9834\n",
            "Epoch 117: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.1174 - accuracy: 0.9842 - val_loss: 0.2005 - val_accuracy: 0.9656\n",
            "Epoch 118/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1206 - accuracy: 0.9839\n",
            "Epoch 118: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.1173 - accuracy: 0.9839 - val_loss: 0.1994 - val_accuracy: 0.9656\n",
            "Epoch 119/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1198 - accuracy: 0.9805\n",
            "Epoch 119: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.1162 - accuracy: 0.9839 - val_loss: 0.1979 - val_accuracy: 0.9656\n",
            "Epoch 120/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1211 - accuracy: 0.9819\n",
            "Epoch 120: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.1160 - accuracy: 0.9844 - val_loss: 0.1964 - val_accuracy: 0.9656\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9853\n",
            "Epoch 121: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.1132 - accuracy: 0.9853 - val_loss: 0.1952 - val_accuracy: 0.9656\n",
            "Epoch 122/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1159 - accuracy: 0.9819\n",
            "Epoch 122: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.1132 - accuracy: 0.9825 - val_loss: 0.1931 - val_accuracy: 0.9656\n",
            "Epoch 123/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1079 - accuracy: 0.9819\n",
            "Epoch 123: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.1105 - accuracy: 0.9839 - val_loss: 0.1922 - val_accuracy: 0.9681\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9858\n",
            "Epoch 124: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 200ms/step - loss: 0.1102 - accuracy: 0.9858 - val_loss: 0.1915 - val_accuracy: 0.9656\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9842\n",
            "Epoch 125: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.1101 - accuracy: 0.9842 - val_loss: 0.1900 - val_accuracy: 0.9656\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9831\n",
            "Epoch 126: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 198ms/step - loss: 0.1088 - accuracy: 0.9831 - val_loss: 0.1886 - val_accuracy: 0.9656\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9855\n",
            "Epoch 127: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 0.1059 - accuracy: 0.9855 - val_loss: 0.1878 - val_accuracy: 0.9656\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9861\n",
            "Epoch 128: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 257ms/step - loss: 0.1064 - accuracy: 0.9861 - val_loss: 0.1870 - val_accuracy: 0.9631\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9853\n",
            "Epoch 129: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 0.1045 - accuracy: 0.9853 - val_loss: 0.1856 - val_accuracy: 0.9656\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9869\n",
            "Epoch 130: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.1030 - accuracy: 0.9869 - val_loss: 0.1850 - val_accuracy: 0.9656\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9855\n",
            "Epoch 131: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.1025 - accuracy: 0.9855 - val_loss: 0.1843 - val_accuracy: 0.9631\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9863\n",
            "Epoch 132: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 0.1009 - accuracy: 0.9863 - val_loss: 0.1832 - val_accuracy: 0.9631\n",
            "Epoch 133/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1004 - accuracy: 0.9873\n",
            "Epoch 133: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0995 - accuracy: 0.9877 - val_loss: 0.1824 - val_accuracy: 0.9631\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9874\n",
            "Epoch 134: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 0.0986 - accuracy: 0.9874 - val_loss: 0.1814 - val_accuracy: 0.9631\n",
            "Epoch 135/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0948 - accuracy: 0.9844\n",
            "Epoch 135: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0993 - accuracy: 0.9844 - val_loss: 0.1805 - val_accuracy: 0.9656\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9866\n",
            "Epoch 136: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.0990 - accuracy: 0.9866 - val_loss: 0.1800 - val_accuracy: 0.9631\n",
            "Epoch 137/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0994 - accuracy: 0.9868\n",
            "Epoch 137: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0999 - accuracy: 0.9869 - val_loss: 0.1794 - val_accuracy: 0.9631\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9866\n",
            "Epoch 138: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.0971 - accuracy: 0.9866 - val_loss: 0.1785 - val_accuracy: 0.9656\n",
            "Epoch 139/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0954 - accuracy: 0.9873\n",
            "Epoch 139: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.0951 - accuracy: 0.9866 - val_loss: 0.1775 - val_accuracy: 0.9656\n",
            "Epoch 140/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0902 - accuracy: 0.9878\n",
            "Epoch 140: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0935 - accuracy: 0.9877 - val_loss: 0.1769 - val_accuracy: 0.9631\n",
            "Epoch 141/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0953 - accuracy: 0.9873\n",
            "Epoch 141: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.0944 - accuracy: 0.9874 - val_loss: 0.1766 - val_accuracy: 0.9656\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9874\n",
            "Epoch 142: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.0940 - accuracy: 0.9874 - val_loss: 0.1760 - val_accuracy: 0.9631\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9880\n",
            "Epoch 143: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.0911 - accuracy: 0.9880 - val_loss: 0.1748 - val_accuracy: 0.9656\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9883\n",
            "Epoch 144: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 0.0919 - accuracy: 0.9883 - val_loss: 0.1745 - val_accuracy: 0.9656\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9863\n",
            "Epoch 145: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 0.0910 - accuracy: 0.9863 - val_loss: 0.1742 - val_accuracy: 0.9631\n",
            "Epoch 146/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0944 - accuracy: 0.9854\n",
            "Epoch 146: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.0912 - accuracy: 0.9866 - val_loss: 0.1729 - val_accuracy: 0.9656\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9874\n",
            "Epoch 147: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.0906 - accuracy: 0.9874 - val_loss: 0.1721 - val_accuracy: 0.9656\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9894\n",
            "Epoch 148: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 0.0878 - accuracy: 0.9894 - val_loss: 0.1711 - val_accuracy: 0.9656\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9880\n",
            "Epoch 149: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.0879 - accuracy: 0.9880 - val_loss: 0.1704 - val_accuracy: 0.9656\n",
            "Epoch 150/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0896 - accuracy: 0.9888\n",
            "Epoch 150: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.0864 - accuracy: 0.9883 - val_loss: 0.1702 - val_accuracy: 0.9631\n",
            "Epoch 151/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0846 - accuracy: 0.9868\n",
            "Epoch 151: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 0.0871 - accuracy: 0.9872 - val_loss: 0.1692 - val_accuracy: 0.9656\n",
            "Epoch 152/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0951 - accuracy: 0.9854\n",
            "Epoch 152: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0884 - accuracy: 0.9869 - val_loss: 0.1688 - val_accuracy: 0.9656\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9880\n",
            "Epoch 153: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.0855 - accuracy: 0.9880 - val_loss: 0.1684 - val_accuracy: 0.9656\n",
            "Epoch 154/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0875 - accuracy: 0.9883\n",
            "Epoch 154: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0854 - accuracy: 0.9883 - val_loss: 0.1685 - val_accuracy: 0.9631\n",
            "Epoch 155/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0804 - accuracy: 0.9893\n",
            "Epoch 155: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.0837 - accuracy: 0.9883 - val_loss: 0.1675 - val_accuracy: 0.9656\n",
            "Epoch 156/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0830 - accuracy: 0.9893\n",
            "Epoch 156: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 0.0855 - accuracy: 0.9880 - val_loss: 0.1670 - val_accuracy: 0.9656\n",
            "Epoch 157/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0823 - accuracy: 0.9883\n",
            "Epoch 157: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0844 - accuracy: 0.9880 - val_loss: 0.1662 - val_accuracy: 0.9705\n",
            "Epoch 158/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0818 - accuracy: 0.9873\n",
            "Epoch 158: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0812 - accuracy: 0.9883 - val_loss: 0.1656 - val_accuracy: 0.9705\n",
            "Epoch 159/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0820 - accuracy: 0.9873\n",
            "Epoch 159: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0830 - accuracy: 0.9880 - val_loss: 0.1652 - val_accuracy: 0.9705\n",
            "Epoch 160/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0820 - accuracy: 0.9883\n",
            "Epoch 160: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0818 - accuracy: 0.9883 - val_loss: 0.1644 - val_accuracy: 0.9705\n",
            "Epoch 161/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0768 - accuracy: 0.9893\n",
            "Epoch 161: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0798 - accuracy: 0.9885 - val_loss: 0.1636 - val_accuracy: 0.9705\n",
            "Epoch 162/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0787 - accuracy: 0.9902\n",
            "Epoch 162: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0790 - accuracy: 0.9888 - val_loss: 0.1629 - val_accuracy: 0.9705\n",
            "Epoch 163/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0750 - accuracy: 0.9893\n",
            "Epoch 163: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0794 - accuracy: 0.9888 - val_loss: 0.1620 - val_accuracy: 0.9705\n",
            "Epoch 164/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0769 - accuracy: 0.9893\n",
            "Epoch 164: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0775 - accuracy: 0.9888 - val_loss: 0.1615 - val_accuracy: 0.9705\n",
            "Epoch 165/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0794 - accuracy: 0.9878\n",
            "Epoch 165: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0777 - accuracy: 0.9883 - val_loss: 0.1608 - val_accuracy: 0.9705\n",
            "Epoch 166/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0801 - accuracy: 0.9863\n",
            "Epoch 166: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0786 - accuracy: 0.9877 - val_loss: 0.1604 - val_accuracy: 0.9705\n",
            "Epoch 167/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9893\n",
            "Epoch 167: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0778 - accuracy: 0.9891 - val_loss: 0.1604 - val_accuracy: 0.9705\n",
            "Epoch 168/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0743 - accuracy: 0.9893\n",
            "Epoch 168: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0757 - accuracy: 0.9883 - val_loss: 0.1603 - val_accuracy: 0.9705\n",
            "Epoch 169/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0733 - accuracy: 0.9888\n",
            "Epoch 169: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0768 - accuracy: 0.9880 - val_loss: 0.1596 - val_accuracy: 0.9705\n",
            "Epoch 170/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0765 - accuracy: 0.9878\n",
            "Epoch 170: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0779 - accuracy: 0.9874 - val_loss: 0.1592 - val_accuracy: 0.9705\n",
            "Epoch 171/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0810 - accuracy: 0.9868\n",
            "Epoch 171: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0752 - accuracy: 0.9888 - val_loss: 0.1591 - val_accuracy: 0.9705\n",
            "Epoch 172/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0718 - accuracy: 0.9883\n",
            "Epoch 172: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0744 - accuracy: 0.9880 - val_loss: 0.1584 - val_accuracy: 0.9705\n",
            "Epoch 173/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0783 - accuracy: 0.9893\n",
            "Epoch 173: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0751 - accuracy: 0.9899 - val_loss: 0.1577 - val_accuracy: 0.9705\n",
            "Epoch 174/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0724 - accuracy: 0.9888\n",
            "Epoch 174: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0749 - accuracy: 0.9880 - val_loss: 0.1572 - val_accuracy: 0.9705\n",
            "Epoch 175/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0706 - accuracy: 0.9917\n",
            "Epoch 175: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0737 - accuracy: 0.9894 - val_loss: 0.1568 - val_accuracy: 0.9705\n",
            "Epoch 176/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0732 - accuracy: 0.9888\n",
            "Epoch 176: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0735 - accuracy: 0.9885 - val_loss: 0.1563 - val_accuracy: 0.9705\n",
            "Epoch 177/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0690 - accuracy: 0.9907\n",
            "Epoch 177: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0732 - accuracy: 0.9891 - val_loss: 0.1559 - val_accuracy: 0.9705\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9891\n",
            "Epoch 178: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.0740 - accuracy: 0.9891 - val_loss: 0.1557 - val_accuracy: 0.9705\n",
            "Epoch 179/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0694 - accuracy: 0.9893\n",
            "Epoch 179: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0715 - accuracy: 0.9885 - val_loss: 0.1548 - val_accuracy: 0.9705\n",
            "Epoch 180/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0661 - accuracy: 0.9893\n",
            "Epoch 180: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0702 - accuracy: 0.9891 - val_loss: 0.1543 - val_accuracy: 0.9705\n",
            "Epoch 181/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0675 - accuracy: 0.9907\n",
            "Epoch 181: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0728 - accuracy: 0.9891 - val_loss: 0.1542 - val_accuracy: 0.9705\n",
            "Epoch 182/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0660 - accuracy: 0.9897\n",
            "Epoch 182: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0700 - accuracy: 0.9883 - val_loss: 0.1531 - val_accuracy: 0.9705\n",
            "Epoch 183/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0645 - accuracy: 0.9907\n",
            "Epoch 183: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0702 - accuracy: 0.9894 - val_loss: 0.1531 - val_accuracy: 0.9705\n",
            "Epoch 184/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0736 - accuracy: 0.9888\n",
            "Epoch 184: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0711 - accuracy: 0.9888 - val_loss: 0.1530 - val_accuracy: 0.9705\n",
            "Epoch 185/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0612 - accuracy: 0.9912\n",
            "Epoch 185: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0698 - accuracy: 0.9888 - val_loss: 0.1526 - val_accuracy: 0.9705\n",
            "Epoch 186/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0735 - accuracy: 0.9883\n",
            "Epoch 186: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0719 - accuracy: 0.9891 - val_loss: 0.1524 - val_accuracy: 0.9705\n",
            "Epoch 187/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0719 - accuracy: 0.9888\n",
            "Epoch 187: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0705 - accuracy: 0.9888 - val_loss: 0.1523 - val_accuracy: 0.9705\n",
            "Epoch 188/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0649 - accuracy: 0.9907\n",
            "Epoch 188: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0700 - accuracy: 0.9888 - val_loss: 0.1525 - val_accuracy: 0.9705\n",
            "Epoch 189/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0638 - accuracy: 0.9902\n",
            "Epoch 189: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0692 - accuracy: 0.9888 - val_loss: 0.1521 - val_accuracy: 0.9705\n",
            "Epoch 190/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0651 - accuracy: 0.9897\n",
            "Epoch 190: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0686 - accuracy: 0.9885 - val_loss: 0.1517 - val_accuracy: 0.9705\n",
            "Epoch 191/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0624 - accuracy: 0.9897\n",
            "Epoch 191: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0685 - accuracy: 0.9888 - val_loss: 0.1517 - val_accuracy: 0.9705\n",
            "Epoch 192/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0698 - accuracy: 0.9873\n",
            "Epoch 192: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0687 - accuracy: 0.9877 - val_loss: 0.1511 - val_accuracy: 0.9705\n",
            "Epoch 193/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0635 - accuracy: 0.9902\n",
            "Epoch 193: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0679 - accuracy: 0.9888 - val_loss: 0.1505 - val_accuracy: 0.9705\n",
            "Epoch 194/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0750 - accuracy: 0.9878\n",
            "Epoch 194: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0714 - accuracy: 0.9885 - val_loss: 0.1500 - val_accuracy: 0.9705\n",
            "Epoch 195/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0618 - accuracy: 0.9907\n",
            "Epoch 195: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0684 - accuracy: 0.9885 - val_loss: 0.1496 - val_accuracy: 0.9705\n",
            "Epoch 196/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0696 - accuracy: 0.9868\n",
            "Epoch 196: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0647 - accuracy: 0.9888 - val_loss: 0.1487 - val_accuracy: 0.9705\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9891\n",
            "Epoch 197: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0669 - accuracy: 0.9891 - val_loss: 0.1480 - val_accuracy: 0.9705\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9885\n",
            "Epoch 198: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0665 - accuracy: 0.9885 - val_loss: 0.1478 - val_accuracy: 0.9705\n",
            "Epoch 199/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0686 - accuracy: 0.9888\n",
            "Epoch 199: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0690 - accuracy: 0.9885 - val_loss: 0.1471 - val_accuracy: 0.9705\n",
            "Epoch 200/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0648 - accuracy: 0.9897\n",
            "Epoch 200: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0651 - accuracy: 0.9896 - val_loss: 0.1466 - val_accuracy: 0.9705\n",
            "Epoch 201/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0654 - accuracy: 0.9888\n",
            "Epoch 201: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0654 - accuracy: 0.9894 - val_loss: 0.1467 - val_accuracy: 0.9705\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9880\n",
            "Epoch 202: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.0639 - accuracy: 0.9880 - val_loss: 0.1466 - val_accuracy: 0.9705\n",
            "Epoch 203/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0721 - accuracy: 0.9873\n",
            "Epoch 203: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0673 - accuracy: 0.9888 - val_loss: 0.1462 - val_accuracy: 0.9705\n",
            "Epoch 204/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0773 - accuracy: 0.9863\n",
            "Epoch 204: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0663 - accuracy: 0.9894 - val_loss: 0.1459 - val_accuracy: 0.9705\n",
            "Epoch 205/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0577 - accuracy: 0.9912\n",
            "Epoch 205: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0622 - accuracy: 0.9894 - val_loss: 0.1462 - val_accuracy: 0.9705\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9880\n",
            "Epoch 206: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 0.0652 - accuracy: 0.9880 - val_loss: 0.1451 - val_accuracy: 0.9705\n",
            "Epoch 207/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0570 - accuracy: 0.9902\n",
            "Epoch 207: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0628 - accuracy: 0.9880 - val_loss: 0.1444 - val_accuracy: 0.9705\n",
            "Epoch 208/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0732 - accuracy: 0.9863\n",
            "Epoch 208: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0638 - accuracy: 0.9888 - val_loss: 0.1441 - val_accuracy: 0.9705\n",
            "Epoch 209/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0624 - accuracy: 0.9893\n",
            "Epoch 209: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0630 - accuracy: 0.9891 - val_loss: 0.1437 - val_accuracy: 0.9705\n",
            "Epoch 210/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0593 - accuracy: 0.9897\n",
            "Epoch 210: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.0625 - accuracy: 0.9888 - val_loss: 0.1433 - val_accuracy: 0.9705\n",
            "Epoch 211/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0640 - accuracy: 0.9893\n",
            "Epoch 211: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0611 - accuracy: 0.9896 - val_loss: 0.1429 - val_accuracy: 0.9705\n",
            "Epoch 212/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0729 - accuracy: 0.9868\n",
            "Epoch 212: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0606 - accuracy: 0.9894 - val_loss: 0.1429 - val_accuracy: 0.9705\n",
            "Epoch 213/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0696 - accuracy: 0.9863\n",
            "Epoch 213: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0644 - accuracy: 0.9883 - val_loss: 0.1431 - val_accuracy: 0.9705\n",
            "Epoch 214/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0642 - accuracy: 0.9897\n",
            "Epoch 214: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0624 - accuracy: 0.9896 - val_loss: 0.1425 - val_accuracy: 0.9705\n",
            "Epoch 215/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9912\n",
            "Epoch 215: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0597 - accuracy: 0.9896 - val_loss: 0.1427 - val_accuracy: 0.9705\n",
            "Epoch 216/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0646 - accuracy: 0.9873\n",
            "Epoch 216: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0615 - accuracy: 0.9891 - val_loss: 0.1431 - val_accuracy: 0.9705\n",
            "Epoch 217/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0553 - accuracy: 0.9912\n",
            "Epoch 217: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0608 - accuracy: 0.9894 - val_loss: 0.1431 - val_accuracy: 0.9705\n",
            "Epoch 218/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0627 - accuracy: 0.9893\n",
            "Epoch 218: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0613 - accuracy: 0.9894 - val_loss: 0.1428 - val_accuracy: 0.9705\n",
            "Epoch 219/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0528 - accuracy: 0.9917\n",
            "Epoch 219: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0624 - accuracy: 0.9896 - val_loss: 0.1428 - val_accuracy: 0.9705\n",
            "Epoch 220/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0625 - accuracy: 0.9888\n",
            "Epoch 220: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0589 - accuracy: 0.9896 - val_loss: 0.1433 - val_accuracy: 0.9705\n",
            "Epoch 221/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0663 - accuracy: 0.9858\n",
            "Epoch 221: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0629 - accuracy: 0.9877 - val_loss: 0.1432 - val_accuracy: 0.9705\n",
            "Epoch 222/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0684 - accuracy: 0.9854\n",
            "Epoch 222: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.0586 - accuracy: 0.9896 - val_loss: 0.1432 - val_accuracy: 0.9705\n",
            "Epoch 223/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0586 - accuracy: 0.9888\n",
            "Epoch 223: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0586 - accuracy: 0.9891 - val_loss: 0.1423 - val_accuracy: 0.9705\n",
            "Epoch 224/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0688 - accuracy: 0.9868\n",
            "Epoch 224: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0612 - accuracy: 0.9888 - val_loss: 0.1414 - val_accuracy: 0.9705\n",
            "Epoch 225/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0613 - accuracy: 0.9873\n",
            "Epoch 225: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0599 - accuracy: 0.9885 - val_loss: 0.1413 - val_accuracy: 0.9705\n",
            "Epoch 226/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0520 - accuracy: 0.9922\n",
            "Epoch 226: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0589 - accuracy: 0.9891 - val_loss: 0.1405 - val_accuracy: 0.9705\n",
            "Epoch 227/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0471 - accuracy: 0.9917\n",
            "Epoch 227: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0573 - accuracy: 0.9885 - val_loss: 0.1396 - val_accuracy: 0.9705\n",
            "Epoch 228/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9863\n",
            "Epoch 228: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0582 - accuracy: 0.9885 - val_loss: 0.1392 - val_accuracy: 0.9705\n",
            "Epoch 229/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0520 - accuracy: 0.9902\n",
            "Epoch 229: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0581 - accuracy: 0.9894 - val_loss: 0.1390 - val_accuracy: 0.9705\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9888\n",
            "Epoch 230: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0596 - accuracy: 0.9888 - val_loss: 0.1385 - val_accuracy: 0.9705\n",
            "Epoch 231/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0598 - accuracy: 0.9873\n",
            "Epoch 231: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0601 - accuracy: 0.9885 - val_loss: 0.1377 - val_accuracy: 0.9705\n",
            "Epoch 232/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0636 - accuracy: 0.9878\n",
            "Epoch 232: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0593 - accuracy: 0.9896 - val_loss: 0.1374 - val_accuracy: 0.9705\n",
            "Epoch 233/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0609 - accuracy: 0.9917\n",
            "Epoch 233: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0606 - accuracy: 0.9891 - val_loss: 0.1382 - val_accuracy: 0.9705\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9874\n",
            "Epoch 234: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.0585 - accuracy: 0.9874 - val_loss: 0.1381 - val_accuracy: 0.9705\n",
            "Epoch 235/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0618 - accuracy: 0.9873\n",
            "Epoch 235: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0572 - accuracy: 0.9896 - val_loss: 0.1382 - val_accuracy: 0.9705\n",
            "Epoch 236/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0665 - accuracy: 0.9868\n",
            "Epoch 236: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0581 - accuracy: 0.9894 - val_loss: 0.1388 - val_accuracy: 0.9705\n",
            "Epoch 237/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0535 - accuracy: 0.9893\n",
            "Epoch 237: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.0570 - accuracy: 0.9896 - val_loss: 0.1388 - val_accuracy: 0.9705\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9888\n",
            "Epoch 238: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.0587 - accuracy: 0.9888 - val_loss: 0.1379 - val_accuracy: 0.9705\n",
            "Epoch 239/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0598 - accuracy: 0.9878\n",
            "Epoch 239: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0581 - accuracy: 0.9894 - val_loss: 0.1373 - val_accuracy: 0.9705\n",
            "Epoch 240/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0561 - accuracy: 0.9888\n",
            "Epoch 240: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.0552 - accuracy: 0.9885 - val_loss: 0.1372 - val_accuracy: 0.9705\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9877\n",
            "Epoch 241: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0567 - accuracy: 0.9877 - val_loss: 0.1362 - val_accuracy: 0.9705\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9896\n",
            "Epoch 242: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.0556 - accuracy: 0.9896 - val_loss: 0.1359 - val_accuracy: 0.9705\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9891\n",
            "Epoch 243: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 0.0557 - accuracy: 0.9891 - val_loss: 0.1357 - val_accuracy: 0.9705\n",
            "Epoch 244/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9937\n",
            "Epoch 244: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.0544 - accuracy: 0.9896 - val_loss: 0.1354 - val_accuracy: 0.9705\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9874\n",
            "Epoch 245: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.0575 - accuracy: 0.9874 - val_loss: 0.1343 - val_accuracy: 0.9705\n",
            "Epoch 246/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0506 - accuracy: 0.9912\n",
            "Epoch 246: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0557 - accuracy: 0.9894 - val_loss: 0.1339 - val_accuracy: 0.9705\n",
            "Epoch 247/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0642 - accuracy: 0.9868\n",
            "Epoch 247: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0562 - accuracy: 0.9894 - val_loss: 0.1336 - val_accuracy: 0.9705\n",
            "Epoch 248/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0551 - accuracy: 0.9893\n",
            "Epoch 248: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 0.0583 - accuracy: 0.9888 - val_loss: 0.1338 - val_accuracy: 0.9705\n",
            "Epoch 249/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0536 - accuracy: 0.9888\n",
            "Epoch 249: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.0557 - accuracy: 0.9888 - val_loss: 0.1344 - val_accuracy: 0.9705\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9891\n",
            "Epoch 250: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.0548 - accuracy: 0.9891 - val_loss: 0.1345 - val_accuracy: 0.9705\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9899\n",
            "Epoch 251: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.0550 - accuracy: 0.9899 - val_loss: 0.1347 - val_accuracy: 0.9705\n",
            "Epoch 252/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0547 - accuracy: 0.9897\n",
            "Epoch 252: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0533 - accuracy: 0.9894 - val_loss: 0.1347 - val_accuracy: 0.9705\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9891\n",
            "Epoch 253: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.0537 - accuracy: 0.9891 - val_loss: 0.1346 - val_accuracy: 0.9705\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9896\n",
            "Epoch 254: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.0535 - accuracy: 0.9896 - val_loss: 0.1345 - val_accuracy: 0.9705\n",
            "Epoch 255/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0527 - accuracy: 0.9902\n",
            "Epoch 255: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.0522 - accuracy: 0.9902 - val_loss: 0.1345 - val_accuracy: 0.9705\n",
            "Epoch 256/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9907\n",
            "Epoch 256: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.0535 - accuracy: 0.9899 - val_loss: 0.1344 - val_accuracy: 0.9705\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9896\n",
            "Epoch 257: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.0522 - accuracy: 0.9896 - val_loss: 0.1337 - val_accuracy: 0.9705\n",
            "Epoch 257: early stopping\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0582 - accuracy: 0.9899\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0582 - accuracy: 0.9899\n",
            "Model: \"DOS2019-LUCID\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv0 (Conv2D)              (None, 8, 1, 64)          2176      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 64)               0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,241\n",
            "Trainable params: 2,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.1656 - accuracy: 0.5520\n",
            "Epoch 1: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 2s 518ms/step - loss: 1.1656 - accuracy: 0.5520 - val_loss: 0.9457 - val_accuracy: 0.5160\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.9049 - accuracy: 0.5987\n",
            "Epoch 2: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.9049 - accuracy: 0.5987 - val_loss: 0.8202 - val_accuracy: 0.5160\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8159 - accuracy: 0.6040\n",
            "Epoch 3: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.8168 - accuracy: 0.6175 - val_loss: 0.8446 - val_accuracy: 0.5897\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8417 - accuracy: 0.7325\n",
            "Epoch 4: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.8417 - accuracy: 0.7325 - val_loss: 0.8402 - val_accuracy: 0.5799\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.8336 - accuracy: 0.7085\n",
            "Epoch 5: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.8271 - accuracy: 0.7174 - val_loss: 0.8100 - val_accuracy: 0.5700\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.6934\n",
            "Epoch 6: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 0.7924 - accuracy: 0.6934 - val_loss: 0.7774 - val_accuracy: 0.5725\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7624 - accuracy: 0.6552\n",
            "Epoch 7: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 0.7624 - accuracy: 0.6552 - val_loss: 0.7718 - val_accuracy: 0.7125\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7572 - accuracy: 0.7267\n",
            "Epoch 8: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 0.7572 - accuracy: 0.7267 - val_loss: 0.7668 - val_accuracy: 0.7125\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7541 - accuracy: 0.7339\n",
            "Epoch 9: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.7497 - accuracy: 0.7297 - val_loss: 0.7533 - val_accuracy: 0.7125\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7358 - accuracy: 0.7289\n",
            "Epoch 10: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.7358 - accuracy: 0.7289 - val_loss: 0.7437 - val_accuracy: 0.7125\n",
            "Epoch 11/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7281 - accuracy: 0.7222\n",
            "Epoch 11: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.7249 - accuracy: 0.7273 - val_loss: 0.7350 - val_accuracy: 0.7125\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7150 - accuracy: 0.7334\n",
            "Epoch 12: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.7145 - accuracy: 0.7295 - val_loss: 0.7243 - val_accuracy: 0.7125\n",
            "Epoch 13/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7072 - accuracy: 0.7256\n",
            "Epoch 13: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.7026 - accuracy: 0.7289 - val_loss: 0.7166 - val_accuracy: 0.7125\n",
            "Epoch 14/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6943 - accuracy: 0.7334\n",
            "Epoch 14: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.6938 - accuracy: 0.7273 - val_loss: 0.7136 - val_accuracy: 0.7125\n",
            "Epoch 15/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6900 - accuracy: 0.7349\n",
            "Epoch 15: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.6898 - accuracy: 0.7281 - val_loss: 0.7047 - val_accuracy: 0.7125\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6826 - accuracy: 0.7334\n",
            "Epoch 16: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.6805 - accuracy: 0.7303 - val_loss: 0.6959 - val_accuracy: 0.7125\n",
            "Epoch 17/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6673 - accuracy: 0.7310\n",
            "Epoch 17: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.6723 - accuracy: 0.7281 - val_loss: 0.7002 - val_accuracy: 0.7125\n",
            "Epoch 18/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6692 - accuracy: 0.7349\n",
            "Epoch 18: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.6717 - accuracy: 0.7248 - val_loss: 0.6952 - val_accuracy: 0.7101\n",
            "Epoch 19/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6711 - accuracy: 0.7212\n",
            "Epoch 19: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.6633 - accuracy: 0.7262 - val_loss: 0.6826 - val_accuracy: 0.7125\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.7281\n",
            "Epoch 20: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.6573 - accuracy: 0.7281 - val_loss: 0.6842 - val_accuracy: 0.7125\n",
            "Epoch 21/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6590 - accuracy: 0.7290\n",
            "Epoch 21: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6584 - accuracy: 0.7259 - val_loss: 0.6815 - val_accuracy: 0.7101\n",
            "Epoch 22/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6566 - accuracy: 0.7207\n",
            "Epoch 22: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.6516 - accuracy: 0.7245 - val_loss: 0.6770 - val_accuracy: 0.7101\n",
            "Epoch 23/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6511 - accuracy: 0.7222\n",
            "Epoch 23: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.6491 - accuracy: 0.7254 - val_loss: 0.6753 - val_accuracy: 0.7101\n",
            "Epoch 24/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6439 - accuracy: 0.7324\n",
            "Epoch 24: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.6471 - accuracy: 0.7275 - val_loss: 0.6731 - val_accuracy: 0.7101\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6444 - accuracy: 0.7256\n",
            "Epoch 25: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.6444 - accuracy: 0.7256 - val_loss: 0.6724 - val_accuracy: 0.7101\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.7245\n",
            "Epoch 26: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.6425 - accuracy: 0.7245 - val_loss: 0.6688 - val_accuracy: 0.7101\n",
            "Epoch 27/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6442 - accuracy: 0.7173\n",
            "Epoch 27: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6400 - accuracy: 0.7256 - val_loss: 0.6654 - val_accuracy: 0.7101\n",
            "Epoch 28/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6379 - accuracy: 0.7275\n",
            "Epoch 28: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.6377 - accuracy: 0.7273 - val_loss: 0.6662 - val_accuracy: 0.7101\n",
            "Epoch 29/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6347 - accuracy: 0.7241\n",
            "Epoch 29: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.6345 - accuracy: 0.7251 - val_loss: 0.6651 - val_accuracy: 0.7101\n",
            "Epoch 30/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6312 - accuracy: 0.7349\n",
            "Epoch 30: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.6349 - accuracy: 0.7270 - val_loss: 0.6628 - val_accuracy: 0.7101\n",
            "Epoch 31/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6357 - accuracy: 0.7256\n",
            "Epoch 31: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.6341 - accuracy: 0.7281 - val_loss: 0.6571 - val_accuracy: 0.7101\n",
            "Epoch 32/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6216 - accuracy: 0.7383\n",
            "Epoch 32: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6293 - accuracy: 0.7289 - val_loss: 0.6595 - val_accuracy: 0.7101\n",
            "Epoch 33/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6362 - accuracy: 0.7266\n",
            "Epoch 33: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.6311 - accuracy: 0.7270 - val_loss: 0.6579 - val_accuracy: 0.7101\n",
            "Epoch 34/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6313 - accuracy: 0.7241\n",
            "Epoch 34: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.6267 - accuracy: 0.7267 - val_loss: 0.6540 - val_accuracy: 0.7101\n",
            "Epoch 35/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6181 - accuracy: 0.7358\n",
            "Epoch 35: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.6268 - accuracy: 0.7289 - val_loss: 0.6573 - val_accuracy: 0.7101\n",
            "Epoch 36/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6274 - accuracy: 0.7339\n",
            "Epoch 36: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.6281 - accuracy: 0.7270 - val_loss: 0.6548 - val_accuracy: 0.7101\n",
            "Epoch 37/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6185 - accuracy: 0.7314\n",
            "Epoch 37: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.6237 - accuracy: 0.7281 - val_loss: 0.6509 - val_accuracy: 0.7150\n",
            "Epoch 38/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6234 - accuracy: 0.7334\n",
            "Epoch 38: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.6235 - accuracy: 0.7295 - val_loss: 0.6521 - val_accuracy: 0.7101\n",
            "Epoch 39/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6174 - accuracy: 0.7358\n",
            "Epoch 39: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.6217 - accuracy: 0.7275 - val_loss: 0.6514 - val_accuracy: 0.7101\n",
            "Epoch 40/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6165 - accuracy: 0.7373\n",
            "Epoch 40: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.6205 - accuracy: 0.7284 - val_loss: 0.6482 - val_accuracy: 0.7125\n",
            "Epoch 41/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6176 - accuracy: 0.7319\n",
            "Epoch 41: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6191 - accuracy: 0.7303 - val_loss: 0.6466 - val_accuracy: 0.7125\n",
            "Epoch 42/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6238 - accuracy: 0.7246\n",
            "Epoch 42: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.6177 - accuracy: 0.7289 - val_loss: 0.6496 - val_accuracy: 0.7101\n",
            "Epoch 43/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6091 - accuracy: 0.7344\n",
            "Epoch 43: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.6169 - accuracy: 0.7289 - val_loss: 0.6464 - val_accuracy: 0.7125\n",
            "Epoch 44/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6227 - accuracy: 0.7202\n",
            "Epoch 44: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.6148 - accuracy: 0.7292 - val_loss: 0.6474 - val_accuracy: 0.7101\n",
            "Epoch 45/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6065 - accuracy: 0.7383\n",
            "Epoch 45: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6165 - accuracy: 0.7275 - val_loss: 0.6455 - val_accuracy: 0.7125\n",
            "Epoch 46/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6195 - accuracy: 0.7280\n",
            "Epoch 46: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.6144 - accuracy: 0.7297 - val_loss: 0.6424 - val_accuracy: 0.7125\n",
            "Epoch 47/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6014 - accuracy: 0.7407\n",
            "Epoch 47: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6120 - accuracy: 0.7305 - val_loss: 0.6449 - val_accuracy: 0.7125\n",
            "Epoch 48/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6127 - accuracy: 0.7295\n",
            "Epoch 48: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.6123 - accuracy: 0.7289 - val_loss: 0.6429 - val_accuracy: 0.7125\n",
            "Epoch 49/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6216 - accuracy: 0.7192\n",
            "Epoch 49: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.6113 - accuracy: 0.7300 - val_loss: 0.6392 - val_accuracy: 0.7125\n",
            "Epoch 50/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6026 - accuracy: 0.7344\n",
            "Epoch 50: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.6105 - accuracy: 0.7308 - val_loss: 0.6433 - val_accuracy: 0.7125\n",
            "Epoch 51/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6162 - accuracy: 0.7236\n",
            "Epoch 51: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.6098 - accuracy: 0.7278 - val_loss: 0.6426 - val_accuracy: 0.7125\n",
            "Epoch 52/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6086 - accuracy: 0.7300\n",
            "Epoch 52: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.6087 - accuracy: 0.7286 - val_loss: 0.6368 - val_accuracy: 0.7174\n",
            "Epoch 53/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6102 - accuracy: 0.7275\n",
            "Epoch 53: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6088 - accuracy: 0.7305 - val_loss: 0.6387 - val_accuracy: 0.7125\n",
            "Epoch 54/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6024 - accuracy: 0.7349\n",
            "Epoch 54: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.6069 - accuracy: 0.7297 - val_loss: 0.6412 - val_accuracy: 0.7125\n",
            "Epoch 55/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5926 - accuracy: 0.7427\n",
            "Epoch 55: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.6067 - accuracy: 0.7286 - val_loss: 0.6378 - val_accuracy: 0.7125\n",
            "Epoch 56/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6156 - accuracy: 0.7178\n",
            "Epoch 56: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.6066 - accuracy: 0.7297 - val_loss: 0.6379 - val_accuracy: 0.7125\n",
            "Epoch 57/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6071 - accuracy: 0.7275\n",
            "Epoch 57: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.6054 - accuracy: 0.7305 - val_loss: 0.6364 - val_accuracy: 0.7125\n",
            "Epoch 58/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5938 - accuracy: 0.7432\n",
            "Epoch 58: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.6050 - accuracy: 0.7295 - val_loss: 0.6350 - val_accuracy: 0.7125\n",
            "Epoch 59/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6026 - accuracy: 0.7305\n",
            "Epoch 59: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.6020 - accuracy: 0.7305 - val_loss: 0.6355 - val_accuracy: 0.7150\n",
            "Epoch 60/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6085 - accuracy: 0.7227\n",
            "Epoch 60: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6042 - accuracy: 0.7303 - val_loss: 0.6394 - val_accuracy: 0.7125\n",
            "Epoch 61/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6030 - accuracy: 0.7339\n",
            "Epoch 61: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.6016 - accuracy: 0.7292 - val_loss: 0.6322 - val_accuracy: 0.7125\n",
            "Epoch 62/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5945 - accuracy: 0.7368\n",
            "Epoch 62: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.6010 - accuracy: 0.7319 - val_loss: 0.6335 - val_accuracy: 0.7150\n",
            "Epoch 63/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5911 - accuracy: 0.7476\n",
            "Epoch 63: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.6012 - accuracy: 0.7303 - val_loss: 0.6389 - val_accuracy: 0.7125\n",
            "Epoch 64/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6044 - accuracy: 0.7285\n",
            "Epoch 64: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.6017 - accuracy: 0.7286 - val_loss: 0.6314 - val_accuracy: 0.7125\n",
            "Epoch 65/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5930 - accuracy: 0.7349\n",
            "Epoch 65: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5994 - accuracy: 0.7308 - val_loss: 0.6332 - val_accuracy: 0.7125\n",
            "Epoch 66/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5953 - accuracy: 0.7368\n",
            "Epoch 66: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5999 - accuracy: 0.7305 - val_loss: 0.6345 - val_accuracy: 0.7125\n",
            "Epoch 67/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6049 - accuracy: 0.7192\n",
            "Epoch 67: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5978 - accuracy: 0.7295 - val_loss: 0.6317 - val_accuracy: 0.7125\n",
            "Epoch 68/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5969 - accuracy: 0.7314\n",
            "Epoch 68: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5981 - accuracy: 0.7374 - val_loss: 0.6303 - val_accuracy: 0.7150\n",
            "Epoch 69/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5892 - accuracy: 0.7383\n",
            "Epoch 69: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5952 - accuracy: 0.7333 - val_loss: 0.6339 - val_accuracy: 0.7125\n",
            "Epoch 70/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6014 - accuracy: 0.7217\n",
            "Epoch 70: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5970 - accuracy: 0.7286 - val_loss: 0.6335 - val_accuracy: 0.7125\n",
            "Epoch 71/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5898 - accuracy: 0.7314\n",
            "Epoch 71: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5968 - accuracy: 0.7368 - val_loss: 0.6280 - val_accuracy: 0.7174\n",
            "Epoch 72/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5961 - accuracy: 0.7524\n",
            "Epoch 72: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5969 - accuracy: 0.7483 - val_loss: 0.6306 - val_accuracy: 0.7125\n",
            "Epoch 73/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5939 - accuracy: 0.7314\n",
            "Epoch 73: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5947 - accuracy: 0.7303 - val_loss: 0.6309 - val_accuracy: 0.7125\n",
            "Epoch 74/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5919 - accuracy: 0.7329\n",
            "Epoch 74: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5941 - accuracy: 0.7385 - val_loss: 0.6283 - val_accuracy: 0.7150\n",
            "Epoch 75/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5967 - accuracy: 0.7534\n",
            "Epoch 75: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5930 - accuracy: 0.7532 - val_loss: 0.6310 - val_accuracy: 0.7125\n",
            "Epoch 76/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5966 - accuracy: 0.7319\n",
            "Epoch 76: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.5942 - accuracy: 0.7325 - val_loss: 0.6290 - val_accuracy: 0.7125\n",
            "Epoch 77/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5896 - accuracy: 0.7510\n",
            "Epoch 77: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5919 - accuracy: 0.7445 - val_loss: 0.6289 - val_accuracy: 0.7199\n",
            "Epoch 78/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5947 - accuracy: 0.7368\n",
            "Epoch 78: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5937 - accuracy: 0.7548 - val_loss: 0.6273 - val_accuracy: 0.7174\n",
            "Epoch 79/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5936 - accuracy: 0.7529\n",
            "Epoch 79: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5897 - accuracy: 0.7447 - val_loss: 0.6312 - val_accuracy: 0.7125\n",
            "Epoch 80/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5946 - accuracy: 0.7305\n",
            "Epoch 80: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5923 - accuracy: 0.7346 - val_loss: 0.6278 - val_accuracy: 0.7445\n",
            "Epoch 81/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5820 - accuracy: 0.7642\n",
            "Epoch 81: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5900 - accuracy: 0.7584 - val_loss: 0.6240 - val_accuracy: 0.7445\n",
            "Epoch 82/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5951 - accuracy: 0.7529\n",
            "Epoch 82: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5894 - accuracy: 0.7538 - val_loss: 0.6300 - val_accuracy: 0.7125\n",
            "Epoch 83/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5805 - accuracy: 0.7412\n",
            "Epoch 83: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5858 - accuracy: 0.7366 - val_loss: 0.6260 - val_accuracy: 0.7445\n",
            "Epoch 84/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5974 - accuracy: 0.7466\n",
            "Epoch 84: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5892 - accuracy: 0.7568 - val_loss: 0.6239 - val_accuracy: 0.7445\n",
            "Epoch 85/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5902 - accuracy: 0.7568\n",
            "Epoch 85: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5877 - accuracy: 0.7573 - val_loss: 0.6307 - val_accuracy: 0.7150\n",
            "Epoch 86/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5895 - accuracy: 0.7417\n",
            "Epoch 86: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5875 - accuracy: 0.7497 - val_loss: 0.6250 - val_accuracy: 0.7445\n",
            "Epoch 87/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5875 - accuracy: 0.7520\n",
            "Epoch 87: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5875 - accuracy: 0.7557 - val_loss: 0.6231 - val_accuracy: 0.7445\n",
            "Epoch 88/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5878 - accuracy: 0.7593\n",
            "Epoch 88: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.5878 - accuracy: 0.7589 - val_loss: 0.6252 - val_accuracy: 0.7199\n",
            "Epoch 89/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5805 - accuracy: 0.7637\n",
            "Epoch 89: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5834 - accuracy: 0.7562 - val_loss: 0.6243 - val_accuracy: 0.7445\n",
            "Epoch 90/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5874 - accuracy: 0.7622\n",
            "Epoch 90: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5838 - accuracy: 0.7598 - val_loss: 0.6233 - val_accuracy: 0.7445\n",
            "Epoch 91/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5895 - accuracy: 0.7539\n",
            "Epoch 91: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5842 - accuracy: 0.7595 - val_loss: 0.6241 - val_accuracy: 0.7445\n",
            "Epoch 92/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5819 - accuracy: 0.7559\n",
            "Epoch 92: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5834 - accuracy: 0.7565 - val_loss: 0.6237 - val_accuracy: 0.7445\n",
            "Epoch 93/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5817 - accuracy: 0.7563\n",
            "Epoch 93: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.5813 - accuracy: 0.7598 - val_loss: 0.6226 - val_accuracy: 0.7445\n",
            "Epoch 94/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5868 - accuracy: 0.7500\n",
            "Epoch 94: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.5806 - accuracy: 0.7595 - val_loss: 0.6221 - val_accuracy: 0.7445\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.7603\n",
            "Epoch 95: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.5798 - accuracy: 0.7603 - val_loss: 0.6219 - val_accuracy: 0.7445\n",
            "Epoch 96/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5845 - accuracy: 0.7573\n",
            "Epoch 96: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.5829 - accuracy: 0.7606 - val_loss: 0.6196 - val_accuracy: 0.7445\n",
            "Epoch 97/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5661 - accuracy: 0.7725\n",
            "Epoch 97: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.5789 - accuracy: 0.7660 - val_loss: 0.6203 - val_accuracy: 0.7445\n",
            "Epoch 98/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5800 - accuracy: 0.7695\n",
            "Epoch 98: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.5791 - accuracy: 0.7652 - val_loss: 0.6228 - val_accuracy: 0.7445\n",
            "Epoch 99/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5834 - accuracy: 0.7583\n",
            "Epoch 99: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 0.5786 - accuracy: 0.7644 - val_loss: 0.6178 - val_accuracy: 0.7445\n",
            "Epoch 100/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5666 - accuracy: 0.7817\n",
            "Epoch 100: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.5771 - accuracy: 0.7628 - val_loss: 0.6203 - val_accuracy: 0.7445\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.7693\n",
            "Epoch 101: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.5761 - accuracy: 0.7693 - val_loss: 0.6153 - val_accuracy: 0.7469\n",
            "Epoch 102/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5836 - accuracy: 0.7637\n",
            "Epoch 102: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.5742 - accuracy: 0.7701 - val_loss: 0.6173 - val_accuracy: 0.7445\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5735 - accuracy: 0.7699\n",
            "Epoch 103: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 0.5735 - accuracy: 0.7699 - val_loss: 0.6180 - val_accuracy: 0.7445\n",
            "Epoch 104/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5719 - accuracy: 0.7642\n",
            "Epoch 104: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.5734 - accuracy: 0.7671 - val_loss: 0.6165 - val_accuracy: 0.7518\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7715\n",
            "Epoch 105: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.5750 - accuracy: 0.7715 - val_loss: 0.6179 - val_accuracy: 0.7518\n",
            "Epoch 106/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5726 - accuracy: 0.7710\n",
            "Epoch 106: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.5719 - accuracy: 0.7693 - val_loss: 0.6136 - val_accuracy: 0.7518\n",
            "Epoch 107/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5669 - accuracy: 0.7720\n",
            "Epoch 107: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5689 - accuracy: 0.7720 - val_loss: 0.6142 - val_accuracy: 0.7543\n",
            "Epoch 108/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5711 - accuracy: 0.7720\n",
            "Epoch 108: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.5712 - accuracy: 0.7712 - val_loss: 0.6144 - val_accuracy: 0.7518\n",
            "Epoch 109/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5655 - accuracy: 0.7715\n",
            "Epoch 109: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.5669 - accuracy: 0.7720 - val_loss: 0.6139 - val_accuracy: 0.7518\n",
            "Epoch 110/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5825 - accuracy: 0.7686\n",
            "Epoch 110: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.5697 - accuracy: 0.7682 - val_loss: 0.6137 - val_accuracy: 0.7518\n",
            "Epoch 111/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5774 - accuracy: 0.7568\n",
            "Epoch 111: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.5671 - accuracy: 0.7726 - val_loss: 0.6077 - val_accuracy: 0.7568\n",
            "Epoch 112/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5653 - accuracy: 0.7734\n",
            "Epoch 112: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.5683 - accuracy: 0.7693 - val_loss: 0.6153 - val_accuracy: 0.7518\n",
            "Epoch 113/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5625 - accuracy: 0.7651\n",
            "Epoch 113: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 0.5644 - accuracy: 0.7682 - val_loss: 0.6100 - val_accuracy: 0.7543\n",
            "Epoch 114/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5712 - accuracy: 0.7725\n",
            "Epoch 114: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.5651 - accuracy: 0.7671 - val_loss: 0.6080 - val_accuracy: 0.7543\n",
            "Epoch 115/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5738 - accuracy: 0.7554\n",
            "Epoch 115: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.5619 - accuracy: 0.7715 - val_loss: 0.6091 - val_accuracy: 0.7543\n",
            "Epoch 116/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5665 - accuracy: 0.7646\n",
            "Epoch 116: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.5648 - accuracy: 0.7655 - val_loss: 0.6107 - val_accuracy: 0.7543\n",
            "Epoch 117/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5599 - accuracy: 0.7690\n",
            "Epoch 117: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.5630 - accuracy: 0.7682 - val_loss: 0.6051 - val_accuracy: 0.7568\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.7666\n",
            "Epoch 118: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.5629 - accuracy: 0.7666 - val_loss: 0.6085 - val_accuracy: 0.7543\n",
            "Epoch 119/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5649 - accuracy: 0.7642\n",
            "Epoch 119: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.5600 - accuracy: 0.7693 - val_loss: 0.6070 - val_accuracy: 0.7568\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5621 - accuracy: 0.7679\n",
            "Epoch 120: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.5621 - accuracy: 0.7679 - val_loss: 0.6050 - val_accuracy: 0.7568\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.7669\n",
            "Epoch 121: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 0.5607 - accuracy: 0.7669 - val_loss: 0.6075 - val_accuracy: 0.7543\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.7690\n",
            "Epoch 122: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.5573 - accuracy: 0.7690 - val_loss: 0.6049 - val_accuracy: 0.7568\n",
            "Epoch 123/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5563 - accuracy: 0.7642\n",
            "Epoch 123: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.5540 - accuracy: 0.7704 - val_loss: 0.6006 - val_accuracy: 0.7543\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.7674\n",
            "Epoch 124: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.5550 - accuracy: 0.7674 - val_loss: 0.6055 - val_accuracy: 0.7568\n",
            "Epoch 125/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5557 - accuracy: 0.7690\n",
            "Epoch 125: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.5579 - accuracy: 0.7660 - val_loss: 0.6041 - val_accuracy: 0.7568\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.7701\n",
            "Epoch 126: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 0.5558 - accuracy: 0.7701 - val_loss: 0.6000 - val_accuracy: 0.7543\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5533 - accuracy: 0.7688\n",
            "Epoch 127: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.5533 - accuracy: 0.7688 - val_loss: 0.6029 - val_accuracy: 0.7568\n",
            "Epoch 128/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5585 - accuracy: 0.7720\n",
            "Epoch 128: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.5527 - accuracy: 0.7704 - val_loss: 0.6028 - val_accuracy: 0.7568\n",
            "Epoch 129/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5576 - accuracy: 0.7710\n",
            "Epoch 129: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5524 - accuracy: 0.7688 - val_loss: 0.6004 - val_accuracy: 0.7568\n",
            "Epoch 130/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5485 - accuracy: 0.7720\n",
            "Epoch 130: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5519 - accuracy: 0.7690 - val_loss: 0.5985 - val_accuracy: 0.7543\n",
            "Epoch 131/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5528 - accuracy: 0.7632\n",
            "Epoch 131: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5522 - accuracy: 0.7682 - val_loss: 0.5978 - val_accuracy: 0.7543\n",
            "Epoch 132/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5558 - accuracy: 0.7690\n",
            "Epoch 132: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5517 - accuracy: 0.7699 - val_loss: 0.6012 - val_accuracy: 0.7568\n",
            "Epoch 133/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5575 - accuracy: 0.7666\n",
            "Epoch 133: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5537 - accuracy: 0.7652 - val_loss: 0.5976 - val_accuracy: 0.7543\n",
            "Epoch 134/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5500 - accuracy: 0.7715\n",
            "Epoch 134: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5501 - accuracy: 0.7682 - val_loss: 0.5971 - val_accuracy: 0.7543\n",
            "Epoch 135/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5423 - accuracy: 0.7769\n",
            "Epoch 135: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5543 - accuracy: 0.7658 - val_loss: 0.5998 - val_accuracy: 0.7543\n",
            "Epoch 136/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5403 - accuracy: 0.7773\n",
            "Epoch 136: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5509 - accuracy: 0.7707 - val_loss: 0.5946 - val_accuracy: 0.7543\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.7690\n",
            "Epoch 137: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.5475 - accuracy: 0.7690 - val_loss: 0.5992 - val_accuracy: 0.7568\n",
            "Epoch 138/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5489 - accuracy: 0.7739\n",
            "Epoch 138: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.5483 - accuracy: 0.7701 - val_loss: 0.5945 - val_accuracy: 0.7543\n",
            "Epoch 139/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5461 - accuracy: 0.7700\n",
            "Epoch 139: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5459 - accuracy: 0.7688 - val_loss: 0.5931 - val_accuracy: 0.7543\n",
            "Epoch 140/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5579 - accuracy: 0.7603\n",
            "Epoch 140: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5506 - accuracy: 0.7658 - val_loss: 0.5967 - val_accuracy: 0.7543\n",
            "Epoch 141/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5450 - accuracy: 0.7729\n",
            "Epoch 141: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.5493 - accuracy: 0.7677 - val_loss: 0.5920 - val_accuracy: 0.7543\n",
            "Epoch 142/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5515 - accuracy: 0.7744\n",
            "Epoch 142: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5478 - accuracy: 0.7704 - val_loss: 0.5943 - val_accuracy: 0.7543\n",
            "Epoch 143/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5443 - accuracy: 0.7656\n",
            "Epoch 143: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5475 - accuracy: 0.7688 - val_loss: 0.5908 - val_accuracy: 0.7543\n",
            "Epoch 144/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5514 - accuracy: 0.7725\n",
            "Epoch 144: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5477 - accuracy: 0.7712 - val_loss: 0.5952 - val_accuracy: 0.7543\n",
            "Epoch 145/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5502 - accuracy: 0.7622\n",
            "Epoch 145: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5463 - accuracy: 0.7696 - val_loss: 0.5914 - val_accuracy: 0.7543\n",
            "Epoch 146/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5505 - accuracy: 0.7725\n",
            "Epoch 146: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.5481 - accuracy: 0.7674 - val_loss: 0.5907 - val_accuracy: 0.7543\n",
            "Epoch 147/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5503 - accuracy: 0.7627\n",
            "Epoch 147: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.5437 - accuracy: 0.7710 - val_loss: 0.5922 - val_accuracy: 0.7543\n",
            "Epoch 148/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5476 - accuracy: 0.7720\n",
            "Epoch 148: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5451 - accuracy: 0.7682 - val_loss: 0.5889 - val_accuracy: 0.7543\n",
            "Epoch 149/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5438 - accuracy: 0.7632\n",
            "Epoch 149: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.5456 - accuracy: 0.7644 - val_loss: 0.5899 - val_accuracy: 0.7543\n",
            "Epoch 150/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5438 - accuracy: 0.7646\n",
            "Epoch 150: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5427 - accuracy: 0.7704 - val_loss: 0.5944 - val_accuracy: 0.7543\n",
            "Epoch 151/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5552 - accuracy: 0.7529\n",
            "Epoch 151: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5456 - accuracy: 0.7674 - val_loss: 0.5880 - val_accuracy: 0.7543\n",
            "Epoch 152/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5581 - accuracy: 0.7627\n",
            "Epoch 152: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5421 - accuracy: 0.7690 - val_loss: 0.5889 - val_accuracy: 0.7543\n",
            "Epoch 153/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5529 - accuracy: 0.7593\n",
            "Epoch 153: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5453 - accuracy: 0.7666 - val_loss: 0.5873 - val_accuracy: 0.7543\n",
            "Epoch 154/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5415 - accuracy: 0.7661\n",
            "Epoch 154: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5413 - accuracy: 0.7699 - val_loss: 0.5907 - val_accuracy: 0.7543\n",
            "Epoch 155/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5478 - accuracy: 0.7554\n",
            "Epoch 155: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5428 - accuracy: 0.7652 - val_loss: 0.5892 - val_accuracy: 0.7543\n",
            "Epoch 156/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5441 - accuracy: 0.7695\n",
            "Epoch 156: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5438 - accuracy: 0.7669 - val_loss: 0.5845 - val_accuracy: 0.7543\n",
            "Epoch 157/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5420 - accuracy: 0.7676\n",
            "Epoch 157: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.5414 - accuracy: 0.7688 - val_loss: 0.5876 - val_accuracy: 0.7543\n",
            "Epoch 158/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5534 - accuracy: 0.7588\n",
            "Epoch 158: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5427 - accuracy: 0.7701 - val_loss: 0.5875 - val_accuracy: 0.7543\n",
            "Epoch 159/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5417 - accuracy: 0.7705\n",
            "Epoch 159: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5403 - accuracy: 0.7712 - val_loss: 0.5863 - val_accuracy: 0.7543\n",
            "Epoch 160/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5458 - accuracy: 0.7607\n",
            "Epoch 160: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5407 - accuracy: 0.7679 - val_loss: 0.5859 - val_accuracy: 0.7543\n",
            "Epoch 161/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5462 - accuracy: 0.7646\n",
            "Epoch 161: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5430 - accuracy: 0.7688 - val_loss: 0.5850 - val_accuracy: 0.7543\n",
            "Epoch 162/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5354 - accuracy: 0.7710\n",
            "Epoch 162: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5428 - accuracy: 0.7677 - val_loss: 0.5884 - val_accuracy: 0.7543\n",
            "Epoch 163/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5421 - accuracy: 0.7632\n",
            "Epoch 163: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5404 - accuracy: 0.7666 - val_loss: 0.5831 - val_accuracy: 0.7543\n",
            "Epoch 164/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5353 - accuracy: 0.7764\n",
            "Epoch 164: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.5406 - accuracy: 0.7682 - val_loss: 0.5854 - val_accuracy: 0.7543\n",
            "Epoch 165/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5457 - accuracy: 0.7666\n",
            "Epoch 165: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5409 - accuracy: 0.7660 - val_loss: 0.5829 - val_accuracy: 0.7543\n",
            "Epoch 166/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5337 - accuracy: 0.7749\n",
            "Epoch 166: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5376 - accuracy: 0.7710 - val_loss: 0.5806 - val_accuracy: 0.7543\n",
            "Epoch 167/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5269 - accuracy: 0.7798\n",
            "Epoch 167: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.5343 - accuracy: 0.7715 - val_loss: 0.5866 - val_accuracy: 0.7543\n",
            "Epoch 168/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5381 - accuracy: 0.7729\n",
            "Epoch 168: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.5401 - accuracy: 0.7707 - val_loss: 0.5816 - val_accuracy: 0.7543\n",
            "Epoch 169/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5362 - accuracy: 0.7725\n",
            "Epoch 169: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5372 - accuracy: 0.7710 - val_loss: 0.5810 - val_accuracy: 0.7543\n",
            "Epoch 170/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5363 - accuracy: 0.7759\n",
            "Epoch 170: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.5404 - accuracy: 0.7685 - val_loss: 0.5832 - val_accuracy: 0.7543\n",
            "Epoch 171/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5460 - accuracy: 0.7681\n",
            "Epoch 171: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5384 - accuracy: 0.7707 - val_loss: 0.5826 - val_accuracy: 0.7543\n",
            "Epoch 172/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5330 - accuracy: 0.7725\n",
            "Epoch 172: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.5350 - accuracy: 0.7715 - val_loss: 0.5829 - val_accuracy: 0.7543\n",
            "Epoch 173/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5472 - accuracy: 0.7588\n",
            "Epoch 173: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5372 - accuracy: 0.7671 - val_loss: 0.5800 - val_accuracy: 0.7543\n",
            "Epoch 174/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5386 - accuracy: 0.7607\n",
            "Epoch 174: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5329 - accuracy: 0.7701 - val_loss: 0.5809 - val_accuracy: 0.7543\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5362 - accuracy: 0.7666\n",
            "Epoch 175: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5362 - accuracy: 0.7666 - val_loss: 0.5813 - val_accuracy: 0.7543\n",
            "Epoch 176/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5408 - accuracy: 0.7642\n",
            "Epoch 176: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.5371 - accuracy: 0.7682 - val_loss: 0.5793 - val_accuracy: 0.7543\n",
            "Epoch 177/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5326 - accuracy: 0.7681\n",
            "Epoch 177: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5374 - accuracy: 0.7677 - val_loss: 0.5785 - val_accuracy: 0.7543\n",
            "Epoch 178/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5416 - accuracy: 0.7573\n",
            "Epoch 178: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.5359 - accuracy: 0.7712 - val_loss: 0.5819 - val_accuracy: 0.7543\n",
            "Epoch 179/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5397 - accuracy: 0.7715\n",
            "Epoch 179: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.5369 - accuracy: 0.7644 - val_loss: 0.5793 - val_accuracy: 0.7543\n",
            "Epoch 180/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5328 - accuracy: 0.7734\n",
            "Epoch 180: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5346 - accuracy: 0.8209 - val_loss: 0.5768 - val_accuracy: 0.7543\n",
            "Epoch 181/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5326 - accuracy: 0.7739\n",
            "Epoch 181: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.5357 - accuracy: 0.7704 - val_loss: 0.5829 - val_accuracy: 0.7543\n",
            "Epoch 182/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5243 - accuracy: 0.7783\n",
            "Epoch 182: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5351 - accuracy: 0.7669 - val_loss: 0.5759 - val_accuracy: 0.7518\n",
            "Epoch 183/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5270 - accuracy: 0.7915\n",
            "Epoch 183: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5373 - accuracy: 0.8054 - val_loss: 0.5786 - val_accuracy: 0.7543\n",
            "Epoch 184/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5373 - accuracy: 0.7705\n",
            "Epoch 184: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5332 - accuracy: 0.7690 - val_loss: 0.5806 - val_accuracy: 0.7543\n",
            "Epoch 185/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5296 - accuracy: 0.7681\n",
            "Epoch 185: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.5348 - accuracy: 0.7718 - val_loss: 0.5763 - val_accuracy: 0.7518\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.7800\n",
            "Epoch 186: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.5385 - accuracy: 0.7800 - val_loss: 0.5779 - val_accuracy: 0.7543\n",
            "Epoch 187/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5332 - accuracy: 0.7603\n",
            "Epoch 187: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.5356 - accuracy: 0.7663 - val_loss: 0.5763 - val_accuracy: 0.7543\n",
            "Epoch 188/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5324 - accuracy: 0.7749\n",
            "Epoch 188: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5325 - accuracy: 0.7740 - val_loss: 0.5774 - val_accuracy: 0.7543\n",
            "Epoch 189/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5358 - accuracy: 0.7705\n",
            "Epoch 189: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.5347 - accuracy: 0.7693 - val_loss: 0.5761 - val_accuracy: 0.7543\n",
            "Epoch 190/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5198 - accuracy: 0.7729\n",
            "Epoch 190: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5291 - accuracy: 0.7734 - val_loss: 0.5756 - val_accuracy: 0.7543\n",
            "Epoch 191/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5457 - accuracy: 0.7651\n",
            "Epoch 191: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5328 - accuracy: 0.7688 - val_loss: 0.5769 - val_accuracy: 0.7543\n",
            "Epoch 192/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5258 - accuracy: 0.7734\n",
            "Epoch 192: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.5304 - accuracy: 0.7734 - val_loss: 0.5764 - val_accuracy: 0.7543\n",
            "Epoch 193/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5351 - accuracy: 0.7744\n",
            "Epoch 193: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5313 - accuracy: 0.7715 - val_loss: 0.5747 - val_accuracy: 0.7543\n",
            "Epoch 194/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5367 - accuracy: 0.7612\n",
            "Epoch 194: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5325 - accuracy: 0.7685 - val_loss: 0.5737 - val_accuracy: 0.7543\n",
            "Epoch 195/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5262 - accuracy: 0.7710\n",
            "Epoch 195: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.5332 - accuracy: 0.7742 - val_loss: 0.5757 - val_accuracy: 0.7543\n",
            "Epoch 196/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5322 - accuracy: 0.7744\n",
            "Epoch 196: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5307 - accuracy: 0.7704 - val_loss: 0.5742 - val_accuracy: 0.7543\n",
            "Epoch 197/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5237 - accuracy: 0.7715\n",
            "Epoch 197: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5313 - accuracy: 0.8114 - val_loss: 0.5739 - val_accuracy: 0.7543\n",
            "Epoch 198/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5264 - accuracy: 0.7744\n",
            "Epoch 198: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5328 - accuracy: 0.7707 - val_loss: 0.5797 - val_accuracy: 0.7543\n",
            "Epoch 199/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5363 - accuracy: 0.7656\n",
            "Epoch 199: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5335 - accuracy: 0.7655 - val_loss: 0.5720 - val_accuracy: 0.7518\n",
            "Epoch 200/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5275 - accuracy: 0.7847\n",
            "Epoch 200: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5330 - accuracy: 0.8258 - val_loss: 0.5732 - val_accuracy: 0.7518\n",
            "Epoch 201/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5282 - accuracy: 0.7773\n",
            "Epoch 201: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.5319 - accuracy: 0.7729 - val_loss: 0.5768 - val_accuracy: 0.7543\n",
            "Epoch 202/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5377 - accuracy: 0.7671\n",
            "Epoch 202: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5283 - accuracy: 0.7666 - val_loss: 0.5701 - val_accuracy: 0.7518\n",
            "Epoch 203/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5394 - accuracy: 0.7891\n",
            "Epoch 203: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5330 - accuracy: 0.8231 - val_loss: 0.5718 - val_accuracy: 0.7518\n",
            "Epoch 204/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5393 - accuracy: 0.7886\n",
            "Epoch 204: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.5334 - accuracy: 0.7770 - val_loss: 0.5746 - val_accuracy: 0.7543\n",
            "Epoch 205/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5318 - accuracy: 0.7617\n",
            "Epoch 205: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5290 - accuracy: 0.8146 - val_loss: 0.5709 - val_accuracy: 0.7518\n",
            "Epoch 206/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5312 - accuracy: 0.7974\n",
            "Epoch 206: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5273 - accuracy: 0.7903 - val_loss: 0.5773 - val_accuracy: 0.7543\n",
            "Epoch 207/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5420 - accuracy: 0.7578\n",
            "Epoch 207: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5320 - accuracy: 0.7696 - val_loss: 0.5742 - val_accuracy: 0.7543\n",
            "Epoch 208/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5447 - accuracy: 0.7656\n",
            "Epoch 208: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5315 - accuracy: 0.7704 - val_loss: 0.5689 - val_accuracy: 0.7518\n",
            "Epoch 209/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5412 - accuracy: 0.8120\n",
            "Epoch 209: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5273 - accuracy: 0.8479 - val_loss: 0.5728 - val_accuracy: 0.7543\n",
            "Epoch 210/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5282 - accuracy: 0.7661\n",
            "Epoch 210: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5268 - accuracy: 0.7679 - val_loss: 0.5739 - val_accuracy: 0.7543\n",
            "Epoch 211/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5269 - accuracy: 0.7681\n",
            "Epoch 211: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5283 - accuracy: 0.7715 - val_loss: 0.5667 - val_accuracy: 0.7592\n",
            "Epoch 212/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5376 - accuracy: 0.8799\n",
            "Epoch 212: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5292 - accuracy: 0.8695 - val_loss: 0.5733 - val_accuracy: 0.7543\n",
            "Epoch 213/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5273 - accuracy: 0.7700\n",
            "Epoch 213: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5260 - accuracy: 0.7729 - val_loss: 0.5736 - val_accuracy: 0.7543\n",
            "Epoch 214/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5254 - accuracy: 0.7734\n",
            "Epoch 214: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.5246 - accuracy: 0.7731 - val_loss: 0.5681 - val_accuracy: 0.7518\n",
            "Epoch 215/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5187 - accuracy: 0.8110\n",
            "Epoch 215: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5275 - accuracy: 0.7882 - val_loss: 0.5746 - val_accuracy: 0.7543\n",
            "Epoch 216/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5264 - accuracy: 0.7700\n",
            "Epoch 216: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5277 - accuracy: 0.7677 - val_loss: 0.5708 - val_accuracy: 0.7543\n",
            "Epoch 217/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5173 - accuracy: 0.7803\n",
            "Epoch 217: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5266 - accuracy: 0.7720 - val_loss: 0.5684 - val_accuracy: 0.7518\n",
            "Epoch 218/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5389 - accuracy: 0.8716\n",
            "Epoch 218: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5293 - accuracy: 0.8400 - val_loss: 0.5716 - val_accuracy: 0.7543\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.7715\n",
            "Epoch 219: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.5258 - accuracy: 0.7715 - val_loss: 0.5708 - val_accuracy: 0.7543\n",
            "Epoch 220/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5350 - accuracy: 0.7646\n",
            "Epoch 220: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.5274 - accuracy: 0.7789 - val_loss: 0.5702 - val_accuracy: 0.7543\n",
            "Epoch 221/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5285 - accuracy: 0.7739\n",
            "Epoch 221: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.5295 - accuracy: 0.7761 - val_loss: 0.5726 - val_accuracy: 0.7543\n",
            "Epoch 221: early stopping\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5303 - accuracy: 0.7775\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5303 - accuracy: 0.7775\n",
            "Model: \"DOS2019-LUCID\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv0 (Conv2D)              (None, 8, 1, 64)          2176      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8, 1, 64)          0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 64)               0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,241\n",
            "Trainable params: 2,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6918 - accuracy: 0.5635\n",
            "Epoch 1: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 0.6747 - accuracy: 0.5307 - val_loss: 0.6764 - val_accuracy: 0.5799\n",
            "Epoch 2/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6239 - accuracy: 0.6382\n",
            "Epoch 2: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.6147 - accuracy: 0.6347 - val_loss: 0.5790 - val_accuracy: 0.6585\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5480 - accuracy: 0.6914\n",
            "Epoch 3: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.5385 - accuracy: 0.6817 - val_loss: 0.5488 - val_accuracy: 0.7518\n",
            "Epoch 4/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5021 - accuracy: 0.7690\n",
            "Epoch 4: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.4913 - accuracy: 0.7871 - val_loss: 0.5146 - val_accuracy: 0.7666\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4664 - accuracy: 0.7856\n",
            "Epoch 5: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.4623 - accuracy: 0.7688 - val_loss: 0.5182 - val_accuracy: 0.7248\n",
            "Epoch 6/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4567 - accuracy: 0.7451\n",
            "Epoch 6: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.4468 - accuracy: 0.7565 - val_loss: 0.4869 - val_accuracy: 0.7420\n",
            "Epoch 7/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4105 - accuracy: 0.7754\n",
            "Epoch 7: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.4201 - accuracy: 0.7693 - val_loss: 0.4744 - val_accuracy: 0.7420\n",
            "Epoch 8/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4009 - accuracy: 0.7666\n",
            "Epoch 8: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.3970 - accuracy: 0.7778 - val_loss: 0.4514 - val_accuracy: 0.8894\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3819 - accuracy: 0.8975\n",
            "Epoch 9: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.3825 - accuracy: 0.9006 - val_loss: 0.4397 - val_accuracy: 0.7838\n",
            "Epoch 10/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3845 - accuracy: 0.7939\n",
            "Epoch 10: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.3687 - accuracy: 0.8468 - val_loss: 0.4344 - val_accuracy: 0.9361\n",
            "Epoch 11/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3496 - accuracy: 0.9551\n",
            "Epoch 11: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.3438 - accuracy: 0.9189 - val_loss: 0.3979 - val_accuracy: 0.8624\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3219 - accuracy: 0.8721\n",
            "Epoch 12: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.3224 - accuracy: 0.8722 - val_loss: 0.4054 - val_accuracy: 0.8354\n",
            "Epoch 13/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3186 - accuracy: 0.9009\n",
            "Epoch 13: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.3177 - accuracy: 0.9020 - val_loss: 0.3667 - val_accuracy: 0.8673\n",
            "Epoch 14/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2925 - accuracy: 0.8765\n",
            "Epoch 14: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.3032 - accuracy: 0.8791 - val_loss: 0.3469 - val_accuracy: 0.8673\n",
            "Epoch 15/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2717 - accuracy: 0.8774\n",
            "Epoch 15: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.2685 - accuracy: 0.8908 - val_loss: 0.3332 - val_accuracy: 0.9386\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2500 - accuracy: 0.9531\n",
            "Epoch 16: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.2503 - accuracy: 0.9582 - val_loss: 0.3197 - val_accuracy: 0.9631\n",
            "Epoch 17/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2269 - accuracy: 0.9819\n",
            "Epoch 17: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.2371 - accuracy: 0.9424 - val_loss: 0.3267 - val_accuracy: 0.9361\n",
            "Epoch 18/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2258 - accuracy: 0.9614\n",
            "Epoch 18: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.2208 - accuracy: 0.9580 - val_loss: 0.2921 - val_accuracy: 0.8943\n",
            "Epoch 19/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2203 - accuracy: 0.9038\n",
            "Epoch 19: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.2019 - accuracy: 0.9394 - val_loss: 0.2811 - val_accuracy: 0.9361\n",
            "Epoch 20/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1849 - accuracy: 0.9565\n",
            "Epoch 20: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.1813 - accuracy: 0.9692 - val_loss: 0.2499 - val_accuracy: 0.9631\n",
            "Epoch 21/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1732 - accuracy: 0.9854\n",
            "Epoch 21: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.1635 - accuracy: 0.9847 - val_loss: 0.2327 - val_accuracy: 0.9656\n",
            "Epoch 22/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1480 - accuracy: 0.9844\n",
            "Epoch 22: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.1476 - accuracy: 0.9831 - val_loss: 0.2151 - val_accuracy: 0.9631\n",
            "Epoch 23/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1385 - accuracy: 0.9829\n",
            "Epoch 23: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.1372 - accuracy: 0.9833 - val_loss: 0.2137 - val_accuracy: 0.9656\n",
            "Epoch 24/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1280 - accuracy: 0.9844\n",
            "Epoch 24: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.1247 - accuracy: 0.9847 - val_loss: 0.1990 - val_accuracy: 0.9631\n",
            "Epoch 25/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1171 - accuracy: 0.9844\n",
            "Epoch 25: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.1147 - accuracy: 0.9850 - val_loss: 0.1956 - val_accuracy: 0.9705\n",
            "Epoch 26/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1114 - accuracy: 0.9849\n",
            "Epoch 26: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.1069 - accuracy: 0.9844 - val_loss: 0.1878 - val_accuracy: 0.9681\n",
            "Epoch 27/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0933 - accuracy: 0.9912\n",
            "Epoch 27: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0988 - accuracy: 0.9891 - val_loss: 0.1875 - val_accuracy: 0.9656\n",
            "Epoch 28/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0938 - accuracy: 0.9849\n",
            "Epoch 28: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0939 - accuracy: 0.9844 - val_loss: 0.1759 - val_accuracy: 0.9681\n",
            "Epoch 29/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0938 - accuracy: 0.9839\n",
            "Epoch 29: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0870 - accuracy: 0.9853 - val_loss: 0.1693 - val_accuracy: 0.9705\n",
            "Epoch 30/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0806 - accuracy: 0.9863\n",
            "Epoch 30: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0818 - accuracy: 0.9850 - val_loss: 0.1698 - val_accuracy: 0.9656\n",
            "Epoch 31/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0753 - accuracy: 0.9854\n",
            "Epoch 31: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0779 - accuracy: 0.9863 - val_loss: 0.1683 - val_accuracy: 0.9681\n",
            "Epoch 32/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0757 - accuracy: 0.9893\n",
            "Epoch 32: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.0741 - accuracy: 0.9874 - val_loss: 0.1568 - val_accuracy: 0.9705\n",
            "Epoch 33/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0864 - accuracy: 0.9810\n",
            "Epoch 33: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0726 - accuracy: 0.9850 - val_loss: 0.1561 - val_accuracy: 0.9730\n",
            "Epoch 34/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0743 - accuracy: 0.9849\n",
            "Epoch 34: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0690 - accuracy: 0.9872 - val_loss: 0.1641 - val_accuracy: 0.9656\n",
            "Epoch 35/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0739 - accuracy: 0.9868\n",
            "Epoch 35: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.0671 - accuracy: 0.9877 - val_loss: 0.1575 - val_accuracy: 0.9656\n",
            "Epoch 36/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0735 - accuracy: 0.9805\n",
            "Epoch 36: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0652 - accuracy: 0.9844 - val_loss: 0.1519 - val_accuracy: 0.9681\n",
            "Epoch 37/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0579 - accuracy: 0.9858\n",
            "Epoch 37: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0634 - accuracy: 0.9853 - val_loss: 0.1504 - val_accuracy: 0.9705\n",
            "Epoch 38/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0656 - accuracy: 0.9844\n",
            "Epoch 38: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0613 - accuracy: 0.9850 - val_loss: 0.1524 - val_accuracy: 0.9656\n",
            "Epoch 39/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0559 - accuracy: 0.9902\n",
            "Epoch 39: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0590 - accuracy: 0.9888 - val_loss: 0.1460 - val_accuracy: 0.9681\n",
            "Epoch 40/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0553 - accuracy: 0.9868\n",
            "Epoch 40: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0576 - accuracy: 0.9853 - val_loss: 0.1392 - val_accuracy: 0.9730\n",
            "Epoch 41/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0562 - accuracy: 0.9849\n",
            "Epoch 41: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0566 - accuracy: 0.9858 - val_loss: 0.1451 - val_accuracy: 0.9705\n",
            "Epoch 42/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0593 - accuracy: 0.9868\n",
            "Epoch 42: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0548 - accuracy: 0.9888 - val_loss: 0.1450 - val_accuracy: 0.9681\n",
            "Epoch 43/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0560 - accuracy: 0.9863\n",
            "Epoch 43: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0534 - accuracy: 0.9863 - val_loss: 0.1366 - val_accuracy: 0.9754\n",
            "Epoch 44/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0540 - accuracy: 0.9854\n",
            "Epoch 44: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0524 - accuracy: 0.9858 - val_loss: 0.1350 - val_accuracy: 0.9754\n",
            "Epoch 45/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0467 - accuracy: 0.9863\n",
            "Epoch 45: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0512 - accuracy: 0.9861 - val_loss: 0.1366 - val_accuracy: 0.9754\n",
            "Epoch 46/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0618 - accuracy: 0.9824\n",
            "Epoch 46: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0515 - accuracy: 0.9861 - val_loss: 0.1355 - val_accuracy: 0.9754\n",
            "Epoch 47/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0414 - accuracy: 0.9912\n",
            "Epoch 47: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0489 - accuracy: 0.9891 - val_loss: 0.1366 - val_accuracy: 0.9705\n",
            "Epoch 48/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0446 - accuracy: 0.9912\n",
            "Epoch 48: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0475 - accuracy: 0.9891 - val_loss: 0.1271 - val_accuracy: 0.9754\n",
            "Epoch 49/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9863\n",
            "Epoch 49: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0502 - accuracy: 0.9861 - val_loss: 0.1263 - val_accuracy: 0.9754\n",
            "Epoch 50/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0460 - accuracy: 0.9854\n",
            "Epoch 50: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0481 - accuracy: 0.9874 - val_loss: 0.1320 - val_accuracy: 0.9705\n",
            "Epoch 51/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0504 - accuracy: 0.9883\n",
            "Epoch 51: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0490 - accuracy: 0.9877 - val_loss: 0.1271 - val_accuracy: 0.9754\n",
            "Epoch 52/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0471 - accuracy: 0.9849\n",
            "Epoch 52: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0448 - accuracy: 0.9874 - val_loss: 0.1355 - val_accuracy: 0.9705\n",
            "Epoch 53/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0445 - accuracy: 0.9902\n",
            "Epoch 53: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0465 - accuracy: 0.9894 - val_loss: 0.1226 - val_accuracy: 0.9754\n",
            "Epoch 54/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0374 - accuracy: 0.9888\n",
            "Epoch 54: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0438 - accuracy: 0.9858 - val_loss: 0.1208 - val_accuracy: 0.9754\n",
            "Epoch 55/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0351 - accuracy: 0.9878\n",
            "Epoch 55: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0419 - accuracy: 0.9874 - val_loss: 0.1264 - val_accuracy: 0.9705\n",
            "Epoch 56/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0459 - accuracy: 0.9893\n",
            "Epoch 56: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0424 - accuracy: 0.9883 - val_loss: 0.1177 - val_accuracy: 0.9754\n",
            "Epoch 57/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0351 - accuracy: 0.9893\n",
            "Epoch 57: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.1208 - val_accuracy: 0.9754\n",
            "Epoch 58/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0425 - accuracy: 0.9922\n",
            "Epoch 58: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0398 - accuracy: 0.9899 - val_loss: 0.1160 - val_accuracy: 0.9754\n",
            "Epoch 59/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0382 - accuracy: 0.9868\n",
            "Epoch 59: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0396 - accuracy: 0.9858 - val_loss: 0.1131 - val_accuracy: 0.9754\n",
            "Epoch 60/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0361 - accuracy: 0.9883\n",
            "Epoch 60: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0367 - accuracy: 0.9874 - val_loss: 0.1183 - val_accuracy: 0.9754\n",
            "Epoch 61/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0384 - accuracy: 0.9888\n",
            "Epoch 61: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0373 - accuracy: 0.9899 - val_loss: 0.1137 - val_accuracy: 0.9754\n",
            "Epoch 62/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0345 - accuracy: 0.9854\n",
            "Epoch 62: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.1120 - val_accuracy: 0.9754\n",
            "Epoch 63/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0392 - accuracy: 0.9893\n",
            "Epoch 63: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0366 - accuracy: 0.9921 - val_loss: 0.1114 - val_accuracy: 0.9754\n",
            "Epoch 64/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0366 - accuracy: 0.9912\n",
            "Epoch 64: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0363 - accuracy: 0.9891 - val_loss: 0.1083 - val_accuracy: 0.9779\n",
            "Epoch 65/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0319 - accuracy: 0.9873\n",
            "Epoch 65: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0347 - accuracy: 0.9899 - val_loss: 0.1140 - val_accuracy: 0.9828\n",
            "Epoch 66/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - accuracy: 0.9946\n",
            "Epoch 66: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0342 - accuracy: 0.9926 - val_loss: 0.1087 - val_accuracy: 0.9754\n",
            "Epoch 67/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0344 - accuracy: 0.9868\n",
            "Epoch 67: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0326 - accuracy: 0.9869 - val_loss: 0.1108 - val_accuracy: 0.9828\n",
            "Epoch 68/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0299 - accuracy: 0.9951\n",
            "Epoch 68: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0337 - accuracy: 0.9937 - val_loss: 0.1064 - val_accuracy: 0.9828\n",
            "Epoch 69/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0327 - accuracy: 0.9941\n",
            "Epoch 69: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0311 - accuracy: 0.9929 - val_loss: 0.1044 - val_accuracy: 0.9853\n",
            "Epoch 70/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0351 - accuracy: 0.9917\n",
            "Epoch 70: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0310 - accuracy: 0.9929 - val_loss: 0.1081 - val_accuracy: 0.9828\n",
            "Epoch 71/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0203 - accuracy: 0.9971\n",
            "Epoch 71: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0320 - accuracy: 0.9940 - val_loss: 0.1039 - val_accuracy: 0.9779\n",
            "Epoch 72/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0323 - accuracy: 0.9873\n",
            "Epoch 72: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0322 - accuracy: 0.9883 - val_loss: 0.1025 - val_accuracy: 0.9828\n",
            "Epoch 73/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0307 - accuracy: 0.9951\n",
            "Epoch 73: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0288 - accuracy: 0.9948 - val_loss: 0.1048 - val_accuracy: 0.9828\n",
            "Epoch 74/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0364 - accuracy: 0.9927\n",
            "Epoch 74: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0287 - accuracy: 0.9943 - val_loss: 0.1013 - val_accuracy: 0.9853\n",
            "Epoch 75/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - accuracy: 0.9907\n",
            "Epoch 75: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.1025 - val_accuracy: 0.9828\n",
            "Epoch 76/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0348 - accuracy: 0.9927\n",
            "Epoch 76: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0281 - accuracy: 0.9940 - val_loss: 0.0987 - val_accuracy: 0.9853\n",
            "Epoch 77/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0290 - accuracy: 0.9941\n",
            "Epoch 77: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0268 - accuracy: 0.9956 - val_loss: 0.0976 - val_accuracy: 0.9853\n",
            "Epoch 78/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0252 - accuracy: 0.9956\n",
            "Epoch 78: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0265 - accuracy: 0.9945 - val_loss: 0.0969 - val_accuracy: 0.9853\n",
            "Epoch 79/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0218 - accuracy: 0.9956\n",
            "Epoch 79: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0263 - accuracy: 0.9940 - val_loss: 0.0963 - val_accuracy: 0.9853\n",
            "Epoch 80/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0271 - accuracy: 0.9946\n",
            "Epoch 80: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0273 - accuracy: 0.9943 - val_loss: 0.0960 - val_accuracy: 0.9853\n",
            "Epoch 81/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0225 - accuracy: 0.9966\n",
            "Epoch 81: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0259 - accuracy: 0.9954 - val_loss: 0.0939 - val_accuracy: 0.9853\n",
            "Epoch 82/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0220 - accuracy: 0.9966\n",
            "Epoch 82: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0258 - accuracy: 0.9956 - val_loss: 0.0958 - val_accuracy: 0.9828\n",
            "Epoch 83/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0261 - accuracy: 0.9946\n",
            "Epoch 83: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0257 - accuracy: 0.9945 - val_loss: 0.0935 - val_accuracy: 0.9853\n",
            "Epoch 84/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0248 - accuracy: 0.9961\n",
            "Epoch 84: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.0253 - accuracy: 0.9962 - val_loss: 0.0918 - val_accuracy: 0.9853\n",
            "Epoch 85/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0268 - accuracy: 0.9956\n",
            "Epoch 85: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0248 - accuracy: 0.9948 - val_loss: 0.0895 - val_accuracy: 0.9853\n",
            "Epoch 86/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0268 - accuracy: 0.9946\n",
            "Epoch 86: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0244 - accuracy: 0.9948 - val_loss: 0.0886 - val_accuracy: 0.9853\n",
            "Epoch 87/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0270 - accuracy: 0.9951\n",
            "Epoch 87: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 0.0900 - val_accuracy: 0.9828\n",
            "Epoch 88/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0187 - accuracy: 0.9976\n",
            "Epoch 88: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.0877 - val_accuracy: 0.9853\n",
            "Epoch 89/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0194 - accuracy: 0.9966\n",
            "Epoch 89: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0233 - accuracy: 0.9962 - val_loss: 0.0853 - val_accuracy: 0.9853\n",
            "Epoch 90/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0270 - accuracy: 0.9956\n",
            "Epoch 90: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0224 - accuracy: 0.9962 - val_loss: 0.0852 - val_accuracy: 0.9853\n",
            "Epoch 91/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0229 - accuracy: 0.9946\n",
            "Epoch 91: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0223 - accuracy: 0.9954 - val_loss: 0.0848 - val_accuracy: 0.9853\n",
            "Epoch 92/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0216 - accuracy: 0.9966\n",
            "Epoch 92: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0221 - accuracy: 0.9962 - val_loss: 0.0841 - val_accuracy: 0.9853\n",
            "Epoch 93/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0212 - accuracy: 0.9951\n",
            "Epoch 93: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 0.0821 - val_accuracy: 0.9853\n",
            "Epoch 94/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0200 - accuracy: 0.9971\n",
            "Epoch 94: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 0.0817 - val_accuracy: 0.9853\n",
            "Epoch 95/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0224 - accuracy: 0.9961\n",
            "Epoch 95: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0210 - accuracy: 0.9962 - val_loss: 0.0820 - val_accuracy: 0.9853\n",
            "Epoch 96/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0238 - accuracy: 0.9941\n",
            "Epoch 96: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0216 - accuracy: 0.9954 - val_loss: 0.0807 - val_accuracy: 0.9853\n",
            "Epoch 97/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0209 - accuracy: 0.9966\n",
            "Epoch 97: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0208 - accuracy: 0.9962 - val_loss: 0.0790 - val_accuracy: 0.9853\n",
            "Epoch 98/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0212 - accuracy: 0.9961\n",
            "Epoch 98: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0206 - accuracy: 0.9962 - val_loss: 0.0780 - val_accuracy: 0.9853\n",
            "Epoch 99/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0233 - accuracy: 0.9961\n",
            "Epoch 99: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0205 - accuracy: 0.9962 - val_loss: 0.0783 - val_accuracy: 0.9853\n",
            "Epoch 100/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0230 - accuracy: 0.9951\n",
            "Epoch 100: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.0780 - val_accuracy: 0.9853\n",
            "Epoch 101/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0247 - accuracy: 0.9946\n",
            "Epoch 101: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0202 - accuracy: 0.9956 - val_loss: 0.0768 - val_accuracy: 0.9853\n",
            "Epoch 102/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0249 - accuracy: 0.9951\n",
            "Epoch 102: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0199 - accuracy: 0.9962 - val_loss: 0.0756 - val_accuracy: 0.9853\n",
            "Epoch 103/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0253 - accuracy: 0.9946\n",
            "Epoch 103: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0195 - accuracy: 0.9962 - val_loss: 0.0753 - val_accuracy: 0.9853\n",
            "Epoch 104/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0233 - accuracy: 0.9956\n",
            "Epoch 104: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0196 - accuracy: 0.9962 - val_loss: 0.0748 - val_accuracy: 0.9853\n",
            "Epoch 105/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0153 - accuracy: 0.9971\n",
            "Epoch 105: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0192 - accuracy: 0.9962 - val_loss: 0.0737 - val_accuracy: 0.9853\n",
            "Epoch 106/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0223 - accuracy: 0.9961\n",
            "Epoch 106: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0729 - val_accuracy: 0.9853\n",
            "Epoch 107/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0169 - accuracy: 0.9971\n",
            "Epoch 107: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.0721 - val_accuracy: 0.9853\n",
            "Epoch 108/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0168 - accuracy: 0.9971\n",
            "Epoch 108: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.0718 - val_accuracy: 0.9853\n",
            "Epoch 109/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0181 - accuracy: 0.9956\n",
            "Epoch 109: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0714 - val_accuracy: 0.9853\n",
            "Epoch 110/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0177 - accuracy: 0.9971\n",
            "Epoch 110: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0185 - accuracy: 0.9965 - val_loss: 0.0719 - val_accuracy: 0.9853\n",
            "Epoch 111/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0207 - accuracy: 0.9956\n",
            "Epoch 111: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.0710 - val_accuracy: 0.9853\n",
            "Epoch 112/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0132 - accuracy: 0.9971\n",
            "Epoch 112: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.0701 - val_accuracy: 0.9853\n",
            "Epoch 113/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0140 - accuracy: 0.9976\n",
            "Epoch 113: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.0700 - val_accuracy: 0.9853\n",
            "Epoch 114/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0183 - accuracy: 0.9961\n",
            "Epoch 114: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.0702 - val_accuracy: 0.9853\n",
            "Epoch 115/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0151 - accuracy: 0.9976\n",
            "Epoch 115: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0180 - accuracy: 0.9965 - val_loss: 0.0694 - val_accuracy: 0.9853\n",
            "Epoch 116/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0182 - accuracy: 0.9956\n",
            "Epoch 116: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 0.0682 - val_accuracy: 0.9853\n",
            "Epoch 117/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0167 - accuracy: 0.9966\n",
            "Epoch 117: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 0.0675 - val_accuracy: 0.9853\n",
            "Epoch 118/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0200 - accuracy: 0.9961\n",
            "Epoch 118: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0175 - accuracy: 0.9965 - val_loss: 0.0674 - val_accuracy: 0.9853\n",
            "Epoch 119/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0222 - accuracy: 0.9951\n",
            "Epoch 119: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0176 - accuracy: 0.9965 - val_loss: 0.0673 - val_accuracy: 0.9853\n",
            "Epoch 120/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0171 - accuracy: 0.9961\n",
            "Epoch 120: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 0.0659 - val_accuracy: 0.9853\n",
            "Epoch 121/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0179 - accuracy: 0.9956\n",
            "Epoch 121: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 0.0652 - val_accuracy: 0.9853\n",
            "Epoch 122/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0164 - accuracy: 0.9966\n",
            "Epoch 122: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0179 - accuracy: 0.9965 - val_loss: 0.0654 - val_accuracy: 0.9853\n",
            "Epoch 123/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0161 - accuracy: 0.9966\n",
            "Epoch 123: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.0662 - val_accuracy: 0.9853\n",
            "Epoch 124/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0154 - accuracy: 0.9956\n",
            "Epoch 124: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.0656 - val_accuracy: 0.9853\n",
            "Epoch 125/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0137 - accuracy: 0.9980\n",
            "Epoch 125: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0169 - accuracy: 0.9965 - val_loss: 0.0640 - val_accuracy: 0.9853\n",
            "Epoch 126/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0153 - accuracy: 0.9966\n",
            "Epoch 126: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.0636 - val_accuracy: 0.9853\n",
            "Epoch 127/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0186 - accuracy: 0.9956\n",
            "Epoch 127: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.0640 - val_accuracy: 0.9853\n",
            "Epoch 128/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0152 - accuracy: 0.9971\n",
            "Epoch 128: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 0.0630 - val_accuracy: 0.9853\n",
            "Epoch 129/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0172 - accuracy: 0.9956\n",
            "Epoch 129: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.0621 - val_accuracy: 0.9853\n",
            "Epoch 130/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0166 - accuracy: 0.9966\n",
            "Epoch 130: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.0618 - val_accuracy: 0.9853\n",
            "Epoch 131/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0172 - accuracy: 0.9966\n",
            "Epoch 131: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.0613 - val_accuracy: 0.9853\n",
            "Epoch 132/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0149 - accuracy: 0.9971\n",
            "Epoch 132: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0161 - accuracy: 0.9967 - val_loss: 0.0611 - val_accuracy: 0.9853\n",
            "Epoch 133/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0116 - accuracy: 0.9980\n",
            "Epoch 133: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.0610 - val_accuracy: 0.9853\n",
            "Epoch 134/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0213 - accuracy: 0.9946\n",
            "Epoch 134: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.0608 - val_accuracy: 0.9853\n",
            "Epoch 135/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0172 - accuracy: 0.9961\n",
            "Epoch 135: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.0604 - val_accuracy: 0.9853\n",
            "Epoch 136/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0162 - accuracy: 0.9971\n",
            "Epoch 136: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.0598 - val_accuracy: 0.9853\n",
            "Epoch 137/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0142 - accuracy: 0.9971\n",
            "Epoch 137: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.0595 - val_accuracy: 0.9853\n",
            "Epoch 138/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0171 - accuracy: 0.9966\n",
            "Epoch 138: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.0596 - val_accuracy: 0.9853\n",
            "Epoch 139/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0131 - accuracy: 0.9976\n",
            "Epoch 139: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.0591 - val_accuracy: 0.9853\n",
            "Epoch 140/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0138 - accuracy: 0.9971\n",
            "Epoch 140: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0586 - val_accuracy: 0.9853\n",
            "Epoch 141/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0117 - accuracy: 0.9976\n",
            "Epoch 141: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.0583 - val_accuracy: 0.9853\n",
            "Epoch 142/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0159 - accuracy: 0.9971\n",
            "Epoch 142: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.0582 - val_accuracy: 0.9853\n",
            "Epoch 143/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0205 - accuracy: 0.9956\n",
            "Epoch 143: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.0580 - val_accuracy: 0.9853\n",
            "Epoch 144/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0185 - accuracy: 0.9956\n",
            "Epoch 144: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.0577 - val_accuracy: 0.9853\n",
            "Epoch 145/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0132 - accuracy: 0.9976\n",
            "Epoch 145: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.0575 - val_accuracy: 0.9853\n",
            "Epoch 146/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0108 - accuracy: 0.9980\n",
            "Epoch 146: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.0575 - val_accuracy: 0.9853\n",
            "Epoch 147/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0143 - accuracy: 0.9971\n",
            "Epoch 147: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.0578 - val_accuracy: 0.9853\n",
            "Epoch 148/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0190 - accuracy: 0.9961\n",
            "Epoch 148: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.0575 - val_accuracy: 0.9853\n",
            "Epoch 149/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0148 - accuracy: 0.9966\n",
            "Epoch 149: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.0571 - val_accuracy: 0.9853\n",
            "Epoch 150/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0139 - accuracy: 0.9961\n",
            "Epoch 150: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.0573 - val_accuracy: 0.9853\n",
            "Epoch 151/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0122 - accuracy: 0.9976\n",
            "Epoch 151: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.0577 - val_accuracy: 0.9853\n",
            "Epoch 152/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0166 - accuracy: 0.9966\n",
            "Epoch 152: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.0575 - val_accuracy: 0.9853\n",
            "Epoch 153/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0163 - accuracy: 0.9966\n",
            "Epoch 153: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.0568 - val_accuracy: 0.9853\n",
            "Epoch 154/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0169 - accuracy: 0.9961\n",
            "Epoch 154: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0566 - val_accuracy: 0.9853\n",
            "Epoch 155/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0116 - accuracy: 0.9976\n",
            "Epoch 155: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0563 - val_accuracy: 0.9853\n",
            "Epoch 156/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0119 - accuracy: 0.9971\n",
            "Epoch 156: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0565 - val_accuracy: 0.9853\n",
            "Epoch 157/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0089 - accuracy: 0.9980\n",
            "Epoch 157: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.0567 - val_accuracy: 0.9853\n",
            "Epoch 158/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0127 - accuracy: 0.9976\n",
            "Epoch 158: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.0557 - val_accuracy: 0.9853\n",
            "Epoch 159/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0158 - accuracy: 0.9956\n",
            "Epoch 159: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0553 - val_accuracy: 0.9853\n",
            "Epoch 160/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0135 - accuracy: 0.9971\n",
            "Epoch 160: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.0557 - val_accuracy: 0.9853\n",
            "Epoch 161/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0129 - accuracy: 0.9980\n",
            "Epoch 161: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.0553 - val_accuracy: 0.9853\n",
            "Epoch 162/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0151 - accuracy: 0.9971\n",
            "Epoch 162: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.0551 - val_accuracy: 0.9853\n",
            "Epoch 163/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0110 - accuracy: 0.9976\n",
            "Epoch 163: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0554 - val_accuracy: 0.9853\n",
            "Epoch 164/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0087 - accuracy: 0.9980\n",
            "Epoch 164: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.0548 - val_accuracy: 0.9853\n",
            "Epoch 165/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0134 - accuracy: 0.9971\n",
            "Epoch 165: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.0549 - val_accuracy: 0.9853\n",
            "Epoch 166/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0145 - accuracy: 0.9971\n",
            "Epoch 166: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.0547 - val_accuracy: 0.9853\n",
            "Epoch 167/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0137 - accuracy: 0.9966\n",
            "Epoch 167: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.0544 - val_accuracy: 0.9853\n",
            "Epoch 168/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0099 - accuracy: 0.9980\n",
            "Epoch 168: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0544 - val_accuracy: 0.9853\n",
            "Epoch 169/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0128 - accuracy: 0.9971\n",
            "Epoch 169: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.0542 - val_accuracy: 0.9853\n",
            "Epoch 170/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0128 - accuracy: 0.9971\n",
            "Epoch 170: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0541 - val_accuracy: 0.9853\n",
            "Epoch 171/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0156 - accuracy: 0.9961\n",
            "Epoch 171: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0546 - val_accuracy: 0.9853\n",
            "Epoch 172/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0127 - accuracy: 0.9976\n",
            "Epoch 172: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.0536 - val_accuracy: 0.9853\n",
            "Epoch 173/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0112 - accuracy: 0.9980\n",
            "Epoch 173: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0535 - val_accuracy: 0.9853\n",
            "Epoch 174/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0149 - accuracy: 0.9966\n",
            "Epoch 174: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0539 - val_accuracy: 0.9853\n",
            "Epoch 175/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0144 - accuracy: 0.9966\n",
            "Epoch 175: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.0536 - val_accuracy: 0.9853\n",
            "Epoch 176/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0149 - accuracy: 0.9966\n",
            "Epoch 176: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0537 - val_accuracy: 0.9853\n",
            "Epoch 177/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0146 - accuracy: 0.9966\n",
            "Epoch 177: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0540 - val_accuracy: 0.9853\n",
            "Epoch 178/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0116 - accuracy: 0.9976\n",
            "Epoch 178: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0540 - val_accuracy: 0.9853\n",
            "Epoch 179/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
            "Epoch 179: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0540 - val_accuracy: 0.9853\n",
            "Epoch 180/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0099 - accuracy: 0.9976\n",
            "Epoch 180: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0542 - val_accuracy: 0.9853\n",
            "Epoch 181/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0106 - accuracy: 0.9980\n",
            "Epoch 181: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0541 - val_accuracy: 0.9853\n",
            "Epoch 182/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0127 - accuracy: 0.9976\n",
            "Epoch 182: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.0539 - val_accuracy: 0.9853\n",
            "Epoch 183/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0122 - accuracy: 0.9966\n",
            "Epoch 183: val_accuracy did not improve from 0.98526\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0537 - val_accuracy: 0.9853\n",
            "Epoch 183: early stopping\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "Best parameters:  {'batch_size': 2048, 'dropout': None, 'kernels': 64, 'learning_rate': 0.1, 'regularization': None}\n",
            "Best model path:  ./output/10t-10n-DOS2019-LUCID\n",
            "F1 Score of the best model on the validation set:  0.9827586206896551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Playground**"
      ],
      "metadata": {
        "id": "IWWuE_kVsnPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **UTILITY**"
      ],
      "metadata": {
        "id": "zT3gE2wxtPHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### UTILITY FILE ############\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import glob\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "SEED = 1\n",
        "MAX_FLOW_LEN = 100 # number of packets\n",
        "TIME_WINDOW = 10\n",
        "TRAIN_SIZE = 0.90 # size of the training set wrt the total number of samples\n",
        "\n",
        "protocols = ['arp','data','dns','ftp','http','icmp','ip','ssdp','ssl','telnet','tcp','udp']\n",
        "powers_of_two = np.array([2**i for i in range(len(protocols))])\n",
        "\n",
        "\n",
        "# feature list with min and max values\n",
        "feature_list = OrderedDict([\n",
        "    ('timestamp', [0,10]),\n",
        "    ('packet_length',[0,1<<16]),\n",
        "    ('highest_layer',[0,1<<32]),\n",
        "    ('IP_flags',[0,1<<16]),\n",
        "    ('protocols',[0,1<<len(protocols)]),\n",
        "    ('TCP_length',[0,1<<16]),\n",
        "    ('TCP_ack',[0,1<<32]),\n",
        "    ('TCP_flags',[0,1<<16]),\n",
        "    ('TCP_window_size',[0,1<<16]),\n",
        "    ('UDP_length',[0,1<<16]),\n",
        "    ('ICMP_type',[0,1<<8])]\n",
        ")\n",
        "\n",
        "def load_dataset(path):\n",
        "    filename = glob.glob(path)[0]\n",
        "    dataset = h5py.File(filename, \"r\")\n",
        "    set_x_orig = np.array(dataset[\"set_x\"][:])  # features\n",
        "    set_y_orig = np.array(dataset[\"set_y\"][:])  # labels\n",
        "\n",
        "    X_train = np.reshape(set_x_orig, (set_x_orig.shape[0], set_x_orig.shape[1], set_x_orig.shape[2], 1))\n",
        "    Y_train = set_y_orig#.reshape((1, set_y_orig.shape[0]))\n",
        "\n",
        "    return X_train, Y_train\n",
        "\n",
        "def scale_linear_bycolumn(rawpoints, mins,maxs,high=1.0, low=0.0):\n",
        "    rng = maxs - mins\n",
        "    return high - (((high - low) * (maxs - rawpoints)) / rng)\n",
        "\n",
        "def count_packets_in_dataset(X_list):\n",
        "    packet_counters = []\n",
        "    for X in X_list:\n",
        "        TOT = X.sum(axis=2)\n",
        "        packet_counters.append(np.count_nonzero(TOT))\n",
        "\n",
        "    return packet_counters\n",
        "\n",
        "def all_same(items):\n",
        "    return all(x == items[0] for x in items)\n",
        "\n",
        "# min/max values of features based on the nominal min/max values of the single features (as defined in the feature_list dict)\n",
        "def static_min_max(time_window=10):\n",
        "    feature_list['timestamp'][1] = time_window\n",
        "\n",
        "    min_array = np.zeros(len(feature_list))\n",
        "    max_array = np.zeros(len(feature_list))\n",
        "\n",
        "    i=0\n",
        "    for feature, value in feature_list.items():\n",
        "        min_array[i] = value[0]\n",
        "        max_array[i] = value[1]\n",
        "        i+=1\n",
        "\n",
        "    return min_array,max_array\n",
        "\n",
        "# min/max values of features based on the values in the dataset\n",
        "def find_min_max(X,time_window=10):\n",
        "    sample_len = X[0].shape[1]\n",
        "    max_array = np.zeros((1,sample_len))\n",
        "    min_array = np.full((1, sample_len),np.inf)\n",
        "\n",
        "    for feature in X:\n",
        "        temp_feature = np.vstack([max_array,feature])\n",
        "        max_array = np.amax(temp_feature,axis=0)\n",
        "        temp_feature = np.vstack([min_array, feature])\n",
        "        min_array = np.amin(temp_feature, axis=0)\n",
        "\n",
        "    # flows cannot last for more than MAX_FLOW_DURATION seconds, so they are normalized accordingly\n",
        "    max_array[0] = time_window\n",
        "    min_array[0] = 0\n",
        "\n",
        "    return min_array,max_array\n",
        "\n",
        "def normalize_and_padding(X,mins,maxs,max_flow_len,padding=True):\n",
        "    norm_X = []\n",
        "    for sample in X:\n",
        "        if sample.shape[0] > max_flow_len: # if the sample is bigger than expected, we cut the sample\n",
        "            sample = sample[:max_flow_len,...]\n",
        "        packet_nr = sample.shape[0] # number of packets in one sample\n",
        "\n",
        "        norm_sample = scale_linear_bycolumn(sample, mins, maxs, high=1.0, low=0.0)\n",
        "        np.nan_to_num(norm_sample, copy=False)  # remove NaN from the array\n",
        "        if padding == True:\n",
        "            norm_sample = np.pad(norm_sample, ((0, max_flow_len - packet_nr), (0, 0)), 'constant',constant_values=(0, 0))  # padding\n",
        "        norm_X.append(norm_sample)\n",
        "    return norm_X\n",
        "\n",
        "def padding(X,max_flow_len):\n",
        "    padded_X = []\n",
        "    for sample in X:\n",
        "        flow_nr = sample.shape[0]\n",
        "        padded_sample = np.pad(sample, ((0, max_flow_len - flow_nr), (0, 0)), 'constant',\n",
        "                              constant_values=(0, 0))  # padding\n",
        "        padded_X.append(padded_sample)\n",
        "    return padded_X"
      ],
      "metadata": {
        "id": "0Ek4bUOZtE1x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parser**"
      ],
      "metadata": {
        "id": "-Mzma0n5tncE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time\n",
        "import pyshark\n",
        "import socket\n",
        "import pickle\n",
        "import random\n",
        "import hashlib\n",
        "import argparse\n",
        "import ipaddress\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from multiprocessing import Process, Manager, Value, Queue\n",
        "\n",
        "# Sample commands\n",
        "# split a pcap file into smaller chunks to leverage multi-core CPUs: tcpdump -r dataset.pcap -w dataset-chunk -C 1000\n",
        "# dataset parsing (first step): python3 lucid_dataset_parser.py --dataset_type SYN2020 --dataset_folder ./sample-dataset/ --packets_per_flow 10 --dataset_id SYN2020 --traffic_type all --time_window 10\n",
        "# dataset parsing (second step): python3 lucid_dataset_parser.py --preprocess_folder ./sample-dataset/\n",
        "\n",
        "IDS2018_DDOS_FLOWS = {'attackers': ['18.218.115.60', '18.219.9.1','18.219.32.43','18.218.55.126','52.14.136.135','18.219.5.43','18.216.200.189','18.218.229.235','18.218.11.51','18.216.24.42'],\n",
        "                      'victims': ['18.218.83.150','172.31.69.28']}\n",
        "\n",
        "IDS2017_DDOS_FLOWS = {'attackers': ['172.16.0.1'],\n",
        "                      'victims': ['192.168.10.50']}\n",
        "\n",
        "CUSTOM_DDOS_SYN = {'attackers': ['11.0.0.' + str(x) for x in range(1,255)],\n",
        "                      'victims': ['10.42.0.2']}\n",
        "\n",
        "DOS2019_FLOWS = {'attackers': ['172.16.0.5'], 'victims': ['192.168.50.1', '192.168.50.4']}\n",
        "\n",
        "DDOS_ATTACK_SPECS = {\n",
        "    'DOS2017' : IDS2017_DDOS_FLOWS,\n",
        "    'DOS2018' : IDS2018_DDOS_FLOWS,\n",
        "    'SYN2020' : CUSTOM_DDOS_SYN,\n",
        "    'DOS2019': DOS2019_FLOWS\n",
        "}\n",
        "\n",
        "\n",
        "vector_proto = CountVectorizer()\n",
        "vector_proto.fit_transform(protocols).todense()\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "class packet_features:\n",
        "    def __init__(self):\n",
        "        self.id_fwd = (0,0,0,0,0) # 5-tuple src_ip_addr, src_port,,dst_ip_addr,dst_port,protocol\n",
        "        self.id_bwd = (0,0,0,0,0)  # 5-tuple src_ip_addr, src_port,,dst_ip_addr,dst_port,protocol\n",
        "        self.features_list = []\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"{} -> {}\".format(self.id_fwd, self.features_list)\n",
        "\n",
        "def get_ddos_flows(attackers,victims):\n",
        "    DDOS_FLOWS = {}\n",
        "\n",
        "    if '/' in attackers: # subnet\n",
        "        DDOS_FLOWS['attackers'] = [str(ip) for ip in list(ipaddress.IPv4Network(attackers).hosts())]\n",
        "    else: # single address\n",
        "        DDOS_FLOWS['attackers'] = [str(ipaddress.IPv4Address(attackers))]\n",
        "\n",
        "    if '/' in victims:  # subnet\n",
        "        DDOS_FLOWS['victims'] = [str(ip) for ip in list(ipaddress.IPv4Network(victims).hosts())]\n",
        "    else:  # single address\n",
        "        DDOS_FLOWS['victims'] = [str(ipaddress.IPv4Address(victims))]\n",
        "\n",
        "    return DDOS_FLOWS\n",
        "\n",
        "# function that build the labels based on the dataset type\n",
        "def parse_labels(dataset_type=None, attackers=None,victims=None, label=1):\n",
        "    output_dict = {}\n",
        "\n",
        "    if attackers is not None and victims is not None:\n",
        "        DDOS_FLOWS = get_ddos_flows(attackers, victims)\n",
        "    elif dataset_type is not None and dataset_type in DDOS_ATTACK_SPECS:\n",
        "        DDOS_FLOWS = DDOS_ATTACK_SPECS[dataset_type]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    for attacker in DDOS_FLOWS['attackers']:\n",
        "        for victim in DDOS_FLOWS['victims']:\n",
        "            ip_src = str(attacker)\n",
        "            ip_dst = str(victim)\n",
        "            key_fwd = (ip_src, ip_dst)\n",
        "            key_bwd = (ip_dst, ip_src)\n",
        "\n",
        "            if key_fwd not in output_dict:\n",
        "                output_dict[key_fwd] = label\n",
        "            if key_bwd not in output_dict:\n",
        "                output_dict[key_bwd] = label\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "def parse_packet(pkt):\n",
        "    pf = packet_features()\n",
        "    tmp_id = [0,0,0,0,0]\n",
        "\n",
        "    try:\n",
        "        pf.features_list.append(float(pkt.sniff_timestamp))  # timestampchild.find('Tag').text\n",
        "        pf.features_list.append(int(pkt.ip.len))  # packet length\n",
        "        pf.features_list.append(int(hashlib.sha256(str(pkt.highest_layer).encode('utf-8')).hexdigest(),\n",
        "                                    16) % 10 ** 8)  # highest layer in the packet\n",
        "        pf.features_list.append(int(int(pkt.ip.flags, 16)))  # IP flags\n",
        "        tmp_id[0] = str(pkt.ip.src)  # int(ipaddress.IPv4Address(pkt.ip.src))\n",
        "        tmp_id[2] = str(pkt.ip.dst)  # int(ipaddress.IPv4Address(pkt.ip.dst))\n",
        "\n",
        "        protocols = vector_proto.transform([pkt.frame_info.protocols]).toarray().tolist()[0]\n",
        "        protocols = [1 if i >= 1 else 0 for i in\n",
        "                     protocols]  # we do not want the protocols counted more than once (sometimes they are listed twice in pkt.frame_info.protocols)\n",
        "        protocols_value = int(np.dot(np.array(protocols), powers_of_two))\n",
        "        pf.features_list.append(protocols_value)\n",
        "\n",
        "        protocol = int(pkt.ip.proto)\n",
        "        tmp_id[4] = protocol\n",
        "        if pkt.transport_layer != None:\n",
        "            if protocol == socket.IPPROTO_TCP:\n",
        "                tmp_id[1] = int(pkt.tcp.srcport)\n",
        "                tmp_id[3] = int(pkt.tcp.dstport)\n",
        "                pf.features_list.append(int(pkt.tcp.len))  # TCP length\n",
        "                pf.features_list.append(int(pkt.tcp.ack))  # TCP ack\n",
        "                pf.features_list.append(int(pkt.tcp.flags, 16))  # TCP flags\n",
        "                pf.features_list.append(int(pkt.tcp.window_size_value))  # TCP window size\n",
        "                pf.features_list = pf.features_list + [0, 0]  # UDP + ICMP positions\n",
        "            elif protocol == socket.IPPROTO_UDP:\n",
        "                pf.features_list = pf.features_list + [0, 0, 0, 0]  # TCP positions\n",
        "                tmp_id[1] = int(pkt.udp.srcport)\n",
        "                pf.features_list.append(int(pkt.udp.length))  # UDP length\n",
        "                tmp_id[3] = int(pkt.udp.dstport)\n",
        "                pf.features_list = pf.features_list + [0]  # ICMP position\n",
        "        elif protocol == socket.IPPROTO_ICMP:\n",
        "            pf.features_list = pf.features_list + [0, 0, 0, 0, 0]  # TCP and UDP positions\n",
        "            pf.features_list.append(int(pkt.icmp.type))  # ICMP type\n",
        "        else:\n",
        "            pf.features_list = pf.features_list + [0, 0, 0, 0, 0, 0]  # padding for layer3-only packets\n",
        "            tmp_id[4] = 0\n",
        "\n",
        "        pf.id_fwd = (tmp_id[0], tmp_id[1], tmp_id[2], tmp_id[3], tmp_id[4])\n",
        "        pf.id_bwd = (tmp_id[2], tmp_id[3], tmp_id[0], tmp_id[1], tmp_id[4])\n",
        "\n",
        "        return pf\n",
        "\n",
        "    except AttributeError as e:\n",
        "        # ignore packets that aren't TCP/UDP or IPv4\n",
        "        return None\n",
        "\n",
        "# Offline preprocessing of pcap files for model training, validation and testing\n",
        "def process_pcap(pcap_file,dataset_type,in_labels,max_flow_len,labelled_flows,max_flows=0, traffic_type='all',time_window=TIME_WINDOW):\n",
        "    start_time = time.time()\n",
        "    temp_dict = OrderedDict()\n",
        "    start_time_window = -1\n",
        "\n",
        "    pcap_name = pcap_file.split(\"/\")[-1]\n",
        "    print(\"Processing file: \", pcap_name)\n",
        "\n",
        "    cap = pyshark.FileCapture(pcap_file)\n",
        "    for i, pkt in enumerate(cap):\n",
        "        if i % 1000 == 0:\n",
        "            print(pcap_name + \" packet #\", i)\n",
        "\n",
        "        # start_time_window is used to group packets/flows captured in a time-window\n",
        "        if start_time_window == -1 or float(pkt.sniff_timestamp) > start_time_window + time_window:\n",
        "            start_time_window = float(pkt.sniff_timestamp)\n",
        "\n",
        "        pf = parse_packet(pkt)\n",
        "        store_packet(pf, temp_dict, start_time_window, max_flow_len)\n",
        "        if max_flows > 0 and len(temp_dict) >= max_flows:\n",
        "            break\n",
        "\n",
        "    apply_labels(temp_dict, labelled_flows, in_labels, traffic_type)\n",
        "    print('Completed file {} in {} seconds.'.format(pcap_name, time.time() - start_time))\n",
        "\n",
        "# Transforms live traffic into input samples for inference\n",
        "def process_live_traffic(cap, dataset_type, in_labels, max_flow_len, traffic_type='all',time_window=TIME_WINDOW):\n",
        "    start_time = time.time()\n",
        "    temp_dict = OrderedDict()\n",
        "    labelled_flows = []\n",
        "\n",
        "    start_time_window = start_time\n",
        "    time_window = start_time_window + time_window\n",
        "\n",
        "    if isinstance(cap, pyshark.LiveCapture) == True:\n",
        "        for pkt in cap.sniff_continuously():\n",
        "            if time.time() >= time_window:\n",
        "                break\n",
        "            pf = parse_packet(pkt)\n",
        "            temp_dict = store_packet(pf, temp_dict, start_time_window, max_flow_len)\n",
        "    elif isinstance(cap, pyshark.FileCapture) == True:\n",
        "        while time.time() < time_window:\n",
        "            try:\n",
        "                pkt = cap.next()\n",
        "                pf = parse_packet(pkt)\n",
        "                temp_dict = store_packet(pf,temp_dict,start_time_window,max_flow_len)\n",
        "            except:\n",
        "                break\n",
        "\n",
        "    apply_labels(temp_dict,labelled_flows, in_labels,traffic_type)\n",
        "    return labelled_flows\n",
        "\n",
        "def store_packet(pf,temp_dict,start_time_window, max_flow_len):\n",
        "    if pf is not None:\n",
        "        if pf.id_fwd in temp_dict and start_time_window in temp_dict[pf.id_fwd] and \\\n",
        "                temp_dict[pf.id_fwd][start_time_window].shape[0] < max_flow_len:\n",
        "            temp_dict[pf.id_fwd][start_time_window] = np.vstack(\n",
        "                [temp_dict[pf.id_fwd][start_time_window], pf.features_list])\n",
        "        elif pf.id_bwd in temp_dict and start_time_window in temp_dict[pf.id_bwd] and \\\n",
        "                temp_dict[pf.id_bwd][start_time_window].shape[0] < max_flow_len:\n",
        "            temp_dict[pf.id_bwd][start_time_window] = np.vstack(\n",
        "                [temp_dict[pf.id_bwd][start_time_window], pf.features_list])\n",
        "        else:\n",
        "            if pf.id_fwd not in temp_dict and pf.id_bwd not in temp_dict:\n",
        "                temp_dict[pf.id_fwd] = {start_time_window: np.array([pf.features_list]), 'label': 0}\n",
        "            elif pf.id_fwd in temp_dict and start_time_window not in temp_dict[pf.id_fwd]:\n",
        "                temp_dict[pf.id_fwd][start_time_window] = np.array([pf.features_list])\n",
        "            elif pf.id_bwd in temp_dict and start_time_window not in temp_dict[pf.id_bwd]:\n",
        "                temp_dict[pf.id_bwd][start_time_window] = np.array([pf.features_list])\n",
        "    return temp_dict\n",
        "\n",
        "def apply_labels(flows, labelled_flows, labels, traffic_type):\n",
        "    for five_tuple, flow in flows.items():\n",
        "        if labels is not None:\n",
        "            short_key = (five_tuple[0], five_tuple[2])  # for IDS2017/IDS2018 dataset the labels have shorter keys\n",
        "            flow['label'] = labels.get(short_key, 0)\n",
        "\n",
        "        for flow_key, packet_list in flow.items():\n",
        "            # relative time wrt the time of the first packet in the flow\n",
        "            if flow_key != 'label':\n",
        "                amin = np.amin(packet_list,axis=0)[0]\n",
        "                packet_list[:, 0] = packet_list[:, 0] - amin\n",
        "\n",
        "        if traffic_type == 'ddos' and flow['label'] == 0: # we only want malicious flows from this dataset\n",
        "            continue\n",
        "        elif traffic_type == 'benign' and flow['label'] > 0: # we only want benign flows from this dataset\n",
        "            continue\n",
        "        else:\n",
        "            labelled_flows.append((five_tuple,flow))\n",
        "\n",
        "# returns the total number of flows\n",
        "def count_flows(preprocessed_flows):\n",
        "    ddos_flows = 0\n",
        "    total_flows = len(preprocessed_flows)\n",
        "    ddos_fragments = 0\n",
        "    total_fragments = 0\n",
        "    for flow in preprocessed_flows:\n",
        "        flow_fragments = len(flow[1]) - 1\n",
        "        total_fragments += flow_fragments\n",
        "        if flow[1]['label'] > 0:\n",
        "            ddos_flows += 1\n",
        "            ddos_fragments += flow_fragments  # the label does not count\n",
        "\n",
        "    return (total_flows, ddos_flows, total_flows - ddos_flows), (total_fragments, ddos_fragments, total_fragments-ddos_fragments)\n",
        "\n",
        "# balance the dataset based on the number of benign and malicious fragments of flows\n",
        "def balance_dataset(flows,total_fragments=float('inf')):\n",
        "    new_flow_list = []\n",
        "\n",
        "    _,(_, ddos_fragments, benign_fragments) = count_flows(flows)\n",
        "\n",
        "    if ddos_fragments == 0 or benign_fragments == 0:\n",
        "        min_fragments = total_fragments\n",
        "    else:\n",
        "        min_fragments = min(total_fragments/2,ddos_fragments,benign_fragments)\n",
        "\n",
        "    random.shuffle(flows)\n",
        "    new_benign_fragments = 0\n",
        "    new_ddos_fragments = 0\n",
        "\n",
        "    for flow in flows:\n",
        "        if flow[1]['label'] == 0 and (new_benign_fragments < min_fragments ):\n",
        "            new_benign_fragments += len(flow[1]) - 1\n",
        "            new_flow_list.append(flow)\n",
        "        elif flow[1]['label'] > 0 and (new_ddos_fragments < min_fragments):\n",
        "            new_ddos_fragments += len(flow[1]) - 1\n",
        "            new_flow_list.append(flow)\n",
        "\n",
        "    return new_flow_list, new_benign_fragments, new_ddos_fragments\n",
        "\n",
        "# convert the dataset from dictionaries with 5-tuples keys into a list of flow fragments and another list of labels\n",
        "def dataset_to_list_of_fragments(dataset):\n",
        "    keys = []\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for flow in dataset:\n",
        "        tuple = flow[0]\n",
        "        flow_data = flow[1]\n",
        "        label = flow_data['label']\n",
        "        for key, fragment in flow_data.items():\n",
        "            if key != 'label':\n",
        "                X.append(fragment)\n",
        "                y.append(label)\n",
        "                keys.append(tuple)\n",
        "\n",
        "    return X,y,keys\n",
        "\n",
        "def train_test_split(flow_list,train_size=TRAIN_SIZE, shuffle=True):\n",
        "    test_list = []\n",
        "    _,(total_examples,_,_) = count_flows(flow_list)\n",
        "    test_examples = total_examples - total_examples*train_size\n",
        "\n",
        "    if shuffle == True:\n",
        "        random.shuffle(flow_list)\n",
        "\n",
        "    current_test_examples = 0\n",
        "    while current_test_examples < test_examples:\n",
        "        flow = flow_list.pop(0)\n",
        "        test_list.append(flow)\n",
        "        current_test_examples += len(flow[1])-1\n",
        "\n",
        "\n",
        "    return flow_list,test_list\n",
        "\n",
        "def main(argv):\n",
        "    command_options = \" \".join(str(x) for x in argv[1:])\n",
        "\n",
        "    help_string = 'Usage[0]: python3 lucid_dataset_parser.py --dataset_type <dataset_name> --dataset_folder <folder path> --dataset_id <dataset identifier> --packets_per_flow <n> --time_window <t>\\n' \\\n",
        "                  'Usage[1]: python3 lucid_dataset_parser.py --preprocess_folder <folder path>'\n",
        "    manager = Manager()\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Dataset parser',\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "\n",
        "    parser.add_argument('-d', '--dataset_folder', nargs='+', type=str,\n",
        "                        help='Folder with the dataset')\n",
        "    parser.add_argument('-o', '--output_folder', nargs='+', type=str,\n",
        "                        help='Output folder')\n",
        "    parser.add_argument('-f', '--traffic_type', default='all', nargs='+', type=str,\n",
        "                        help='Type of flow to process (all, benign, ddos)')\n",
        "    parser.add_argument('-p', '--preprocess_folder', nargs='+', type=str,\n",
        "                        help='Folder with preprocessed data')\n",
        "    parser.add_argument('--preprocess_file', nargs='+', type=str,\n",
        "                        help='File with preprocessed data')\n",
        "    parser.add_argument('-b', '--balance_folder', nargs='+', type=str,\n",
        "                        help='Folder where balancing datasets')\n",
        "    parser.add_argument('-n', '--packets_per_flow', nargs='+', type=str,\n",
        "                        help='Packet per flow sample')\n",
        "    parser.add_argument('-s', '--samples', default=float('inf'), type=int,\n",
        "                        help='Number of training samples in the reduced output')\n",
        "    parser.add_argument('-i', '--dataset_id', nargs='+', type=str,\n",
        "                        help='String to append to the names of output files')\n",
        "    parser.add_argument('-m', '--max_flows', default=0, type=int,\n",
        "                        help='Max number of flows to extract from the pcap files')\n",
        "    parser.add_argument('-l', '--label', default=1, type=int,\n",
        "                        help='Label assigned to the DDoS class')\n",
        "\n",
        "    parser.add_argument('-t', '--dataset_type', nargs='+', type=str,\n",
        "                        help='Type of the dataset. Available options are: DOS2017, DOS2018, DOS2019, SYN2020')\n",
        "\n",
        "    parser.add_argument('-w', '--time_window', nargs='+', type=str,\n",
        "                        help='Length of the time window')\n",
        "\n",
        "    parser.add_argument('--no_split', help='Do not split the dataset', action='store_true')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.packets_per_flow is not None:\n",
        "        max_flow_len = int(args.packets_per_flow[0])\n",
        "    else:\n",
        "        max_flow_len = MAX_FLOW_LEN\n",
        "\n",
        "    if args.time_window is not None:\n",
        "        time_window = float(args.time_window[0])\n",
        "    else:\n",
        "        time_window = TIME_WINDOW\n",
        "\n",
        "    if args.dataset_id is not None:\n",
        "        dataset_id = str(args.dataset_id[0])\n",
        "    else:\n",
        "        dataset_id = ''\n",
        "\n",
        "    if args.traffic_type is not None:\n",
        "        traffic_type = str(args.traffic_type[0])\n",
        "    else:\n",
        "        traffic_type = 'all'\n",
        "\n",
        "    if args.dataset_folder is not None and args.dataset_type is not None:\n",
        "        process_list = []\n",
        "        flows_list = []\n",
        "\n",
        "        if args.output_folder is not None and os.path.isdir(args.output_folder[0]) is True:\n",
        "            output_folder = args.output_folder[0]\n",
        "        else:\n",
        "            output_folder = args.dataset_folder[0]\n",
        "\n",
        "        filelist = glob.glob(args.dataset_folder[0]+ '/*.pcap')\n",
        "        in_labels = parse_labels(args.dataset_type[0],args.dataset_folder[0],label=args.label)\n",
        "\n",
        "        start_time = time.time()\n",
        "        for file in filelist:\n",
        "            try:\n",
        "                flows = manager.list()\n",
        "                p = Process(target=process_pcap,args=(file,args.dataset_type[0],in_labels,max_flow_len,flows,args.max_flows, traffic_type,time_window))\n",
        "                process_list.append(p)\n",
        "                flows_list.append(flows)\n",
        "            except FileNotFoundError as e:\n",
        "                continue\n",
        "\n",
        "        for p in process_list:\n",
        "            p.start()\n",
        "\n",
        "        for p in process_list:\n",
        "            p.join()\n",
        "\n",
        "        np.seterr(divide='ignore', invalid='ignore')\n",
        "        try:\n",
        "            preprocessed_flows = list(flows_list[0])\n",
        "        except:\n",
        "            print (\"ERROR: No traffic flows. \\nPlease check that the dataset folder name (\" + args.dataset_folder[0] + \") is correct and \\nthe folder contains the traffic traces in pcap format (the pcap extension is mandatory)\")\n",
        "            exit(1)\n",
        "\n",
        "        #concatenation of the features\n",
        "        for results in flows_list[1:]:\n",
        "            preprocessed_flows = preprocessed_flows + list(results)\n",
        "\n",
        "        process_time = time.time()-start_time\n",
        "\n",
        "        if dataset_id == '':\n",
        "            dataset_id = str(args.dataset_type[0])\n",
        "\n",
        "        filename = str(int(time_window)) + 't-' + str(max_flow_len) + 'n-' + dataset_id + '-preprocess'\n",
        "        output_file = output_folder + '/' + filename\n",
        "        output_file = output_file.replace(\"//\", \"/\") # remove double slashes when needed\n",
        "\n",
        "        with open(output_file + '.data', 'wb') as filehandle:\n",
        "            # store the data as binary data stream\n",
        "            pickle.dump(preprocessed_flows, filehandle)\n",
        "\n",
        "\n",
        "        (total_flows, ddos_flows, benign_flows),  (total_fragments, ddos_fragments, benign_fragments) = count_flows(preprocessed_flows)\n",
        "\n",
        "        log_string = time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" | dataset_type:\" + args.dataset_type[0] + \\\n",
        "                     \" | flows (tot,ben,ddos):(\" + str(total_flows) + \",\" + str(benign_flows) + \",\" + str(ddos_flows) + \\\n",
        "                     \") | fragments (tot,ben,ddos):(\" + str(total_fragments) + \",\" + str(benign_fragments) + \",\" + str(ddos_fragments) + \\\n",
        "                     \") | options:\" + command_options + \" | process_time:\" + str(process_time) + \" |\\n\"\n",
        "        print (log_string)\n",
        "\n",
        "        # saving log file\n",
        "        with open(output_folder + '/history.log', \"a\") as myfile:\n",
        "            myfile.write(log_string)\n",
        "\n",
        "    if args.preprocess_folder is not None or args.preprocess_file is not None:\n",
        "        if args.preprocess_folder is not None:\n",
        "            output_folder = args.output_folder[0] if args.output_folder is not None else args.preprocess_folder[0]\n",
        "            filelist = glob.glob(args.preprocess_folder[0] + '/*.data')\n",
        "        else:\n",
        "            output_folder = args.output_folder[0] if args.output_folder is not None else os.path.dirname(os.path.realpath(args.preprocess_file[0]))\n",
        "            filelist = args.preprocess_file\n",
        "\n",
        "        # obtain time_window and flow_len from filename and ensure that all files have the same values\n",
        "        time_window = None\n",
        "        max_flow_len = None\n",
        "        dataset_id = None\n",
        "        for file in filelist:\n",
        "            filename = file.split('/')[-1].strip()\n",
        "            current_time_window = int(filename.split('-')[0].strip().replace('t',''))\n",
        "            current_max_flow_len = int(filename.split('-')[1].strip().replace('n',''))\n",
        "            current_dataset_id = str(filename.split('-')[2].strip())\n",
        "            if time_window != None and current_time_window != time_window:\n",
        "                print (\"Incosistent time windows!!\")\n",
        "                exit()\n",
        "            else:\n",
        "                time_window = current_time_window\n",
        "            if max_flow_len != None and current_max_flow_len != max_flow_len:\n",
        "                print (\"Incosistent flow lengths!!\")\n",
        "                exit()\n",
        "            else:\n",
        "                max_flow_len = current_max_flow_len\n",
        "\n",
        "            if dataset_id != None and current_dataset_id != dataset_id:\n",
        "                dataset_id = \"IDS201X\"\n",
        "            else:\n",
        "                dataset_id = current_dataset_id\n",
        "\n",
        "\n",
        "\n",
        "        preprocessed_flows = []\n",
        "        for file in filelist:\n",
        "            with open(file, 'rb') as filehandle:\n",
        "                # read the data as binary data stream\n",
        "                preprocessed_flows = preprocessed_flows + pickle.load(filehandle)\n",
        "\n",
        "\n",
        "        # balance samples and redux the number of samples when requested\n",
        "        preprocessed_flows, benign_fragments, ddos_fragments = balance_dataset(preprocessed_flows,args.samples)\n",
        "\n",
        "        if len(preprocessed_flows) == 0:\n",
        "            print(\"Empty dataset!\")\n",
        "            exit()\n",
        "\n",
        "        preprocessed_train, preprocessed_test = train_test_split(preprocessed_flows,train_size=TRAIN_SIZE, shuffle=True)\n",
        "        preprocessed_train, preprocessed_val = train_test_split(preprocessed_train, train_size=TRAIN_SIZE, shuffle=True)\n",
        "\n",
        "        X_train, y_train, _ = dataset_to_list_of_fragments(preprocessed_train)\n",
        "        X_val, y_val, _ = dataset_to_list_of_fragments(preprocessed_val)\n",
        "        X_test, y_test, _ = dataset_to_list_of_fragments(preprocessed_test)\n",
        "\n",
        "        # normalization and padding\n",
        "        X_full = X_train + X_val + X_test\n",
        "        y_full = y_train + y_val + y_test\n",
        "        mins,maxs = static_min_max(time_window=time_window)\n",
        "\n",
        "        total_examples = len(y_full)\n",
        "        total_ddos_examples = np.count_nonzero(y_full)\n",
        "        total_benign_examples = total_examples - total_ddos_examples\n",
        "\n",
        "        output_file = output_folder + '/' + str(time_window) + 't-' + str(max_flow_len) + 'n-' + dataset_id + '-dataset'\n",
        "        if args.no_split == True: # don't split the dataset\n",
        "            norm_X_full = normalize_and_padding(X_full, mins, maxs, max_flow_len)\n",
        "            #norm_X_full = padding(X_full,max_flow_len) # only padding\n",
        "            norm_X_full_np = np.array(norm_X_full)\n",
        "            y_full_np = np.array(y_full)\n",
        "\n",
        "            hf = h5py.File(output_file + '-full.hdf5', 'w')\n",
        "            hf.create_dataset('set_x', data=norm_X_full_np)\n",
        "            hf.create_dataset('set_y', data=y_full_np)\n",
        "            hf.close()\n",
        "\n",
        "            [full_packets] = count_packets_in_dataset([norm_X_full_np])\n",
        "            log_string = time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" | Total examples (tot,ben,ddos):(\" + str(total_examples) + \",\" + str(total_benign_examples) + \",\" + str(total_ddos_examples) + \\\n",
        "                         \") | Total packets:(\" + str(full_packets) + \\\n",
        "                         \") | options:\" + command_options + \" |\\n\"\n",
        "        else:\n",
        "            norm_X_train = normalize_and_padding(X_train,mins,maxs,max_flow_len)\n",
        "            norm_X_val = normalize_and_padding(X_val, mins, maxs, max_flow_len)\n",
        "            norm_X_test = normalize_and_padding(X_test, mins, maxs, max_flow_len)\n",
        "\n",
        "            norm_X_train_np = np.array(norm_X_train)\n",
        "            y_train_np = np.array(y_train)\n",
        "            norm_X_val_np = np.array(norm_X_val)\n",
        "            y_val_np = np.array(y_val)\n",
        "            norm_X_test_np = np.array(norm_X_test)\n",
        "            y_test_np = np.array(y_test)\n",
        "\n",
        "            hf = h5py.File(output_file + '-train.hdf5', 'w')\n",
        "            hf.create_dataset('set_x', data=norm_X_train_np)\n",
        "            hf.create_dataset('set_y', data=y_train_np)\n",
        "            hf.close()\n",
        "\n",
        "            hf = h5py.File(output_file + '-val.hdf5', 'w')\n",
        "            hf.create_dataset('set_x', data=norm_X_val_np)\n",
        "            hf.create_dataset('set_y', data=y_val_np)\n",
        "            hf.close()\n",
        "\n",
        "            hf = h5py.File(output_file + '-test.hdf5', 'w')\n",
        "            hf.create_dataset('set_x', data=norm_X_test_np)\n",
        "            hf.create_dataset('set_y', data=y_test_np)\n",
        "            hf.close()\n",
        "\n",
        "            [train_packets, val_packets, test_packets] = count_packets_in_dataset([norm_X_train_np, norm_X_val_np, norm_X_test_np])\n",
        "            log_string = time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" | examples (tot,ben,ddos):(\" + str(total_examples) + \",\" + str(total_benign_examples) + \",\" + str(total_ddos_examples) + \\\n",
        "                         \") | Train/Val/Test sizes: (\" + str(norm_X_train_np.shape[0]) + \",\" + str(norm_X_val_np.shape[0]) + \",\" + str(norm_X_test_np.shape[0]) + \\\n",
        "                         \") | Packets (train,val,test):(\" + str(train_packets) + \",\" + str(val_packets) + \",\" + str(test_packets) + \\\n",
        "                         \") | options:\" + command_options + \" |\\n\"\n",
        "\n",
        "        print(log_string)\n",
        "\n",
        "        # saving log file\n",
        "        with open(output_folder + '/history.log', \"a\") as myfile:\n",
        "            myfile.write(log_string)\n",
        "\n",
        "    if args.balance_folder is not None and args.output_folder is not None:\n",
        "        output_folder = args.output_folder[0] if args.output_folder is not None else args.balance_folder[0]\n",
        "        datasets = []\n",
        "        for folder in args.balance_folder:\n",
        "            datasets += glob.glob(folder + '/*.hdf5')\n",
        "        train_filelist = {}\n",
        "        val_filelist = {}\n",
        "        test_filelist = {}\n",
        "        min_samples_train = float('inf')\n",
        "        min_samples_val = float('inf')\n",
        "        min_samples_test = float('inf')\n",
        "\n",
        "        output_filename_prefix = None\n",
        "\n",
        "        for file in datasets:\n",
        "            filename = file.split('/')[-1].strip()\n",
        "            dataset = h5py.File(file, \"r\")\n",
        "            X = np.array(dataset[\"set_x\"][:])  # features\n",
        "            Y = np.array(dataset[\"set_y\"][:])  # labels\n",
        "            if 'train' in filename:\n",
        "                key = filename.split('dataset')[0].strip() + 'dataset-balanced-train.hdf5'\n",
        "                if output_filename_prefix ==None:\n",
        "                    output_filename_prefix = filename.split('IDS')[0].strip()\n",
        "                else:\n",
        "                    if filename.split('IDS')[0].strip() != output_filename_prefix:\n",
        "                        print (\"Inconsistent datasets!\")\n",
        "                        exit()\n",
        "                train_filelist[key] = (X,Y)\n",
        "                if X.shape[0] < min_samples_train:\n",
        "                    min_samples_train = X.shape[0]\n",
        "            elif 'val' in filename:\n",
        "                key = filename.split('dataset')[0].strip() + 'dataset-balanced-val.hdf5'\n",
        "                if output_filename_prefix ==None:\n",
        "                    output_filename_prefix = filename.split('IDS')[0].strip()\n",
        "                else:\n",
        "                    if filename.split('IDS')[0].strip() != output_filename_prefix:\n",
        "                        print (\"Inconsistent datasets!\")\n",
        "                        exit()\n",
        "                val_filelist[key] = (X,Y)\n",
        "                if X.shape[0] < min_samples_val:\n",
        "                    min_samples_val = X.shape[0]\n",
        "            elif 'test' in filename:\n",
        "                key = filename.split('dataset')[0].strip() + 'dataset-balanced-test.hdf5'\n",
        "                if output_filename_prefix ==None:\n",
        "                    output_filename_prefix = filename.split('IDS')[0].strip()\n",
        "                else:\n",
        "                    if filename.split('IDS')[0].strip() != output_filename_prefix:\n",
        "                        print (\"Inconsistent datasets!\")\n",
        "                        exit()\n",
        "                test_filelist[key] = (X, Y)\n",
        "                if X.shape[0] < min_samples_test:\n",
        "                    min_samples_test = X.shape[0]\n",
        "\n",
        "        final_X = {'train':None,'val':None,'test':None}\n",
        "        final_y = {'train':None,'val':None,'test':None}\n",
        "\n",
        "        for key,value in train_filelist.items():\n",
        "            X_short = value[0][:min_samples_train,...]\n",
        "            y_short = value[1][:min_samples_train,...]\n",
        "\n",
        "            if final_X['train'] is None:\n",
        "                final_X['train'] = X_short\n",
        "                final_y['train'] = y_short\n",
        "            else:\n",
        "                final_X['train'] = np.vstack((final_X['train'],X_short))\n",
        "                final_y['train'] = np.hstack((final_y['train'],y_short))\n",
        "\n",
        "        for key,value in val_filelist.items():\n",
        "            X_short = value[0][:min_samples_val,...]\n",
        "            y_short = value[1][:min_samples_val,...]\n",
        "\n",
        "            if final_X['val'] is None:\n",
        "                final_X['val'] = X_short\n",
        "                final_y['val'] = y_short\n",
        "            else:\n",
        "                final_X['val'] = np.vstack((final_X['val'],X_short))\n",
        "                final_y['val'] = np.hstack((final_y['val'],y_short))\n",
        "\n",
        "\n",
        "        for key,value in test_filelist.items():\n",
        "            X_short = value[0][:min_samples_test,...]\n",
        "            y_short = value[1][:min_samples_test,...]\n",
        "\n",
        "            if final_X['test'] is None:\n",
        "                final_X['test'] = X_short\n",
        "                final_y['test'] = y_short\n",
        "            else:\n",
        "                final_X['test'] = np.vstack((final_X['test'],X_short))\n",
        "                final_y['test'] = np.hstack((final_y['test'],y_short))\n",
        "\n",
        "        for key,value in final_X.items():\n",
        "            filename = output_filename_prefix + 'IDS201X-dataset-balanced-' + key + '.hdf5'\n",
        "            hf = h5py.File(output_folder + '/' + filename, 'w')\n",
        "            hf.create_dataset('set_x', data=value)\n",
        "            hf.create_dataset('set_y', data=final_y[key])\n",
        "            hf.close()\n",
        "\n",
        "        total_flows = final_y['train'].shape[0]+final_y['val'].shape[0]+final_y['test'].shape[0]\n",
        "        ddos_flows = np.count_nonzero(final_y['train'])+np.count_nonzero(final_y['val'])+np.count_nonzero(final_y['test'])\n",
        "        benign_flows = total_flows-ddos_flows\n",
        "        [train_packets, val_packets, test_packets] = count_packets_in_dataset([final_X['train'], final_X['val'], final_X['test']])\n",
        "        log_string = time.strftime(\"%Y-%m-%d %H:%M:%S\") + \" | total_flows (tot,ben,ddos):(\" + str(total_flows) + \",\" + str(benign_flows) + \",\" + str(ddos_flows) + \\\n",
        "                     \") | Packets (train,val,test):(\" + str(train_packets) + \",\" + str(val_packets) + \",\" + str(test_packets) + \\\n",
        "                     \") | Train/Val/Test sizes: (\" + str(final_y['train'].shape[0]) + \",\" + str(final_y['val'].shape[0]) + \",\" + str(final_y['test'].shape[0]) + \\\n",
        "                     \") | options:\" + command_options + \" |\\n\"\n",
        "\n",
        "        print(log_string)\n",
        "\n",
        "        # saving log file\n",
        "        with open(output_folder + '/history.log', \"a\") as myfile:\n",
        "            myfile.write(log_string)\n",
        "\n",
        "\n",
        "    if args.dataset_folder is None and args.preprocess_folder is None and args.preprocess_file is None and args.balance_folder is None:\n",
        "        print (help_string)\n",
        "    if args.dataset_type is None and args.dataset_folder is not None:\n",
        "        print(\"Please specify the dataset type (DOS2017, DOS2018, DOS2020)!\")\n",
        "        print(help_string)\n",
        "    if args.output_folder is None and args.balance_folder is not None:\n",
        "        print(\"Please specify the output folder!\")\n",
        "        print(help_string)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(sys.argv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjpmYowdtqiK",
        "outputId": "72a197d2-dc08-4db5-bb03-1973a79fe54c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage[0]: python3 lucid_dataset_parser.py --dataset_type <dataset_name> --dataset_folder <folder path> --dataset_id <dataset identifier> --packets_per_flow <n> --time_window <t>\n",
            "Usage[1]: python3 lucid_dataset_parser.py --preprocess_folder <folder path>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN Script**"
      ],
      "metadata": {
        "id": "RQsKa5ZhtVux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-vhZGsHN6NXK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import os\n",
        "import csv\n",
        "import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Conv2D\n",
        "from tensorflow.keras.layers import Dropout, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential, load_model, save_model\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SEED\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "rn.seed(SEED)\n",
        "config = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=1)"
      ],
      "metadata": {
        "id": "QVKmjAq3sw0r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "tf.random.set_seed(SEED)\n",
        "K.set_image_data_format('channels_last')\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "config.gpu_options.allow_growth = True"
      ],
      "metadata": {
        "id": "t-46SqG5s7oX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_FOLDER = \"./output/\"\n",
        "\n",
        "VAL_HEADER = ['Model', 'Samples', 'Accuracy', 'F1Score', 'Hyper-parameters','Validation Set']\n",
        "PREDICT_HEADER = ['Model', 'Time', 'Packets', 'Samples', 'DDOS%', 'Accuracy', 'F1Score', 'TPR', 'FPR','TNR', 'FNR', 'Source']\n",
        "\n",
        "# hyperparameters\n",
        "PATIENCE = 10\n",
        "DEFAULT_EPOCHS = 1000\n",
        "hyperparamters = {\n",
        "    \"learning_rate\": [0.1,0.01],\n",
        "    \"batch_size\": [1024,2048],\n",
        "    \"kernels\": [32,64],\n",
        "    \"regularization\" : [None,'l1'],\n",
        "    \"dropout\" : [None,0.2]\n",
        "}"
      ],
      "metadata": {
        "id": "7e1GQiqevNQn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Conv2DModel(model_name,input_shape,kernel_col, kernels=64,kernel_rows=3,learning_rate=0.01,regularization=None,dropout=None):\n",
        "    K.clear_session()\n",
        "\n",
        "    model = Sequential(name=model_name)\n",
        "    regularizer = regularization\n",
        "\n",
        "    model.add(Conv2D(kernels, (kernel_rows,kernel_col), strides=(1, 1), input_shape=input_shape, kernel_regularizer=regularizer, name='conv0'))\n",
        "    if dropout != None and type(dropout) == float:\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(GlobalMaxPooling2D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid', name='fc1'))\n",
        "\n",
        "    print(model.summary())\n",
        "    compileModel(model, learning_rate)\n",
        "    return model\n",
        "\n",
        "def compileModel(model,lr):\n",
        "    # optimizer = SGD(learning_rate=lr, momentum=0.0, decay=0.0, nesterov=False)\n",
        "    optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])  # here we specify the loss function\n",
        "\n",
        "def plot_training_history(grid_search, model_name, output_folder, time_window, max_flow_len):\n",
        "    \"\"\"\n",
        "    Plot and save training/validation accuracy and loss curves from GridSearchCV results.\n",
        "\n",
        "    Args:\n",
        "        grid_search: Fitted GridSearchCV object\n",
        "        model_name: Name of the model\n",
        "        output_folder: Directory to save plots\n",
        "        time_window: Time window parameter\n",
        "        max_flow_len: Maximum flow length parameter\n",
        "    \"\"\"\n",
        "    # Get the best model's history\n",
        "    best_model = grid_search.best_estimator_.model\n",
        "\n",
        "    # Access the history from the model's history attribute\n",
        "    try:\n",
        "        history = best_model.history.history\n",
        "    except AttributeError:\n",
        "        print(\"Warning: Could not access history directly. Trying alternative method...\")\n",
        "        try:\n",
        "            history = grid_search.cv_results_\n",
        "            print(\"Available metrics:\", history.keys())\n",
        "            return\n",
        "        except:\n",
        "            print(\"Error: Could not access training history\")\n",
        "            return\n",
        "\n",
        "    if history is None or len(history) == 0:\n",
        "        print(\"Error: No training history found\")\n",
        "        return\n",
        "\n",
        "    # Create figure with two subplots\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot training & validation metrics if available\n",
        "    metrics = {}\n",
        "    for key in history.keys():\n",
        "        if 'loss' in key:\n",
        "            metrics.setdefault('loss', []).append(key)\n",
        "        if 'acc' in key:\n",
        "            metrics.setdefault('acc', []).append(key)\n",
        "\n",
        "    epochs = range(1, len(next(iter(history.values()))) + 1)\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for metric in metrics.get('acc', []):\n",
        "        if 'val' in metric:\n",
        "            plt.plot(epochs, history[metric], 'r-', label='Validation Accuracy')\n",
        "        else:\n",
        "            plt.plot(epochs, history[metric], 'b-', label='Training Accuracy')\n",
        "    plt.title(f'{model_name}\\nAccuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for metric in metrics.get('loss', []):\n",
        "        if 'val' in metric:\n",
        "            plt.plot(epochs, history[metric], 'r-', label='Validation Loss')\n",
        "        else:\n",
        "            plt.plot(epochs, history[metric], 'b-', label='Training Loss')\n",
        "    plt.title(f'{model_name}\\nLoss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Adjust layout and save\n",
        "    plt.tight_layout()\n",
        "    plot_filename = f\"{output_folder}{time_window}t-{max_flow_len}n-{model_name}-training_history.png\"\n",
        "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "uP9YtnSGvRxY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = \"/content/drive/MyDrive/'Lucid DDoS'/sample-dataset\""
      ],
      "metadata": {
        "id": "c22zenbNvWpJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = load_dataset(\"/content/drive/MyDrive/Lucid DDoS/sample-dataset/10t-10n-DOS2019-dataset-train.hdf5\")\n",
        "X_val, Y_val = load_dataset(\"/content/drive/MyDrive/Lucid DDoS/sample-dataset/10t-10n-DOS2019-dataset-val.hdf5\")"
      ],
      "metadata": {
        "id": "DCJrGb2XvuKa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = shuffle(X_train, Y_train, random_state=SEED)\n",
        "X_val, Y_val = shuffle(X_val, Y_val, random_state=SEED)"
      ],
      "metadata": {
        "id": "wwIVp-agvxaZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEX0udOgwKNZ",
        "outputId": "ef95ee2e-3730-41ad-c1cd-f56916cc35a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.00000000e+00],\n",
              "        [1.14440918e-03],\n",
              "        [1.48505177e-02],\n",
              "        [0.00000000e+00],\n",
              "        [5.16601562e-01],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [8.39233398e-04],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[1.90734863e-07],\n",
              "        [1.14440918e-03],\n",
              "        [1.48505177e-02],\n",
              "        [0.00000000e+00],\n",
              "        [5.16601562e-01],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [8.39233398e-04],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[2.10940838e-03],\n",
              "        [2.12097168e-03],\n",
              "        [1.48505177e-02],\n",
              "        [3.05175781e-05],\n",
              "        [5.16601562e-01],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [1.81579590e-03],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[2.10950375e-03],\n",
              "        [2.12097168e-03],\n",
              "        [1.48505177e-02],\n",
              "        [3.05175781e-05],\n",
              "        [5.16601562e-01],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [1.81579590e-03],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_matrix(matrix, title=\"Raw Matrix Visualization\"):\n",
        "    \"\"\"\n",
        "    Visualize a single matrix as a heatmap or grayscale image.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(matrix, cmap='viridis', aspect='auto')  # Use 'viridis' or 'gray' for grayscale\n",
        "    plt.colorbar(label=\"Value Intensity\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Feature Index\")\n",
        "    plt.ylabel(\"Time Step (or Sample Index)\")\n",
        "    plt.show()\n",
        "\n",
        "def visualize_matrices(matrices, num_samples=10):\n",
        "    \"\"\"\n",
        "    Visualize multiple matrices. Display the first `num_samples` matrices.\n",
        "    \"\"\"\n",
        "    for i in range(min(num_samples, len(matrices))):\n",
        "        visualize_matrix(matrices[i], title=f\"Sample {i+1} Matrix\")"
      ],
      "metadata": {
        "id": "gjonpMxVwnWr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_matrices(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8RCNr2CVyNbd",
        "outputId": "b8a2219a-95d1-4fb0-a0f9-aea9824cc1d4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApwAAAIjCAYAAACu18sFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbQklEQVR4nO3dd3iUZdr38d8kMYUQQk/BQEJRamgBDIg8SiSIhWIBwSUExAaCZkFFgYggbYWNCgvKLqCuCBZU1hKBLEGUJgRQEKR3EkSEkEQIzNzPHyyzzibBzDAlyXw/x3EfL3PNNdec97z7wOl5ldtkGIYhAAAAwEV8PB0AAAAAKjYSTgAAALgUCScAAABcioQTAAAALkXCCQAAAJci4QQAAIBLkXACAADApUg4AQAA4FIknAAAAHApEk4ATmUymfTiiy96OowyLTMzUyaTSZmZmZ4OBQDcgoQTKIN++OEH3XfffapXr54CAwNVp04d3X777Xr99dc9HZpHFBYWavLkyWrcuLECAwMVFhamO++8U0ePHr3q5w4ePCiTySSTyaRJkyYV22fAgAEymUyqXLmyQ7EtWrRIaWlpDn0WALyFiWepA2XL2rVrdeutt6pu3bpKSkpSeHi4jhw5ovXr12vfvn3au3evp0O8KpPJpNTUVKdVOS9evKgePXpo7dq1Gjp0qGJjY/Xrr79qw4YNSk1NVbNmzUr87MGDBxUTE6PAwEDVr19fO3bssHk/Pz9fYWFhMpvN8vX1VV5ent3x3XXXXdq+fbsOHjxY6s9YLBYVFhbK399fPj78dz+Ais/P0wEAsPXyyy8rNDRU3333napWrWrz3smTJz0TlAf99a9/1erVq/XNN9+offv2Do3Ro0cPLV26VNu2bVPLli2t7Z9++qkKCwvVvXt3/fvf/3ZWyCU6f/68NckMDAx0+fcBQFnBf1oDZcy+ffvUrFmzIsmmJNWuXdvm9YIFC3Tbbbepdu3aCggIUNOmTTVnzpwin4uOjtZdd92lzMxMxcXFKSgoSC1atLCuIVy6dKlatGihwMBAtW3bVlu2bLH5/KBBg1S5cmXt379fiYmJCg4OVmRkpF566SWVZpLk2LFjGjx4sMLCwhQQEKBmzZpp/vz5f/g5i8WiV199Vb1791b79u116dIlFRQU/OHn/ld8fLxiYmK0aNEim/Z3331X3bt3V/Xq1Yt85tNPP9Wdd96pyMhIBQQEqEGDBpo4caLMZrO1z//93//p888/16FDh6xT99HR0ZL+u05z8eLFGjt2rOrUqaNKlSopNze3yBrOnTt3KigoSAMHDrSJ4ZtvvpGvr6+effZZu+8ZAMoSEk6gjKlXr542b96s7du3/2HfOXPmqF69enr++ec1Y8YMRUVF6YknntDs2bOL9N27d6/69++vu+++W1OmTNGvv/6qu+++W++++66efvppPfTQQ5owYYL27dunBx54QBaLxebzZrNZ3bt3V1hYmKZPn662bdsqNTVVqampV40xJydHN910k1auXKnhw4fr1VdfVcOGDTVkyJA/XPv4448/6vjx44qNjdUjjzyi4OBgBQcHKzY2VqtWrfrD3+f3HnzwQS1evNiaIJ86dUrLly9X//79i+2/cOFCVa5cWSkpKXr11VfVtm1bjR8/Xs8995y1zwsvvKBWrVqpZs2aeuedd/TOO+8UuaeJEyfq888/16hRozR58mT5+/sX+a4mTZpo4sSJeuedd7Rs2TJJl6f7Bw0apMaNG+ull16y614BoMwxAJQpy5cvN3x9fQ1fX18jPj7eeOaZZ4yvvvrKKCwsLNK3oKCgSFtiYqJRv359m7Z69eoZkoy1a9da27766itDkhEUFGQcOnTI2v7GG28YkoxVq1ZZ25KSkgxJxpNPPmlts1gsxp133mn4+/sbP//8s7VdkpGammp9PWTIECMiIsI4deqUTUz9+vUzQkNDi72HK5YuXWpIMmrUqGE0atTIWLBggbFgwQKjUaNGhr+/v7Ft27YSP2sYhnHgwAFDkvGXv/zF2L59uyHJWLNmjWEYhjF79myjcuXKRn5+vpGUlGQEBwfbfLa4uB599FGjUqVKxvnz561td955p1GvXr0ifVetWmVIMurXr19krCvv/f43NpvNxs0332yEhYUZp06dMoYNG2b4+fkZ33333VXvEQDKAyqcQBlz++23a926dbrnnnu0bds2TZ8+XYmJiapTp461+nVFUFCQ9c9nz57VqVOn1KVLF+3fv19nz5616du0aVPFx8dbX3fo0EGSdNttt6lu3bpF2vfv318ktuHDh1v/bDKZNHz4cBUWFmrlypXF3othGProo4909913yzAMnTp1ynolJibq7NmzysrKKvG3uLKJ59y5c8rIyNCgQYM0aNAgrVy5UoZhaPr06SV+9n81a9ZMsbGxeu+99yRd3l3es2dPVapUqdj+v/9tz507p1OnTqlz584qKCjQrl27Sv29SUlJNmOVxMfHRwsXLlReXp7uuOMO/e1vf9OYMWMUFxdX6u8CgLKKhBMog9q1a6elS5fq119/1caNGzVmzBidO3dO9913n3788Udrv2+//VYJCQkKDg5W1apVVatWLT3//POSVCTh/H1SKUmhoaGSpKioqGLbf/31V5t2Hx8f1a9f36bthhtukKQSd2j//PPPOnPmjN58803VqlXL5kpOTpZ09Y1QVxK1Tp062cRZt25d3XzzzVq7dm2Jny1O//799cEHH2jv3r1au3ZtidPpkrRjxw717t1boaGhqlKlimrVqqWHHnpIUtHf9mpiYmJK3bdBgwZ68cUX9d1336lZs2YaN25cqT8LAGUZu9SBMszf31/t2rVTu3btdMMNNyg5OVkffPCBUlNTtW/fPnXt2lWNGzfWzJkzFRUVJX9/f33xxRf661//WmQNpq+vb7HfUVK74YQT067E8NBDDykpKanYPrGxsSV+PjIyUpIUFhZW5L3atWsX2dz0Rx588EGNGTNGQ4cOVY0aNdStW7di+505c0ZdunRRlSpV9NJLL6lBgwYKDAxUVlaWnn322SK/7dWUprr5e8uXL5ckHT9+XL/88ovCw8Pt+jwAlEUknEA5cWVq9cSJE5Kkf/3rX7pw4YKWLVtmU720dzNNaVksFu3fv99a1ZSk3bt3S5J1Z/b/qlWrlkJCQmQ2m5WQkGD3d7Zo0ULXXXedjh07VuS948ePq1atWnaNV7duXXXq1EmZmZl6/PHH5edX/F+BmZmZ+uWXX7R06VLdcsst1vYDBw4U6WsymeyK4Wrmzp2rFStW6OWXX9aUKVP06KOP6tNPP3Xa+ADgKUypA2XMqlWriq0ufvHFF5KkG2+8UdJ/K5O/73v27FktWLDAZbHNmjXL+mfDMDRr1ixdd9116tq1a7H9fX19de+99+qjjz4qdtf9zz//fNXvCwkJsR76/vt1kzt37tTatWt1++23230PkyZNUmpqqp588skS+xT32xYWFupvf/tbkb7BwcF2TbGX5MCBAxo9erTuvfdePf/883rllVe0bNkyvf3229c8NgB4GhVOoIx58sknVVBQoN69e6tx48YqLCzU2rVrtWTJEkVHR1vXPnbr1k3+/v66++679eijjyovL0/z5s1T7dq1rVVQZwoMDFR6erqSkpLUoUMHffnll/r888/1/PPPX7XSOHXqVK1atUodOnTQ0KFD1bRpU50+fVpZWVlauXKlTp8+fdXvnTx5sjIyMnTbbbdpxIgRkqTXXntN1atXt65XtUeXLl3UpUuXq/bp2LGjqlWrpqSkJI0YMUImk0nvvPNOsf8h0LZtWy1ZskQpKSlq166dKleurLvvvtuumAzD0ODBgxUUFGQ9R/XRRx/VRx99pJEjRyohIcG6vAAAyiMqnEAZ88orr+jWW2/VF198oZSUFKWkpGjjxo164okntGHDBuuB8DfeeKM+/PBDmUwmjRo1SnPnztUjjzyikSNHuiQuX19fpaenKzs7W6NHj9Z3332n1NRUTZw48aqfCwsL08aNG5WcnKylS5daz+I8ffq0pk2b9off27RpU61evVrNmjXTpEmTNHnyZLVv317ffvut6tSp46zbs1GjRg199tlnioiI0NixY/XKK6/o9ttvL3ZX/BNPPKH+/ftrwYIF6t+//1UrpyV5/fXXlZmZqblz59ok7//4xz9ksVg0dOjQa7ofAPA0nqUO4A8NGjRIH374oUPPGgcAgAonAAAAXIqEEwAAAC5FwgkAAACXIuEE8IeuPHIRAOB8s2fPVnR0tAIDA9WhQwdt3LixxL7z5s1T586dVa1aNVWrVk0JCQlF+g8aNEgmk8nm6t69u6tv46pIOAEAADzkyrFqqampysrKUsuWLZWYmFjiY38zMzP14IMPatWqVVq3bp2ioqLUrVu3Ig/I6N69u06cOGG93nvvPXfcTonYpQ4AAOAhHTp0ULt27awP1rBYLIqKitKTTz6p55577g8/bzabVa1aNc2aNUsDBw6UdLnCeebMGX3yySeuDN0u5frgd4vFouPHjyskJMSpj5cDAACuYxiGzp07p8jISPn4uH+y9fz58yosLHTJ2IZhFMlJAgICFBAQUKRvYWGhNm/erDFjxljbfHx8lJCQoHXr1pXq+woKCnTx4kVVr17dpj0zM1O1a9dWtWrVdNttt2nSpEmqUaOGA3fkHOU64Tx+/LiioqI8HQYAAHDAkSNHdP3117v1O8+fP6+YepWVfdLskvErV65cZM17amqqXnzxxSJ9T506JbPZrLCwMJv2sLAwm8f5Xs2zzz6ryMhIJSQkWNu6d++uPn36KCYmRvv27dPzzz+vO+64Q+vWrbM+utfdynXCGRISIkm6WT3kp+s8HI0dymE11uRXjn7f/zAuuua/Xl1t7+zWng7Bbg2HbfF0CCijPt79g6dDsFvvG1p4OoQK75Iu6ht9Yf133J0KCwuVfdKsQ5ujVSXEudXV3HMW1Wt7UEeOHFGVKlWs7cVVN51h6tSpWrx4sTIzMxUYGGht79evn/XPLVq0UGxsrBo0aKDMzEx17drVJbH8kXKdcF4pWfvpOvmZylFCVB4TzvL0+/6HYSqfy5N9ggL/uFMZU67+7w9u5ex/0N2B/z27wX/+evbkcrjKISZVDnHu91t0ebwqVarYJJwlqVmzpnx9fZWTk2PTnpOTo/Dw8Kt+9pVXXtHUqVO1cuVKxcbGXrVv/fr1VbNmTe3du9djCWf5+5sAAADgGpkNi0sue/j7+6tt27bKyMiwtlksFmVkZCg+Pr7Ez02fPl0TJ05Uenq64uLi/vB7jh49ql9++UURERF2xedMJJwAAAAekpKSonnz5umtt97Szp079fjjjys/P1/JycmSpIEDB9psKpo2bZrGjRun+fPnKzo6WtnZ2crOzrauG83Ly9Po0aO1fv16HTx4UBkZGerZs6caNmyoxMREj9yjVM6n1AEAABxhkSGLnLv0ypHx+vbtq59//lnjx49Xdna2WrVqpfT0dOtGosOHD9vs5J8zZ44KCwt133332YxzZWOSr6+vvv/+e7311ls6c+aMIiMj1a1bN02cONFla0lLg4QTAADAg4YPH67hw4cX+15mZqbN64MHD151rKCgIH311VdOisx5SDgBAIDXscgi+1Zclm5MFI81nAAAAHApKpwAAMDrmA1DZic/3dvZ41UkVDgBAADgUlQ4AQCA1ykru9S9BQknAADwOhYZMpNwug1T6gAAAHApKpwAAMDrMKXuXlQ4AQAA4FJUOAEAgNfhWCT3osIJAAAAl6LCCQAAvI7lP5ezx0TxykSFc/bs2YqOjlZgYKA6dOigjRs3ejokAAAAOInHE84lS5YoJSVFqampysrKUsuWLZWYmKiTJ096OjQAAFBBmf9zDqezLxTP4wnnzJkzNXToUCUnJ6tp06aaO3euKlWqpPnz53s6NAAAUEGZDddcKJ5HE87CwkJt3rxZCQkJ1jYfHx8lJCRo3bp1RfpfuHBBubm5NhcAAADKNo8mnKdOnZLZbFZYWJhNe1hYmLKzs4v0nzJlikJDQ61XVFSUu0IFAAAViMVFF4rn8Sl1e4wZM0Znz561XkeOHPF0SAAAAPgDHj0WqWbNmvL19VVOTo5Ne05OjsLDw4v0DwgIUEBAgLvCAwAAFZRFJpllcvqYKJ5HK5z+/v5q27atMjIyrG0Wi0UZGRmKj4/3YGQAAABwFo8f/J6SkqKkpCTFxcWpffv2SktLU35+vpKTkz0dGgAAqKAsxuXL2WOieB5POPv27auff/5Z48ePV3Z2tlq1aqX09PQiG4kAAABQPnk84ZSk4cOHa/jw4Z4OAwAAeAmzC9ZwOnu8iqRMJJwAAADuRMLpXuXqWCQAAACUP1Q4AQCA17EYJlkMJx+L5OTxKhIqnAAAAHApKpwAAMDrsIbTvahwAgAAwKWocAIAAK9jlo/MTq67mZ06WsVChRMAAAAuRYUTAAB4HcMFu9QNdqmXiIQTAAB4HTYNuRdT6gAAAHApKpwAAMDrmA0fmQ0nbxoynDpchUKFEwAAAC5FhRMAAHgdi0yyOLnuZhElzpJQ4QQAAIBLUeFEqfjWrO7pEOx26US2p0MAAJRR7FJ3LyqcAAAAcCkqnAAAwOu4Zpc6azhLQsIJAAC8zuVNQ86dAnf2eBUJU+oAAABwKSqcAADA61jkIzPHIrkNFU4AAAC4FBVOAADgddg05F5UOAEAAOBSVDgBAIDXsciHR1u6ERVOAAAAuBQVTgAA4HXMhklmw8mPtnTyeBUJCScAAPA6Zhcci2RmSr1ETKkDAADApahwAgAAr2MxfGRx8rFIFo5FKhEVTgAAALgUFU4AAOB1WMPpXlQ4AQAA4FJUOAEAgNexyPnHGFmcOlrFQoUTAAAALkWFEwAAeB3XPNqSOl5JSDgBAIDXMRs+Mjv5WCRnj1eR8MsAAADApahwAgAAr2ORSRY5e9MQz1IvCRVOAAAAuBQVTgAA4HVYw+le/DIAAABwKSqcAADA67jm0ZbU8UrCLwMAAACXosIJAAC8jsUwyeLsR1s6ebyKhAonAAAAXIoKJwAA8DoWF6zh5NGWJSPhBAAAXsdi+Mji5GOMnD1eRcIvAwAAAJeiwgkAALyOWSaZnfwoSmePV5FQ4QQAAIBLUeEEAABehzWc7sUvAwAAAJeiwgkAALyOWc5fc2l26mgVCxVOAAAAuBQVTgAA4HVYw+leJJwAAMDrmA0fmZ2cIDp7vIqEXwYAAAAuRYUTAAB4HUMmWZy8acjg4PcSUeEEAADwoNmzZys6OlqBgYHq0KGDNm7cWGLfefPmqXPnzqpWrZqqVaumhISEIv0Nw9D48eMVERGhoKAgJSQkaM+ePa6+jasi4QQAAF7nyhpOZ1/2WrJkiVJSUpSamqqsrCy1bNlSiYmJOnnyZLH9MzMz9eCDD2rVqlVat26doqKi1K1bNx07dszaZ/r06Xrttdc0d+5cbdiwQcHBwUpMTNT58+cd/r2uFQknAACAE+Xm5tpcFy5cKLHvzJkzNXToUCUnJ6tp06aaO3euKlWqpPnz5xfb/91339UTTzyhVq1aqXHjxvr73/8ui8WijIwMSZerm2lpaRo7dqx69uyp2NhYvf322zp+/Lg++eQTV9xuqVSINZym6/xlMl3n6TBKzbh00dMh2M186rSnQwBQDnWv197TITig0NMBwA0shkkWw7lrLq+MFxUVZdOempqqF198sUj/wsJCbd68WWPGjLG2+fj4KCEhQevWrSvVdxYUFOjixYuqXr26JOnAgQPKzs5WQkKCtU9oaKg6dOigdevWqV+/fvbellNUiIQTAACgrDhy5IiqVKlifR0QEFBsv1OnTslsNissLMymPSwsTLt27SrVdz377LOKjIy0JpjZ2dnWMf53zCvveQIJJwAA8Dpm+cjs5JWFV8arUqWKTcLpKlOnTtXixYuVmZmpwMBAl3/ftWANJwAA8DpXptSdfdmjZs2a8vX1VU5Ojk17Tk6OwsPDr/rZV155RVOnTtXy5csVGxtrbb/yOUfGdCUSTgAAAA/w9/dX27ZtrRt+JFk3AMXHx5f4uenTp2vixIlKT09XXFyczXsxMTEKDw+3GTM3N1cbNmy46piuxpQ6AADwOhb5yOLkupsj46WkpCgpKUlxcXFq37690tLSlJ+fr+TkZEnSwIEDVadOHU2ZMkWSNG3aNI0fP16LFi1SdHS0dV1m5cqVVblyZZlMJj311FOaNGmSGjVqpJiYGI0bN06RkZHq1auX0+7VXiScAAAAHtK3b1/9/PPPGj9+vLKzs9WqVSulp6dbN/0cPnxYPj7/TWTnzJmjwsJC3XfffTbj/H4n/DPPPKP8/Hw98sgjOnPmjG6++Walp6d7dJ2nyTAMw2Pffo1yc3MVGhqqW6+7X34ci+RSJr/y8/teYVwsn0eb7P5H3B93KmNuGLLJ0yGgjDJd5+/pEOxWXv/uKE8uGReVqU919uxZt2yu+b0rucPja/oooLJz/227kHdRczov9ch9lXWs4QQAAIBLMaUOAAC8jisPfkdRVDgBAADgUlQ4AQCA1zEMH1kM59bdDCePV5GQcAIAAK9jlklmOXcK3NnjVSSk4gAAAHApKpwAAMDrWAznb/KxlNuDJl2PCicAAABcigonAADwOhYXbBpy9ngVCb8MAAAAXIoKJwAA8DoWmWRx8q5yZ49XkXi0wjllyhS1a9dOISEhql27tnr16qWffvrJkyEBAADAyTyacK5evVrDhg3T+vXrtWLFCl28eFHdunVTfn6+J8MCAAAVnNkwueRC8Tw6pZ6enm7zeuHChapdu7Y2b96sW265xUNRAQCAio5NQ+5VptZwnj17VpJUvXr1Yt+/cOGCLly4YH2dm5vrlrgAAADguDKTilssFj311FPq1KmTmjdvXmyfKVOmKDQ01HpFRUW5OUoAAFARWGSSxXDyxaahEpWZhHPYsGHavn27Fi9eXGKfMWPG6OzZs9bryJEjbowQAAAAjigTU+rDhw/XZ599pq+//lrXX399if0CAgIUEBDgxsgAAEBFZLjgWCSDCmeJPJpwGoahJ598Uh9//LEyMzMVExPjyXAAAADgAh5NOIcNG6ZFixbp008/VUhIiLKzsyVJoaGhCgoK8mRoAACgAruy7tLZY6J4Hl3DOWfOHJ09e1b/93//p4iICOu1ZMkST4YFAAAAJ/L4lDoAAIC7cQ6ne5WJTUMAAADuxJS6e5GKAwAAwKWocAIAAK9jccGxSBz8XjIqnAAAAHApKpwAAMDrsIbTvahwAgAAwKWocAIAAK9DhdO9qHACAADApahwAgAAr0OF071IOAEAgNch4XQvptQBAADgUlQ4AQCA1zHk/IPaDaeOVrE4lHAePnxYhw4dUkFBgWrVqqVmzZopICDA2bEBAACgAih1wnnw4EHNmTNHixcv1tGjR2UY/83j/f391blzZz3yyCO699575ePDTD0AACi7WMPpXqXKDEeMGKGWLVvqwIEDmjRpkn788UedPXtWhYWFys7O1hdffKGbb75Z48ePV2xsrL777jtXxw0AAIByolQVzuDgYO3fv181atQo8l7t2rV122236bbbblNqaqrS09N15MgRtWvXzunBAgAAOAMVTvcqVcI5ZcqUUg/YvXt3h4NB2eVbs7qnQ7DbpRPZng4BAADIgWORdu3aVeJ7X3311TUFAwAA4A5XKpzOvlA8uxPONm3aaPbs2TZtFy5c0PDhw9WzZ0+nBQYAAOAqJJzuZXfCuXDhQo0fP149evRQTk6Otm7dqtatW2vlypVas2aNK2IEAABAOWZ3wvnAAw9o27Ztunjxopo1a6b4+Hh16dJFWVlZbBQCAADlgmGYXHKheA4fmFlYWCiz2Syz2ayIiAgFBgY6My4AAABUEHYnnIsXL1aLFi0UGhqq3bt36/PPP9ebb76pzp07a//+/a6IEQAAwKksMrnkQvHsTjiHDBmiyZMna9myZapVq5Zuv/12/fDDD6pTp45atWrlghABAABQntn9LPWsrCzdeOONNm3VqlXT+++/r3feecdpgQEAALgKB7+7l90VzhtvvFGXLl3SypUr9cYbb+jcuXOSpOPHj6t3795ODxAAAADlm90VzkOHDql79+46fPiwLly4oNtvv10hISGaNm2aLly4oLlz57oiTgAAAKdxxa5ydqmXzO4K58iRIxUXF6dff/1VQUFB1vbevXsrIyPDqcEBAACg/LO7wrlmzRqtXbtW/v7+Nu3R0dE6duyY0wIDAABwFdZwupfdCafFYpHZbC7SfvToUYWEhDglKAAAAFdiSt297J5S79atm9LS0qyvTSaT8vLylJqaqh49ejgzNgAAAFQAdlc4Z8yYocTERDVt2lTnz59X//79tWfPHtWsWVPvvfeeK2IEAABwKsMFU+pUOEtmd8J5/fXXa9u2bVq8eLG+//575eXlaciQIRowYIDNJiIAAABAciDhlCQ/Pz899NBDzo4FAADALQxJhuH8MVG8UiWcy5YtK/WA99xzj8PBAAAAoOIpVcLZq1cvm9cmk0nG//xngcl0ed1CcTvYAQAAyhKLTDLJycciOXm8iqRUu9QtFov1Wr58uVq1aqUvv/xSZ86c0ZkzZ/Tll1+qTZs2Sk9Pd3W8AAAAKGfsXsP51FNPae7cubr55putbYmJiapUqZIeeeQR7dy506kBAgAAOBvncLqX3Qnnvn37VLVq1SLtoaGhOnjwoBNCAgAAcC2LYZKJJw25jd0Hv7dr104pKSnKycmxtuXk5Gj06NFq3769U4MDAABA+Wd3hXP+/Pnq3bu36tatq6ioKEnSkSNH1KhRI33yySfOjg8AAMDpDMMFxyJxLlKJ7E44GzZsqO+//14rVqzQrl27JElNmjRRQkKCdac6AAAAcIVDB7+bTCZ169ZN3bp1c3Y8AAAALsemIfdyKOHMyMhQRkaGTp48KYvFYvPe/PnznRIYAAAAKga7E84JEybopZdeUlxcnCIiIphGBwAA5Q4VTveyO+GcO3euFi5cqD/96U+uiAcAAAAVjN0JZ2FhoTp27OiKWAAAANyCczjdy+5zOB9++GEtWrTIFbEAAAC4xZVjkZx9oXh2VzjPnz+vN998UytXrlRsbKyuu+46m/dnzpzptOAAAABQ/tmdcH7//fdq1aqVJGn79u0277GBCAAAlAeXK5LO3jTk1OEqFLsTzlWrVrkiDgAAAFRQDp3DCQAAUJ5xLJJ7lTrh7NOnT6n6LV261OFgAAAAUPGUOuEMDQ11ZRwAAABuY/zncvaYKF6pE84FCxa4Mg4AAABUUKzhBAAAXoc1nO5FwgkAALwPc+puZfeThgAAAAB7UOEEAADexwVT6mJKvURUOAEAADxo9uzZio6OVmBgoDp06KCNGzeW2HfHjh269957FR0dLZPJpLS0tCJ9XnzxRZlMJpurcePGpYpl//79jt7GVTmUcL7zzjvq1KmTIiMjdejQIUlSWlqaPv30U6cGBwAA4AqXH23p/MteS5YsUUpKilJTU5WVlaWWLVsqMTFRJ0+eLLZ/QUGB6tevr6lTpyo8PLzEcZs1a6YTJ05Yr2+++aZU8TRs2FC33nqr/vnPf+r8+fP231AJ7E4458yZo5SUFPXo0UNnzpyR2WyWJFWtWrXYLBsAAADFmzlzpoYOHark5GQ1bdpUc+fOVaVKlTR//vxi+7dr105/+ctf1K9fPwUEBJQ4rp+fn8LDw61XzZo1SxVPVlaWYmNjlZKSovDwcD366KNXrbiWlt1rOF9//XXNmzdPvXr10tSpU63tcXFxGjVq1DUH5Ajf68Pl61Pyj17WXNp/0NMhAIBbpB+69n+o3C0xspWnQ4AbuPJYpNzcXJv2gICAYpPDwsJCbd68WWPGjLG2+fj4KCEhQevWrbumWPbs2aPIyEgFBgYqPj5eU6ZMUd26df/wc61atdKrr76qGTNmaNmyZVq4cKFuvvlm3XDDDRo8eLD+9Kc/qVatWnbHY3eF88CBA2rdunWR9oCAAOXn59sdAAAAQEUSFRWl0NBQ6zVlypRi+506dUpms1lhYWE27WFhYcrOznb4+zt06KCFCxcqPT1dc+bM0YEDB9S5c2edO3eu1GP4+fmpT58++uCDDzRt2jTt3btXo0aNUlRUlAYOHKgTJ07YFZPdFc6YmBht3bpV9erVs2lPT09XkyZN7B0OAADA/QyT83eV/2e8I0eOqEqVKtbmq019u8Idd9xh/XNsbKw6dOigevXq6f3339eQIUNKNcamTZs0f/58LV68WMHBwRo1apSGDBmio0ePasKECerZs6ddU+12J5wpKSkaNmyYzp8/L8MwtHHjRr333nuaMmWK/v73v9s7HAAAgNs5usnnj8aUpCpVqtgknCWpWbOmfH19lZOTY9Oek5Nz1Q1B9qpatapuuOEG7d279w/7zpw5UwsWLNBPP/2kHj166O2331aPHj3k43N5UjwmJkYLFy5UdHS0XTHYnXA+/PDDCgoK0tixY1VQUKD+/fsrMjJSr776qvr162fvcAAAAF7J399fbdu2VUZGhnr16iVJslgsysjI0PDhw532PXl5edq3b5/+9Kc//WHfOXPmaPDgwRo0aJAiIiKK7VO7dm394x//sCsGhw5+HzBggAYMGKCCggLl5eWpdu3ajgwDAADgGWXk0ZYpKSlKSkpSXFyc2rdvr7S0NOXn5ys5OVmSNHDgQNWpU8e6DrSwsFA//vij9c/Hjh3T1q1bVblyZTVs2FCSNGrUKN19992qV6+ejh8/rtTUVPn6+urBBx/8w3hWrFihunXrWiua1lszDB05ckR169aVv7+/kpKS7LrPa3rSUKVKlVSpUqVrGQIAAMBr9e3bVz///LPGjx+v7OxstWrVSunp6daNRIcPH7ZJ/o4fP26zefuVV17RK6+8oi5duigzM1OSdPToUT344IP65ZdfVKtWLd18881av359qXaXN2jQQCdOnChSTDx9+rRiYmKsx2Haq1QJZ+vWrWUylW5hbVZWlkOBAAAAuIsrj0Wy1/Dhw0ucQr+SRF4RHR0t4w8Wny5evNihOCSVOHZeXp4CAwMdHrdUCeeVdQUAAACoeFJSUiRJJpNJ48ePt5nBNpvN2rBhg1q1auXw+KVKOFNTUx3+AgAAgDLJ2Ws4y7EtW7ZIulzh/OGHH+Tv7299z9/fXy1btrymB/w4vIZz06ZN2rlzpySpadOmatu2rcNBAAAAwHNWrVolSUpOTtarr75aqmOd7GF3wnllIeq3336rqlWrSpLOnDmjjh07avHixbr++uudGiAAAICzlaU1nGXJggULXDKuQ+dwXrx4UTt37tSNN94oSfrpp5+UnJyshx9+WOnp6U4PEgAAwKnKyLFIZUGfPn20cOFCValSRX369Llq36VLlzr0HXYnnKtXr9batWutyaYk3XjjjXr99dfVuXNnh4IAAACAZ4SGhlpPIwoNDXXJd9idcEZFRenixYtF2s1msyIjI50SFAAAgGuZ/nM5e8zy5/fT6K6aUvf54y62/vKXv+jJJ5/Upk2brG2bNm3SyJEj9corrzg1OAAAALjPb7/9poKCAuvrQ4cOKS0tTcuXL7+mce2ucA4aNEgFBQXq0KGD/Pwuf/zSpUvy8/PT4MGDNXjwYGvf06dPX1NwAAAALsEazmL17NlTffr00WOPPaYzZ86offv28vf316lTpzRz5kw9/vjjDo1rd8KZlpbm0BcBAACgbMvKytJf//pXSdKHH36o8PBwbdmyRR999JHGjx/vvoTT3oe1AwAAlDlUOItVUFCgkJAQSdLy5cvVp08f+fj46KabbtKhQ4ccHtfhg99PnjypkydPymKx2LTHxsY6HAwAAAA8p2HDhvrkk0/Uu3dvffXVV3r66aclXc77ruUweLs3DW3evFnNmzdXRESEYmNj1apVK+vVunVrhwOZOnWqTCaTnnrqKYfHAAAAKBXD5JqrnBs/frxGjRql6OhodejQQfHx8ZIuVzuvJc+zu8I5ePBg3XDDDfrHP/6hsLAw67lN1+K7777TG2+8QXUUAAC4hWFcvpw9Znl333336eabb9aJEyfUsmVLa3vXrl3Vu3dvh8e1O+Hcv3+/PvroIzVs2NDhL/29vLw8DRgwQPPmzdOkSZOcMiYAAAAcEx4ervDwcJu29u3bX9OYdk+pd+3aVdu2bbumL/29YcOG6c4771RCQsIf9r1w4YJyc3NtLgAAALsZLrrKufz8fI0bN04dO3ZUw4YNVb9+fZvLUXZXOP/+978rKSlJ27dvV/PmzXXdddfZvH/PPfeUeqzFixcrKytL3333Xan6T5kyRRMmTLArXgAAAJTOww8/rNWrV+tPf/qTIiIinLJ0UnIg4Vy3bp2+/fZbffnll0XeM5lMMpvNpRrnyJEjGjlypFasWKHAwMBSfWbMmDFKSUmxvs7NzVVUVFTpAgcAALjCFZt8KsCmoS+//FKff/65OnXq5NRx7Z5Sf/LJJ/XQQw/pxIkTslgsNldpk03p8m73kydPqk2bNvLz85Ofn59Wr16t1157TX5+fsWOFRAQoCpVqthcAAAAcI5q1aqpevXqTh/X7oTzl19+0dNPP62wsLBr+uKuXbvqhx9+0NatW61XXFycBgwYoK1bt8rX1/eaxgcAACiJyXDNVd5NnDhR48ePt3meujPYPaXep08frVq1Sg0aNLimLw4JCVHz5s1t2oKDg1WjRo0i7QAAAHC9GTNmaN++fQoLC1N0dHSRvTpZWVkOjWt3wnnDDTdozJgx+uabb9SiRYsigYwYMcKhQAAAANyGR1sWq1evXi4Z16Fd6pUrV9bq1au1evVqm/dMJtM1JZyZmZkOfxYAAKDU2DRUrNTUVJeMa3fCeeDAAVfEAQAAgDLgzJkz+vDDD7Vv3z6NHj1a1atXV1ZWlsLCwlSnTh2HxrQ74QQAACj3mFIv1vfff6+EhASFhobq4MGDGjp0qKpXr66lS5fq8OHDevvttx0a16GE8+jRo1q2bJkOHz6swsJCm/dmzpzpUCAAAADwrJSUFA0aNEjTp09XSEiItb1Hjx7q37+/w+PanXBmZGTonnvuUf369bVr1y41b95cBw8elGEYatOmjcOBAAAAuA0VzmJ99913euONN4q016lTR9nZ2Q6Pa/c5nGPGjNGoUaP0ww8/KDAwUB999JGOHDmiLl266P7773c4EAAAAHhWQECAcnNzi7Tv3r1btWrVcnhcuxPOnTt3auDAgZIkPz8//fbbb6pcubJeeuklTZs2zeFAAAAA3MZw0VXO3XPPPXrppZd08eJFSZdPIDp8+LCeffZZ3XvvvQ6Pa3fCGRwcbF23GRERoX379lnfO3XqlMOBAAAAwLNmzJihvLw81a5dW7/99pu6dOmihg0bKiQkRC+//LLD49q9hvOmm27SN998oyZNmqhHjx7685//rB9++EFLly7VTTfd5HAgAAAAbsM5nMUKDQ3VihUr9O2332rbtm3Ky8tTmzZtlJCQcE3j2p1wzpw5U3l5eZKkCRMmKC8vT0uWLFGjRo3YoQ4AAFCOvf322+rbt686deqkTp06WdsLCwu1ePFi67JKe9mdcNavX9/65+DgYM2dO9ehLwYAAPAUk3H5cvaY5V1ycrK6d++u2rVr27SfO3dOycnJ7ks4f+/8+fNasmSJCgoKdPvtt6thw4bXMhwAAIB7cCxSsQzDkMlUdGnA0aNHFRoa6vC4pU44U1JSdPHiRb3++uuSLpdW4+PjtWPHDlWqVEmjR4/WihUrFB8f73AwAAAAcL/WrVvLZDLJZDKpa9eu8vP7b4poNpt14MABde/e3eHxS51wLl++XJMnT7a+fvfdd3Xo0CHt2bNHdevW1eDBgzVp0iR9/vnnDgcDAAAA9+vVq5ckaevWrUpMTFTlypWt7/n7+ys6OvqajkUqdcJ5+PBhNW3a1Pp6+fLluu+++1SvXj1J0siRI9WjRw+HAwEAAIBnpKamSpKio6PVt29fBQYGOnX8UiecPj4+Moz/Lk5Yv369xo0bZ31dtWpV/frrr04NDgAAwBVMcsGmIecO5xFJSUmSLi+dPHnypCwWi837devWdWjcUh/83qRJE/3rX/+SJO3YsUOHDx/Wrbfean3/0KFDCgsLcygIAAAAeN6ePXvUuXNnBQUFqV69eoqJiVFMTIyio6MVExPj8LilrnA+88wz6tevnz7//HPt2LFDPXr0sPniL774Qu3bt3c4EAAAALfh4PdiDRo0SH5+fvrss88UERFR7I51R5Q64ezdu7e++OILffbZZ+rWrZuefPJJm/crVaqkJ554wilBAQAAwP22bt2qzZs3q3Hjxk4d165zOLt27aquXbsW+96VxaYAAABlHudwFqtp06Y6deqU08ct9RpOAACACsNw0VXOTZs2Tc8884wyMzP1yy+/KDc31+Zy1DU9aQgAAAAVR0JCgiQVmdG+8gQis9ns0LgknAAAwOvwLPXirVq1yiXj2pVwGoahI0eOqHbt2k4/EBQAAACe1aVLF5eMa3fC2bBhQ+3YsUONGjVySUAAAAAux6YhG99//32p+sXGxjo0vl0Jp4+Pjxo1aqRffvmFhBMAAKCCaNWqlUwmk81TJf+XW9dwTp06VaNHj9acOXPUvHlzh74UAADAo6hw2jhw4IBLx7c74Rw4cKAKCgrUsmVL+fv7KygoyOb906dPOy04AAAAuF69evVcOr7dCWdaWpoLwgAAAHAfdqm7l90JZ1JSkiviAAAAcB+epe5WDp3DaTab9cknn2jnzp2SpGbNmumee+6Rr6+vU4MDAABA+Wd3wrl371716NFDx44d04033ihJmjJliqKiovT555+rQYMGTg8SAADAqdg05FZ2P0t9xIgRatCggY4cOaKsrCxlZWXp8OHDiomJ0YgRI1wRIwAAANzk0qVLWrlypd544w2dO3dOknT8+HHl5eU5PKbdFc7Vq1dr/fr1ql69urWtRo0amjp1qjp16uRwIAAAAO7CpqHiHTp0SN27d9fhw4d14cIF3X777QoJCdG0adN04cIFzZ0716Fx7a5wBgQEWLPd38vLy5O/v79DQQAAAMDzRo4cqbi4OP366682R1/27t1bGRkZDo9rd8J511136ZFHHtGGDRtkGIYMw9D69ev12GOP6Z577nE4EAAAALcxXHSVc2vWrNHYsWOLFBGjo6N17Ngxh8e1O+F87bXX1KBBA8XHxyswMFCBgYHq1KmTGjZsqFdffdXhQAAAAOBZFoul2MdXHj16VCEhIQ6Pa/cazqpVq+rTTz/V3r17rcciNWnSRA0bNnQ4CAAAALdywRrOilDh7Natm9LS0vTmm29Kuvz89Ly8PKWmpqpHjx4Oj+vQOZyS1LBhQ5JMAABQPnEsUrFmzJihxMRENW3aVOfPn1f//v21Z88e1axZU++9957D45ZqSn3q1Kn67bffSjXghg0b9PnnnzscEAAAADzj+uuv17Zt2/T888/r6aefVuvWrTV16lRt2bJFtWvXdnjcUlU4f/zxR9WtW1f333+/7r77bsXFxalWrVqSLp/V9OOPP+qbb77RP//5Tx0/flxvv/22wwEBAAC4HBXOEvn5+emhhx5y7pil6fT2229r27ZtmjVrlvr376/c3Fz5+voqICBABQUFkqTWrVvr4Ycf1qBBgxQYGOjUIAEAAOB6f1Q0HDhwoEPjlnoNZ8uWLTVv3jy98cYb+v7773Xo0CH99ttvqlmzplq1aqWaNWs6FAAAAIC7cfB78UaOHGnz+uLFiyooKJC/v78qVark+oTzCh8fH7Vq1UqtWrVy6AsBAABQNv36669F2vbs2aPHH39co0ePdnhcu8/hBAAAgPdo1KiRpk6dWqT6aQ8STgAAAFyVn5+fjh8/7vjnnRgLAABA+cAu9WItW7bM5rVhGDpx4oRmzZqlTp06OTwuCScAAPA6bBoqXq9evWxem0wm1apVS7fddptmzJjh8LjXlHAeOXJEkhQVFXUtwwAAAKAMsFgsLhnX7jWcly5d0rhx4xQaGqro6GhFR0crNDRUY8eO1cWLF10RIwAAgPMZTr5QIrsrnE8++aSWLl2q6dOnKz4+XpK0bt06vfjii/rll180Z84cpwcJAAAA10hJSSl135kzZzr0HXYnnIsWLdLixYt1xx13WNtiY2MVFRWlBx98kIQTAACUfWwastqyZUup+plMJoe/w+6EMyAgQNHR0UXaY2Ji5O/v73AgAAAAcL9Vq1a5/DvsXsM5fPhwTZw4URcuXLC2XbhwQS+//LKGDx/u1OAAAABc4coudWdfKJ7dFc4tW7YoIyND119/vVq2bClJ2rZtmwoLC9W1a1f16dPH2nfp0qXOixQAAAAut2nTJr3//vs6fPiwCgsLbd5zNLezO+GsWrWq7r33Xps2jkUCAADlCms4i7V48WINHDhQiYmJWr58ubp166bdu3crJydHvXv3dnhcuxPOBQsWOPxlAAAAZQEHvxdv8uTJ+utf/6phw4YpJCREr776qmJiYvToo48qIiLC4XEdepb6pUuXtHLlSr3xxhs6d+6cJOn48ePKy8tzOBAAAAB41r59+3TnnXdKkvz9/ZWfny+TyaSnn35ab775psPj2l3hPHTokLp3767Dhw/rwoULuv322xUSEqJp06bpwoULmjt3rsPBAAAAuAVT6sWqVq2atZhYp04dbd++XS1atNCZM2dUUFDg8Lh2VzhHjhypuLg4/frrrwoKCrK29+7dWxkZGQ4HAgAA4I1mz56t6OhoBQYGqkOHDtq4cWOJfXfs2KF7771X0dHRMplMSktLu+Yxf++WW27RihUrJEn333+/Ro4cqaFDh+rBBx9U165d7b63K+xOONesWaOxY8cWOXMzOjpax44dczgQAAAAt3H2Yy0drJguWbJEKSkpSk1NVVZWllq2bKnExESdPHmy2P4FBQWqX7++pk6dqvDwcKeMKUnbt2+XJM2aNUv9+vWTJL3wwgtKSUlRTk6O7r33Xv3jH/+w/wb/w+6E02KxyGw2F2k/evSoQkJCHA4EAADA28ycOVNDhw5VcnKymjZtqrlz56pSpUqaP39+sf3btWunv/zlL+rXr58CAgKcMqZ0+amRHTp00EcffWTN53x8fPTcc89p2bJlmjFjhqpVq+bwfdqdcHbr1s2mfGsymZSXl6fU1FT16NHD4UAAAADcxZUHv+fm5tpcv39Yzu8VFhZq8+bNSkhIsLb5+PgoISFB69atc+i+HB1z9erVatasmf785z8rIiJCSUlJWrNmjUMxFMfuTUMzZsxQYmKimjZtqvPnz6t///7as2ePatasqffee89pgdnD8PWV4evrke92yDU8ixQAypPu9dp7OgQHFP5xF+Aq/vd88tTUVL344otF+p06dUpms1lhYWE27WFhYdq1a5dD3+3omJ07d1bnzp31+uuv6/3339fChQvVpUsXNWzYUEOGDFFSUlKJU/ilYXfCef3112vbtm1asmSJtm3bpry8PA0ZMkQDBgyw2UQEAABQZrlwl/qRI0dUpUoVa3NJU99lUXBwsJKTk5WcnKy9e/dqwYIFmj17tsaNG6fu3btr2bJlDo1rd8L59ddfq2PHjhowYIAGDBhgbb906ZK+/vpr3XLLLQ4FAgAA4DYuTDirVKlik3CWpGbNmvL19VVOTo5Ne05OjsPVRGeO2bBhQz3//POqV6+exowZo88//9yhmCQH1nDeeuutOn36dJH2s2fP6tZbb3U4EAAAAG/i7++vtm3b2hwrabFYlJGRofj4eI+O+fXXX2vQoEEKDw/X6NGj1adPH3377bcOxSQ5UOE0DEOmYtYg/vLLLwoODnY4EAAAAHcpK4+2TElJUVJSkuLi4tS+fXulpaUpPz9fycnJkqSBAweqTp06mjJliqTLm4J+/PFH65+PHTumrVu3qnLlymrYsGGpxizJ8ePHtXDhQi1cuFB79+5Vx44d9dprr+mBBx645hyv1Alnnz59JF3elT5o0CCb9Qhms1nff/+9OnbseE3BAAAAeJO+ffvq559/1vjx45Wdna1WrVopPT3duunn8OHD8vH574T08ePH1bp1a+vrV155Ra+88oq6dOmizMzMUo1ZnDvuuEMrV65UzZo1NXDgQA0ePFg33nij0+6z1AlnaGiopMsVzpCQEJsNQv7+/rrppps0dOhQpwUGAADgMmXo0ZbDhw/X8OHDi33vShJ5RXR0tAzjj7/oamMW57rrrtOHH36ou+66S74uOPmn1AnnggULJF2+0VGjRjF9DgAAUEE4uvu8tOxew5mammrzevXq1crPz1d8fPw1nUAPAADgLmVlDae3KHXCOW3aNOXl5WnixImSLk+t33HHHVq+fLkkqXbt2srIyFCzZs1cEykAAADKpVIfi7RkyRI1b97c+vrDDz/U119/rTVr1ujUqVOKi4vThAkTXBIkAACAUxkuulCsUiecBw4cUGxsrPX1F198ofvuu0+dOnVS9erVNXbsWIef+wkAAOBWJJxuVeqE89KlSzZHIa1bt87mGKTIyEidOnXKudEBAACg3Ct1wtmgQQN9/fXXki6fCbV7926bx1gePXpUNWrUcH6EAAAATmZy0YXilXrT0LBhwzR8+HCtWbNG69evV3x8vJo2bWp9/9///rfNQaQAAACAZEfCOXToUPn6+upf//qXbrnlliLHIx0/flyDBw92eoAAAABOV4YOfvcGdp3DOXjw4BKTyr/97W9OCQgAAAAVi90HvwMAAJR3HPzuXqXeNAQAAAA4wuMJ57Fjx/TQQw+pRo0aCgoKUosWLbRp0yZPhwUAACoyzuF0K49Oqf/666/q1KmTbr31Vn355ZeqVauW9uzZwzPZAQCA65Eguo3DCefevXu1b98+3XLLLQoKCpJhGDKZ7DuBatq0aYqKitKCBQusbTExMY6GBAAAgDLI7in1X375RQkJCbrhhhvUo0cPnThxQpI0ZMgQ/fnPf7ZrrGXLlikuLk7333+/ateurdatW2vevHkl9r9w4YJyc3NtLgAAAHtd2TTk7AvFszvhfPrpp+Xn56fDhw+rUqVK1va+ffsqPT3drrH279+vOXPmqFGjRvrqq6/0+OOPa8SIEXrrrbeK7T9lyhSFhoZar6ioKHvDBwAAgJvZPaW+fPlyffXVV7r++utt2hs1aqRDhw7ZNZbFYlFcXJwmT54sSWrdurW2b9+uuXPnKikpqUj/MWPGKCUlxfo6NzeXpBMAANiPg9/dyu4KZ35+vk1l84rTp08rICDArrEiIiJsHo8pSU2aNNHhw4eL7R8QEKAqVarYXAAAACjb7E44O3furLffftv62mQyyWKxaPr06br11lvtGqtTp0766aefbNp2796tevXq2RsWAABAqbGG073snlKfPn26unbtqk2bNqmwsFDPPPOMduzYodOnT+vbb7+1a6ynn35aHTt21OTJk/XAAw9o48aNevPNN/Xmm2/aGxYAAADKKLsrnM2bN9fu3bt18803q2fPnsrPz1efPn20ZcsWNWjQwK6x2rVrp48//ljvvfeemjdvrokTJyotLU0DBgywNywAAIDS4+B3t3LoHM7Q0FC98MILTgngrrvu0l133eWUsQAAAFD2OJRwnj9/Xt9//71Onjwpi8Vi894999zjlMAAAABcxRVrLlnDWTK7E8709HQNHDhQp06dKvKeyWSS2Wx2SmAAAAAuw7FIbmX3Gs4nn3xS999/v06cOCGLxWJzkWwCAADgf9ld4czJyVFKSorCwsJcEQ8AAIDrUeF0K7srnPfdd58yMzNdEAoAAAAqIrsrnLNmzdL999+vNWvWqEWLFrruuuts3h8xYoTTggMAAHAFNg25l90J53vvvafly5crMDBQmZmZMplM1vdMJhMJJwAAAGzYnXC+8MILmjBhgp577jn5+Ng9Iw8AAOB5rOF0K7szxsLCQvXt25dkEwAAAKVid9aYlJSkJUuWuCIWAAAAtzAZhksuFM/uKXWz2azp06frq6++UmxsbJFNQzNnznRacAAAAC7BlLpb2Z1w/vDDD2rdurUkafv27Tbv/X4DEQAAACA5kHCuWrXKFXEAAAC4DcciuRc7fwAAAOBSpapw9unTRwsXLlSVKlXUp0+fq/ZdunSpUwIDAABwGdZwulWpEs7Q0FDr+szQ0FCXBgQAAICKpVQJ54IFC/TSSy9p1KhRWrBggatjAgAAcCnWcLpXqddwTpgwQXl5ea6MBQAAABVQqXepGxxmCgAAKgrWcLqVXccicc4mAACoCJhSdy+7Es4bbrjhD5PO06dPX1NAAAAAqFjsSjgnTJjALnUAAFD+MaXuVnYlnP369VPt2rVdFQsAAAAqoFInnKzfBAAAFQlrLt2n1McisUsdAAAAjih1hdNisbgyDgAAAPcxjMuXs8dEsUpd4QQAAAAcYdemIQAAgIqAczjdi4QTAAB4H45Fcium1AEAAOBSVDgBAIDXMVkuX84eE8WjwgkAAACXosIJAAC8D2s43YoKJwAAAFyKCicAAPA6HIvkXlQ4AQAA4FJUOAEAgPfh0ZZuRcIJAAC8DlPq7sWUOgAAAFyKCicAAPA+HIvkVlQ4AQAA4FJUOAEAgNdhDad7UeEEAACAS1HhBAAA3odjkdyKCicAAABcigonAADwOqzhdC8STgAA4H04FsmtmFIHAACAS1HhBAAAXocpdfeiwgkAAACXosIJAAC8j8W4fDl7TBSLCicAAABcigonAADwPuxSdysqnAAAAHApKpwAAMDrmOSCXerOHa5CIeEEAADeh2epuxVT6gAAAHApKpwAAMDrcPC7e1HhBAAAgEuRcAIAAO9juOhywOzZsxUdHa3AwEB16NBBGzduvGr/Dz74QI0bN1ZgYKBatGihL774wub9QYMGyWQy2Vzdu3d3LDgnIeEEAADwkCVLliglJUWpqanKyspSy5YtlZiYqJMnTxbbf+3atXrwwQc1ZMgQbdmyRb169VKvXr20fft2m37du3fXiRMnrNd7773njtspEQknAADwOibDcMklSbm5uTbXhQsXSoxj5syZGjp0qJKTk9W0aVPNnTtXlSpV0vz584vt/+qrr6p79+4aPXq0mjRpookTJ6pNmzaaNWuWTb+AgACFh4dbr2rVqjnvx3MAm4Y8gWMTAHiJ9ENXnxosixIjW3k6BJRzUVFRNq9TU1P14osvFulXWFiozZs3a8yYMdY2Hx8fJSQkaN26dcWOvW7dOqWkpNi0JSYm6pNPPrFpy8zMVO3atVWtWjXddtttmjRpkmrUqOHYDTkBCScAAPA+lv9czh5T0pEjR1SlShVrc0BAQLHdT506JbPZrLCwMJv2sLAw7dq1q9jPZGdnF9s/Ozvb+rp79+7q06ePYmJitG/fPj3//PO64447tG7dOvn6+jpyZ9eMhBMAAHid30+BO3NMSapSpYpNwulu/fr1s/65RYsWio2NVYMGDZSZmamuXbt6JCbWcAIAAHhAzZo15evrq5ycHJv2nJwchYeHF/uZ8PBwu/pLUv369VWzZk3t3bv32oN2EAknAADwPmXgWCR/f3+1bdtWGRkZ1jaLxaKMjAzFx8cX+5n4+Hib/pK0YsWKEvtL0tGjR/XLL78oIiLCvgCdiIQTAADAQ1JSUjRv3jy99dZb2rlzpx5//HHl5+crOTlZkjRw4ECbTUUjR45Uenq6ZsyYoV27dunFF1/Upk2bNHz4cElSXl6eRo8erfXr1+vgwYPKyMhQz5491bBhQyUmJnrkHiXWcAIAAG9kGM4/NcaB8fr27auff/5Z48ePV3Z2tlq1aqX09HTrxqDDhw/Lx+e/9cGOHTtq0aJFGjt2rJ5//nk1atRIn3zyiZo3by5J8vX11ffff6+33npLZ86cUWRkpLp166aJEyeWuHnJHUg4AQAAPGj48OHWCuX/yszMLNJ2//336/777y+2f1BQkL766itnhucUJJwAAMDrmIzLl7PHRPFYwwkAAACXosIJAAC8TxlZw+ktqHACAADApahwAgAAr2OyXL6cPSaKR8IJAAC8D1PqbsWUOgAAAFyKCicAAPA+DjyKslRjolhUOAEAAOBSVDgBAIDXMRmGTE5ec+ns8SoSKpwAAABwKSqcAADA+7BL3a08WuE0m80aN26cYmJiFBQUpAYNGmjixIky+P8wAACACsOjFc5p06Zpzpw5euutt9SsWTNt2rRJycnJCg0N1YgRIzwZGgAAqMgMSc4+qJ16WYk8mnCuXbtWPXv21J133ilJio6O1nvvvaeNGzcW2//ChQu6cOGC9XVubq5b4gQAABULm4bcy6NT6h07dlRGRoZ2794tSdq2bZu++eYb3XHHHcX2nzJlikJDQ61XVFSUO8MFAACAAzxa4XzuueeUm5urxo0by9fXV2azWS+//LIGDBhQbP8xY8YoJSXF+jo3N5ekEwAA2M+QCzYNOXe4isSjCef777+vd999V4sWLVKzZs20detWPfXUU4qMjFRSUlKR/gEBAQoICPBApAAAAHCURxPO0aNH67nnnlO/fv0kSS1atNChQ4c0ZcqUYhNOAAAAp+BYJLfy6BrOgoIC+fjYhuDr6yuLxdnbxgAAAOApHq1w3n333Xr55ZdVt25dNWvWTFu2bNHMmTM1ePBgT4YFAAAqOoskkwvGRLE8mnC+/vrrGjdunJ544gmdPHlSkZGRevTRRzV+/HhPhgUAAAAn8mjCGRISorS0NKWlpXkyDAAA4GU4h9O9eJY6AADwPmwaciuPbhoCAABAxUeFEwAAeB8qnG5FhRMAAAAuRYUTAAB4HyqcbkWFEwAAAC5FhRMAAHgfDn53KyqcAAAAcCkqnAAAwOtw8Lt7kXACAADvw6Yht2JKHQAAAC5FhRMAAHgfiyGZnFyRtFDhLAkVTgAAALgUFU4AAOB9WMPpVlQ4AQAA4FJUOAEAgBdyQYVTVDhLQoUTAAAALkWFEwAAeB/WcLoVCScAAPA+FkNOnwLnWKQSMaUOAAAAl6LCCQAAvI9huXw5e0wUiwonAAAAXIoKJwAA8D5sGnIrKpwAAABwKSqcAADA+7BL3a2ocAIAAMClqHACAADvwxpOtyLhBAAA3seQCxJO5w5XkTClDgAAAJeiwgkAALwPU+puRYUTAAAALkWFEwAAeB+LRZKTH0Vp4dGWJaHCCQAAAJeiwgkAALwPazjdigonAAAAXIoKJwAA8D5UON2KhBMAAHgfnqXuVkypAwAAwKWocAIAAK9jGBYZhnOPMXL2eBUJFU4AAAC4FBVOAADgfQzD+Wsu2TRUIiqcAAAAcCkqnAAAwPsYLtilToWzRFQ4AQAA4FJUOAEAgPexWCSTk3eVs0u9RCScAADA+zCl7lZMqQMAAMClqHACAACvY1gsMpw8pc7B7yWjwgkAAACXosIJAAC8D2s43YoKJwAAAFyKCicAAPA+FkMyUeF0FyqcAAAAcCkqnAAAwPsYhiRnH/xOhbMkVDgBAADgUlQ4AQCA1zEshgwnr+E0qHCWiIQTAAB4H8Mi50+pc/B7SZhSBwAAgEuRcAIAAK9jWAyXXI6YPXu2oqOjFRgYqA4dOmjjxo1X7f/BBx+ocePGCgwMVIsWLfTFF1/Y3pthaPz48YqIiFBQUJASEhK0Z88eh2JzFhJOAAAAD1myZIlSUlKUmpqqrKwstWzZUomJiTp58mSx/deuXasHH3xQQ4YM0ZYtW9SrVy/16tVL27dvt/aZPn26XnvtNc2dO1cbNmxQcHCwEhMTdf78eXfdVhEknAAAwPsYFtdcdpo5c6aGDh2q5ORkNW3aVHPnzlWlSpU0f/78Yvu/+uqr6t69u0aPHq0mTZpo4sSJatOmjWbNmnX5tgxDaWlpGjt2rHr27KnY2Fi9/fbbOn78uD755JNr+cWuSbneNHRlN9glywUPR2Ifs3HR0yHYz1Lo6Qjsdqk8/s6SLL957r9AHVVef2u4Xu658reJgv89u94lXf6NPbmr+5IuOv1R6lfuKzc316Y9ICBAAQEBRfoXFhZq8+bNGjNmjLXNx8dHCQkJWrduXbHfsW7dOqWkpNi0JSYmWpPJAwcOKDs7WwkJCdb3Q0ND1aFDB61bt079+vVz6N6uVblOOM+dOydJWr1/jocj8QLZng7Aiwz71NMR2O2opwNAmVXtBk9H4Ij9ng7Aa5w7d06hoaFu/U5/f3+Fh4frm+wv/rizAypXrqyoqCibttTUVL344otF+p46dUpms1lhYWE27WFhYdq1a1ex42dnZxfbPzs72/r+lbaS+nhCuU44IyMjdeTIEYWEhMhkMjl17NzcXEVFRenIkSOqUqWKU8fGf/E7uwe/s3vwO7sHv7P7uOq3NgxD586dU2RkpNPGLK3AwEAdOHBAhYWumbkzDKNITlJcddPblOuE08fHR9dff71Lv6NKlSr8heYG/M7uwe/sHvzO7sHv7D6u+K3dXdn8vcDAQAUGBnrs+6+oWbOmfH19lZOTY9Oek5Oj8PDwYj8THh5+1f5X/t+cnBxFRETY9GnVqpUTo7cPm4YAAAA8wN/fX23btlVGRoa1zWKxKCMjQ/Hx8cV+Jj4+3qa/JK1YscLaPyYmRuHh4TZ9cnNztWHDhhLHdIdyXeEEAAAoz1JSUpSUlKS4uDi1b99eaWlpys/PV3JysiRp4MCBqlOnjqZMmSJJGjlypLp06aIZM2bozjvv1OLFi7Vp0ya9+eabkiSTyaSnnnpKkyZNUqNGjRQTE6Nx48YpMjJSvXr18tRtknCWJCAgQKmpqay7cDF+Z/fgd3YPfmf34Hd2H35r1+vbt69+/vlnjR8/XtnZ2WrVqpXS09Otm34OHz4sH5//Tkh37NhRixYt0tixY/X888+rUaNG+uSTT9S8eXNrn2eeeUb5+fl65JFHdObMGd18881KT0/36DICk8GT5gEAAOBCrOEEAACAS5FwAgAAwKVIOAEAAOBSJJwAAABwKRLOYsyePVvR0dEKDAxUhw4dtHHjRk+HVOFMmTJF7dq1U0hIiGrXrq1evXrpp59+8nRYFdrUqVOtx2XA+Y4dO6aHHnpINWrUUFBQkFq0aKFNmzZ5OqwKxWw2a9y4cYqJiVFQUJAaNGigiRMnevR53BXB119/rbvvvluRkZEymUzWZ3JfYRiGxo8fr4iICAUFBSkhIUF79uzxTLAot0g4/8eSJUuUkpKi1NRUZWVlqWXLlkpMTNTJkyc9HVqFsnr1ag0bNkzr16/XihUrdPHiRXXr1k35+fmeDq1C+u677/TGG28oNjbW06FUSL/++qs6deqk6667Tl9++aV+/PFHzZgxQ9WqVfN0aBXKtGnTNGfOHM2aNUs7d+7UtGnTNH36dL3++uueDq1cy8/PV8uWLTV79uxi358+fbpee+01zZ07Vxs2bFBwcLASExN1/vx5N0eK8oxjkf5Hhw4d1K5dO82aNUvS5RP/o6Ki9OSTT+q5557zcHQV188//6zatWtr9erVuuWWWzwdToWSl5enNm3a6G9/+5smTZqkVq1aKS0tzdNhVSjPPfecvv32W61Zs8bToVRod911l8LCwvSPf/zD2nbvvfcqKChI//znPz0YWcVhMpn08ccfWw8INwxDkZGR+vOf/6xRo0ZJks6ePauwsDAtXLhQ/fr182C0KE+ocP5OYWGhNm/erISEBGubj4+PEhIStG7dOg9GVvGdPXtWklS9enUPR1LxDBs2THfeeafN/67hXMuWLVNcXJzuv/9+1a5dW61bt9a8efM8HVaF07FjR2VkZGj37t2SpG3btumbb77RHXfc4eHIKq4DBw4oOzvb5u+P0NBQdejQgX8XYReeNPQ7p06dktlstp7uf0VYWJh27drloagqPovFoqeeekqdOnWyeVICrt3ixYuVlZWl7777ztOhVGj79+/XnDlzlJKSoueff17fffedRowYIX9/fyUlJXk6vArjueeeU25urho3bixfX1+ZzWa9/PLLGjBggKdDq7Cys7Mlqdh/F6+8B5QGCSc8btiwYdq+fbu++eYbT4dSoRw5ckQjR47UihUrPPo4M29gsVgUFxenyZMnS5Jat26t7du3a+7cuSScTvT+++/r3Xff1aJFi9SsWTNt3bpVTz31lCIjI/mdgTKOKfXfqVmzpnx9fZWTk2PTnpOTo/DwcA9FVbENHz5cn332mVatWqXrr7/e0+FUKJs3b9bJkyfVpk0b+fn5yc/PT6tXr9Zrr70mPz8/mc1mT4dYYURERKhp06Y2bU2aNNHhw4c9FFHFNHr0aD333HPq16+fWrRooT/96U96+umnNWXKFE+HVmFd+bePfxdxrUg4f8ff319t27ZVRkaGtc1isSgjI0Px8fEejKziMQxDw4cP18cff6x///vfiomJ8XRIFU7Xrl31ww8/aOvWrdYrLi5OAwYM0NatW+Xr6+vpECuMTp06FTnWa/fu3apXr56HIqqYCgoK5ONj+8+Wr6+vLBaLhyKq+GJiYhQeHm7z72Jubq42bNjAv4uwC1Pq/yMlJUVJSUmKi4tT+/btlZaWpvz8fCUnJ3s6tApl2LBhWrRokT799FOFhIRY1wKFhoYqKCjIw9FVDCEhIUXWxAYHB6tGjRqslXWyp59+Wh07dtTkyZP1wAMPaOPGjXrzzTf15ptvejq0CuXuu+/Wyy+/rLp166pZs2basmWLZs6cqcGDB3s6tHItLy9Pe/futb4+cOCAtm7dqurVq6tu3bp66qmnNGnSJDVq1EgxMTEaN26cIiMjrTvZgVIxUMTrr79u1K1b1/D39zfat29vrF+/3tMhVTiSir0WLFjg6dAqtC5duhgjR470dBgV0r/+9S+jefPmRkBAgNG4cWPjzTff9HRIFU5ubq4xcuRIo27dukZgYKBRv35944UXXjAuXLjg6dDKtVWrVhX793FSUpJhGIZhsViMcePGGWFhYUZAQIDRtWtX46effvJs0Ch3OIcTAAAALsUaTgAAALgUCScAAABcioQTAAAALkXCCQAAAJci4QQAAIBLkXACAADApUg4AQAA4FIknAAAAHApEk4A+B2TyaRPPvnE02EAQIVCwgl4gUGDBslkMhW5fv/85GuxcOFCVa1a1SljOWrQoEE82xkAyig/TwcAwD26d++uBQsW2LTVqlXLQ9GU7OLFi7ruuus8HQYAwImocAJeIiAgQOHh4TaXr6+vJOnTTz9VmzZtFBgYqPr162vChAm6dOmS9bMzZ85UixYtFBwcrKioKD3xxBPKy8uTJGVmZio5OVlnz561Vk5ffPFFScVPT1etWlULFy6UJB08eFAmk0lLlixRly5dFBgYqHfffVeS9Pe//11NmjRRYGCgGjdurL/97W923e///d//acSIEXrmmWdUvXp1hYeHW+O6Ys+ePbrlllsUGBiopk2basWKFUXGOXLkiB544AFVrVpV1atXV8+ePXXw4EFJ0q5du1SpUiUtWrTI2v/9999XUFCQfvzxR7viBYCKjIQT8HJr1qzRwIEDNXLkSP3444964403tHDhQr388svWPj4+Pnrttde0Y8cOvfXWW/r3v/+tZ555RpLUsWNHpaWlqUqVKjpx4oROnDihUaNG2RXDc889p5EjR2rnzp1KTEzUu+++q/Hjx+vll1/Wzp07NXnyZI0bN05vvfWWXeO+9dZbCg4O1oYNGzR9+nS99NJL1qTSYrGoT58+8vf314YNGzR37lw9++yzNp+/ePGiEhMTFRISojVr1ujbb79V5cqV1b17dxUWFqpx48Z65ZVX9MQTT+jw4cM6evSoHnvsMU2bNk1Nmza1K1YAqNAMABVeUlKS4evrawQHB1uv++67zzAMw+jatasxefJkm/7vvPOOERERUeJ4H3zwgVGjRg3r6wULFhihoaFF+kkyPv74Y5u20NBQY8GCBYZhGMaBAwcMSUZaWppNnwYNGhiLFi2yaZs4caIRHx9/1Xvs2bOn9XWXLl2Mm2++2aZPu3btjGeffdYwDMP46quvDD8/P+PYsWPW97/88kubmN955x3jxhtvNCwWi7XPhQsXjKCgIOOrr76ytt15551G586dja5duxrdunWz6Q8AMAzWcAJe4tZbb9WcOXOsr4ODgyVJ27Zt07fffmtT0TSbzTp//rwKCgpUqVIlrVy5UlOmTNGuXbuUm5urS5cu2bx/reLi4qx/zs/P1759+zRkyBANHTrU2n7p0iWFhobaNW5sbKzN64iICJ08eVKStHPnTkVFRSkyMtL6fnx8vE3/bdu2ae/evQoJCbFpP3/+vPbt22d9PX/+fN1www3y8fHRjh07ZDKZ7IoTACo6Ek7ASwQHB6thw4ZF2vPy8jRhwgT16dOnyHuBgYE6ePCg7rrrLj3++ON6+eWXVb16dX3zzTcaMmSICgsLr5pwmkwmGYZh03bx4sViY/t9PJI0b948dejQwabflTWnpfW/m49MJpMsFkupP5+Xl6e2bdta15X+3u83XG3btk35+fny8fHRiRMnFBERYVecAFDRkXACXq5Nmzb66aefik1GJWnz5s2yWCyaMWOGfHwuL/t+//33bfr4+/vLbDYX+WytWrV04sQJ6+s9e/aooKDgqvGEhYUpMjJS+/fv14ABA+y9nVJr0qSJjhw5YpMgrl+/3qZPmzZttGTJEtWuXVtVqlQpdpzTp09r0KBBeuGFF3TixAkNGDBAWVlZCgoKclnsAFDesGkI8HLjx4/X22+/rQkTJmjHjh3auXOnFi9erLFjx0qSGjZsqIsXL+r111/X/v379c4772ju3Lk2Y0RHRysvL08ZGRk6deqUNam87bbbNGvWLG3ZskWbNm3SY489VqojjyZMmKApU6botdde0+7du/XDDz9owYIFmjlzptPuOyEhQTfccIOSkpK0bds2rVmzRi+88IJNnwEDBqhmzZrq2bOn1qxZowMHDigzM1MjRozQ0aNHJUmPPfaYoqKiNHbsWM2cOVNms9nuTVMAUNGRcAJeLjExUZ999pmWL1+udu3a6aabbtJf//pX1atXT5LUsmVLzZw5U9OmTVPz5s317rvvasqUKTZjdOzYUY899pj69u2rWrVqafr06ZKkGTNmKCoqSp07d1b//v01atSoUq35fPjhh/X3v/9dCxYsUIsWLdSlSxctXLhQMTExTrtvHx8fffzxx/rtt9/Uvn17PfzwwzbrWCWpUqVK+vrrr1W3bl316dNHTZo00ZAhQ3T+/HlVqVJFb7/9tr744gu988478vPzU3BwsP75z39q3rx5+vLLL50WKwCUdybjfxdYAQAAAE5EhRMAAAAuRcIJAAAAlyLhBAAAgEuRcAIAAMClSDgBAADgUiScAAAAcCkSTgAAALgUCScAAABcioQTAAAALkXCCQAAAJci4QQAAIBL/T8SKYuLJeROhQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Grad-CAM Function\n",
        "def compute_grad_cam(model, input_data, class_index):\n",
        "    \"\"\"\n",
        "    Compute Grad-CAM for a specific class index.\n",
        "    Args:\n",
        "    - model: Trained CNN model.\n",
        "    - input_data: Preprocessed input sample (single sample).\n",
        "    - class_index: Index of the class for which Grad-CAM is calculated.\n",
        "    Returns:\n",
        "    - heatmap: Grad-CAM heatmap.\n",
        "    \"\"\"\n",
        "    # Get the last convolutional layer\n",
        "    last_conv_layer = model.get_layer('conv0')\n",
        "\n",
        "    # Create a model that outputs the feature maps and predictions\n",
        "    grad_model = Model(inputs=model.input, outputs=[last_conv_layer.output, model.output])\n",
        "\n",
        "    # Record operations for gradient computation\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_output, predictions = grad_model(input_data)\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    # Compute gradients of the class score w.r.t. feature maps\n",
        "    grads = tape.gradient(loss, conv_output)\n",
        "\n",
        "    # Compute weights by global average pooling of gradients\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Compute weighted combination of feature maps\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
        "\n",
        "    # Apply ReLU to retain positive values only\n",
        "    heatmap = tf.maximum(heatmap, 0)\n",
        "\n",
        "    # Normalize the heatmap to [0, 1]\n",
        "    heatmap /= tf.reduce_max(heatmap) + 1e-8\n",
        "    return heatmap.numpy()[0]\n"
      ],
      "metadata": {
        "id": "ih2RimjUybid"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-CAM Visualization Function\n",
        "def visualize_grad_cam(heatmap, input_data, title=\"Grad-CAM\"):\n",
        "    \"\"\"\n",
        "    Visualize Grad-CAM heatmap over the input sample.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(input_data[0, :, :, 0], cmap='gray', aspect='auto', alpha=0.6)  # Overlay input data\n",
        "    plt.imshow(heatmap, cmap='jet', aspect='auto', alpha=0.4)  # Overlay Grad-CAM heatmap\n",
        "    plt.colorbar(label=\"Importance\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Feature Index\")\n",
        "    plt.ylabel(\"Time Step (or Sample Index)\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "6LG1jigLzu_9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLg371M80Cy9",
        "outputId": "88a6e413-afb4-4409-8f44-1a4339eea9b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3663, 10, 11, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = load_model(\"/content/output/10t-10n-DOS2019-LUCID.h5\")"
      ],
      "metadata": {
        "id": "506n9Bhs4UA-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    sample_input = np.expand_dims(X_train[i + 5], axis=0)  # Select and reshape a single sample\n",
        "    predicted_class = np.argmax(cnn_model.predict(sample_input))  # Get predicted class\n",
        "    grad_cam_heatmap = compute_grad_cam(cnn_model, sample_input, class_index=predicted_class)\n",
        "\n",
        "    # Visualize Grad-CAM for each sample\n",
        "    visualize_grad_cam(grad_cam_heatmap, sample_input, title=f\"Grad-CAM for Sample {i+1}, Class {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_lhSeEHv4c2-",
        "outputId": "7e3d8ad8-3550-40c5-c0e7-9ec5fe1e5aff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApMAAAIjCAYAAABf3JCIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeUklEQVR4nO3de3zP9f//8ft7Y3tv2BDGWObMnCannFJZVuSQkvDJHNKnIj726SRlKEZffHQQUigROlCfDihZJJJjjh0YGzFJNptstr1+f/jt/endRnu9vd57b9636+Xyuny8n6/n6/l6vPaej0eP1+v5fNkMwzAEAAAAuMDH0wEAAACg5CKZBAAAgMtIJgEAAOAykkkAAAC4jGQSAAAALiOZBAAAgMtIJgEAAOAykkkAAAC4jGQSAAAALiOZBP7G4MGDFR4e7ukwLLd48WI1bNhQpUuXVvny5T0dTrF15MgR2Ww2LVq0yNOhWGbRokWy2Ww6cuSIp0MBcA0gmUSxlZiYqJEjR6p+/foKDAxUYGCgIiIiNGLECH3//feeDu+y0tLSNHHiRDVv3lxly5ZVQECAmjRpoieffFK//PJLgcfce++9stlsevLJJwvcn5CQIJvNJpvNprfffrvAPh06dJDNZlOTJk3+NsaDBw9q8ODBqlOnjubPn6/XXnut8Bfooq+//lp33HGHqlevLrvdruuvv149evTQ0qVL3X7u4iY8PNzxff55e+ihh65q3JycHC1cuFA333yzKlasKH9/f4WHh2vIkCHatm2bRdG71zfffKOOHTsqMDBQVatW1ahRo5Senu7psABcQSlPBwAU5OOPP1a/fv1UqlQpDRw4UM2bN5ePj48OHjyoDz74QHPmzFFiYqJq1qzp6VCdHD58WFFRUUpKSlLfvn314IMPys/PT99//73eeOMNrVy5Uj/++KPTMWlpafrvf/+r8PBwvfPOO5o6dapsNluB49vtdi1dulT/+Mc/nNqPHDmib775Rna7vVBxJiQkKDc3Vy+++KLq1q3r2sWa8O6776pfv36KjIzU6NGjVaFCBSUmJmrDhg2aP3++BgwY4PYYipvIyEj9+9//dmqrX7++y+P98ccf6tOnj1avXq2bbrpJTz/9tCpWrKgjR45oxYoVevPNN5WUlKQaNWpcbehus2vXLnXp0kWNGjXSzJkzdezYMU2fPl0//fSTPvvsM0+HB+AySCZR7Bw6dEj33XefatasqXXr1qlatWpO+6dNm6ZXX31VPj5XLqxnZGSoTJky7gzVSXZ2tvr06aOUlBQlJCSoY8eOTvsnT56sadOm5Tvu/fffV05OjhYsWKBbb71VGzZsUOfOnQs8R7du3fTRRx/p9OnTqlSpkqN96dKlCgkJUb169fT777//baynTp2SJEtvb58/f16BgYEF7pswYYIiIiK0ZcsW+fn5FRiLt6levXq+/yi4Go8//rhWr16t//znP/rXv/7ltC8uLk7/+c9/LDuXuzz99NOqUKGCEhISFBQUJOlSFXf48OFau3atunbt6uEIARSE29wodl544QVlZGRo4cKF+RJJSSpVqpRGjRqlsLAwR9vgwYNVtmxZHTp0SN26dVO5cuU0cOBASdLGjRvVt29fXX/99fL391dYWJjGjBmjP/74I9/Yq1atUpMmTWS329WkSROtXLmy0HG///772r17t8aNG5cvkZSkoKAgTZ48OV/7kiVLdNttt+mWW25Ro0aNtGTJksueo1evXvL399e7777r1L506VLde++98vX1/ds4w8PDFRcXJ0mqXLmybDabJkyY4Nj/6quvqnHjxvL391doaKhGjBihs2fPOo1x8803q0mTJtq+fbtuuukmBQYG6umnn77sOQ8dOqTWrVvnSyQlqUqVKk6fp0+frvbt2+u6665TQECAWrZsqffeey/fcTabTSNHjtS7776riIgIBQQEqF27dtqzZ48kad68eapbt67sdrtuvvnmfM8H/vka2rdvr4CAANWqVUtz58690o/P4eDBg7rnnntUsWJF2e12tWrVSh999FGhjs2TlZWljIwMU8cU5NixY5o3b55uu+22fImkJPn6+uqxxx67YlXyww8/VPfu3RUaGip/f3/VqVNHzz33nHJycpz6/fTTT7r77rtVtWpV2e121ahRQ/fdd59SU1MdfT7//HN17NhR5cuXV9myZdWgQYMr/n5Ilyr0n3/+uf7xj384EklJGjRokMqWLasVK1YU8qcBoKiRTKLY+fjjj1W3bl21bdvW1HHZ2dmKjo5WlSpVNH36dN19992SLt1iPX/+vB5++GG9/PLLio6O1ssvv6xBgwY5Hb927Vrdfffdstlsio+PV+/evU09a5aXSNx///2FjvmXX37R+vXr1b9/f0lS//799d577ykrK6vA/oGBgerVq5feeecdR9vu3bu1b9++Qt8qnjVrlu666y5J0pw5c7R48WL16dNH0qUK4ogRIxQaGqoZM2bo7rvv1rx589S1a1ddvHjRaZzffvtNd9xxhyIjIzVr1izdcsstlz1nXpX52LFjfxvfiy++qBYtWmjSpEmaMmWKSpUqpb59++qTTz7J13fjxo3697//rZiYGE2YMEEHDhzQnXfeqdmzZ+ull17SI488oscff1ybN2/W0KFD8x3/+++/q1u3bmrZsqVeeOEF1ahRQw8//LAWLFhwxRj37dunG2+8UQcOHNBTTz2lGTNmqEyZMurdu3eh/wPkyy+/VGBgoMqWLavw8HC9+OKLhTquIJ999pmys7NN/e791aJFi1S2bFnFxsbqxRdfVMuWLTV+/Hg99dRTjj5ZWVmKjo7Wli1b9Oijj2r27Nl68MEHdfjwYcd/cOzbt0933nmnMjMzNWnSJM2YMUM9e/bUpk2brnj+PXv2KDs7W61atXJq9/PzU2RkpHbu3OnytQFwMwMoRlJTUw1JRu/evfPt+/33341ff/3VsZ0/f96xLyYmxpBkPPXUU/mO+3O/PPHx8YbNZjOOHj3qaIuMjDSqVatmnD171tG2du1aQ5JRs2bNv429RYsWRnBw8N/2+7Pp06cbAQEBRlpammEYhvHjjz8akoyVK1c69Vu/fr0hyXj33XeNjz/+2LDZbEZSUpJhGIbx+OOPG7Vr1zYMwzA6d+5sNG7c+G/PGxcXZ0gyfv31V0fbqVOnDD8/P6Nr165GTk6Oo/2VV14xJBkLFixwtHXu3NmQZMydO7dQ1/nGG28Ykgw/Pz/jlltuMZ599llj48aNTufJ89fvKysry2jSpIlx6623OrVLMvz9/Y3ExERH27x58wxJRtWqVR0/U8MwjLFjxxqSnPrmXcOMGTMcbZmZmUZkZKRRpUoVIysryzAMw0hMTDQkGQsXLnT069Kli9G0aVPjwoULjrbc3Fyjffv2Rr169f7259GjRw9j2rRpxqpVq4w33njD6NSpkyHJeOKJJ/722IKMGTPGkGTs3LmzUP0XLlyY7+dR0N+Tf/7zn0ZgYKDjOnfu3On4Pbyc//znP/l+twrj3XffNSQZGzZsyLevb9++RtWqVU2NB6DoUJlEsZKWliZJKlu2bL59N998sypXruzYZs+ena/Pww8/nK8tICDA8eeMjAydPn1a7du3l2EYjmrHiRMntGvXLsXExCg4ONjR/7bbblNEREShYy9Xrlyh+uZZsmSJunfv7jiuXr16atmy5RVvdXft2lUVK1bUsmXLZBiGli1b5qhsXo0vvvhCWVlZ+te//uX0POrw4cMVFBSUrzLo7++vIUOGFGrsoUOHavXq1br55pv19ddf67nnnlOnTp1Ur149ffPNN059//x9/f7770pNTVWnTp20Y8eOfON26dLFadmmvGr23Xff7fRd5LUfPnzY6fhSpUrpn//8p+Ozn5+f/vnPf+rUqVPavn17gddy5swZffnll7r33nt17tw5nT59WqdPn9Zvv/2m6Oho/fTTTzp+/PgVfx4fffSRnnjiCfXq1UtDhw7VV199pejoaMekE7Py/t6Y/f37sz//3POuq1OnTjp//rwOHjwoSY6/G2vWrNH58+cLHCfvOdwPP/xQubm5hT5/3mMn/v7++fbZ7fYCH0sBUDyQTKJYyfvHsKClQObNm6fPP//8skvjlCpVqsBnwpKSkjR48GBVrFhRZcuWVeXKlR0TXPKe8zp69KikS8ncXzVo0MDp86+//qqTJ086trxYg4KCdO7cucJeqg4cOKCdO3eqQ4cO+vnnnx3bzTffrI8//tiRIPxV6dKl1bdvXy1dulQbNmxQcnKyJbOh834Gf71ePz8/1a5d27E/T/Xq1Qt8BvJyoqOjtWbNGp09e1YbNmzQiBEjdPToUd15551Ok3A+/vhj3XjjjbLb7apYsaIqV66sOXPmOD2Tl+f66693+pyX7Pz5edo/t/91clJoaGi+SVp5M6ovtwbjzz//LMMw9Oyzzzr9x03lypUdz6KanVRks9k0ZswYZWdnKyEhwdSxkhzPGJr5/furffv26a677lJwcLCCgoJUuXJlxwShvJ99rVq1FBsbq9dff12VKlVSdHS0Zs+e7fTd9OvXTx06dNADDzygkJAQ3XfffVqxYsXfJpZ5yWxmZma+fRcuXHBKdgEUL8zmRrESHBysatWqae/evfn25VWXLvePvL+/f74Z3jk5Obrtttt05swZPfnkk2rYsKHKlCmj48ePa/DgwaYqJ3lat27tlFjFxcVpwoQJatiwoXbu3Knk5OR8yUxB8pLiMWPGaMyYMfn2v//++5et/A0YMEBz587VhAkT1Lx580JXT63k6j/ugYGB6tSpkzp16qRKlSpp4sSJ+uyzzxQTE6ONGzeqZ8+euummm/Tqq6+qWrVqKl26tBYuXFjgepSXm3B0uXbDMFyK+c/yfmcee+wxRUdHF9jHleWW8n5nzpw5Y/rYhg0bSrr03GFkZKTp48+ePavOnTsrKChIkyZNUp06dWS327Vjxw49+eSTTn9PZsyYocGDB+vDDz/U2rVrNWrUKMXHx2vLli2qUaOGAgICtGHDBq1fv16ffPKJVq9ereXLl+vWW2/V2rVrL/vd5E22O3HiRL59J06cUGhoqOnrAlA0SCZR7HTv3l2vv/66tm7dqjZt2lzVWHv27NGPP/6oN99802nCzeeff+7UL2+9yp9++infGD/88IPT5yVLljjdcqtdu7YkqUePHnrnnXf09ttva+zYsVeMyzAMLV26VLfccoseeeSRfPufe+45LVmy5LLJZMeOHXX99dcrISGhwOWGXJH3M/jhhx8c1yRdmnSRmJioqKgoS87zZ3mTLfISiPfff192u11r1qxxut25cOFCy88tXZoA9dclpPLWAb3cW4/yfjalS5e29GeSdwu+cuXKpo+944475Ovrq7ffftulSTgJCQn67bff9MEHH+imm25ytCcmJhbYv2nTpmratKmeeeYZffPNN+rQoYPmzp2r559/XpLk4+OjLl26qEuXLpo5c6amTJmicePGaf369Zf9mTVp0kSlSpXStm3bdO+99zras7KytGvXLqc2AMULt7lR7DzxxBMKDAzU0KFDlZKSkm+/mepSXhXkz8cYhpFv5my1atUUGRmpN998M98SJ/v373fq26FDB0VFRTm2vOTinnvuUdOmTTV58mRt3rw5Xyznzp3TuHHjJEmbNm3SkSNHNGTIEN1zzz35tn79+mn9+vWXfWOOzWbTSy+9pLi4uKuawftnUVFR8vPz00svveT083rjjTeUmpqq7t27uzz2unXrCmz/9NNPJf3v1rqvr69sNpvTcjRHjhzRqlWrXD73lWRnZ2vevHmOz1lZWZo3b54qV66sli1bFnhMlSpVdPPNN2vevHkFVtF+/fXXK57zzJkz+ZbbuXjxoqZOnSo/P78rzoq/nLCwMMdajC+//HK+/bm5uZoxY8Zln8cs6O9JVlaWXn31Vad+aWlpys7Odmpr2rSpfHx8HLenC6qs5lVLC7qFnSc4OFhRUVF6++23nW7XL168WOnp6erbt+9ljwXgWVQmUezUq1dPS5cuVf/+/dWgQQPHG3AMw1BiYqKWLl0qHx+fQr3Jo2HDhqpTp44ee+wxHT9+XEFBQXr//fcLXNg7Pj5e3bt3V8eOHTV06FCdOXNGL7/8sho3blyo17mVLl1aH3zwgaKionTTTTfp3nvvVYcOHVS6dGnt27dPS5cuVYUKFTR58mQtWbJEvr6+l03QevbsqXHjxmnZsmWKjY0tsE+vXr3Uq1evv42rsCpXrqyxY8dq4sSJuv3229WzZ0/98MMPevXVV9W6deurWmC7V69eqlWrlnr06KE6deooIyNDX3zxhf773/+qdevW6tGjh6RLVemZM2fq9ttv14ABA3Tq1CnNnj1bdevWdcsrNENDQzVt2jQdOXJE9evX1/Lly7Vr1y699tprKl269GWPmz17tjp27KimTZtq+PDhql27tlJSUrR582YdO3ZMu3fvvuyxH330kZ5//nndc889qlWrls6cOaOlS5dq7969mjJliqpWreroe+TIEdWqVUsxMTF/+27wGTNm6NChQxo1apQ++OAD3XnnnapQoYKSkpL07rvv6uDBg7rvvvsKPLZ9+/aqUKGCYmJiNGrUKNlsNi1evDjff7h9+eWXGjlypPr27av69esrOztbixcvlq+vr2MprkmTJmnDhg3q3r27atasqVOnTunVV19VjRo1Clx/9c8mT56s9u3bq3PnznrwwQd17NgxzZgxQ127dtXtt99+xWMBeJBnJpEDf+/nn382Hn74YaNu3bqG3W43AgICjIYNGxoPPfSQsWvXLqe+MTExRpkyZQocZ//+/UZUVJRRtmxZo1KlSsbw4cON3bt351vuxTAM4/333zcaNWpk+Pv7GxEREcYHH3xgxMTEFGppoDy///67MX78eKNp06ZGYGCgYbfbjSZNmhhjx441Tpw4YWRlZRnXXXed0alTpyuOU6tWLaNFixaGYTgvDXQlV7M0UJ5XXnnFaNiwoVG6dGkjJCTEePjhh43ff//dpfPkeeedd4z77rvPqFOnjhEQEGDY7XYjIiLCGDdunNMSPoZxaRmhevXqGf7+/kbDhg2NhQsXOuL9M0nGiBEjnNrylvH5v//7P6f2gn5+edewbds2o127dobdbjdq1qxpvPLKKwWO+dfflUOHDhmDBg0yqlatapQuXdqoXr26ceeddxrvvffeFX8W27ZtM3r06GFUr17d8PPzM8qWLWt07NjRWLFiRb6+e/bsueySVwXJzs42Xn/9daNTp05GcHCwUbp0aaNmzZrGkCFDnJYNKmhpoE2bNhk33nijERAQYISGhhpPPPGEsWbNGkOSsX79esMwDOPw4cPG0KFDjTp16hh2u92oWLGiccsttxhffPGFY5x169YZvXr1MkJDQw0/Pz8jNDTU6N+/v/Hjjz8W6ho2btxotG/f3rDb7UblypWNESNG5PsdAVC82AzDgifSAaCEufnmm3X69OkCJ3sVF6+++qqeeOIJHTp0SCEhIZ4OBwAKxDOTAFBMrV+/XqNGjSKRBFCs8cwkABRTf30HOwAUR1QmAQAA4DKemQQAAIDLqEwCAADAZSSTAAAAcFmJnoCTm5urX375ReXKlZPNZvN0OAAAoBAMw9C5c+cUGhoqH5+ir2tduHBBWVlZbhnbz89PdrvdLWMXVyU6mfzll18UFhbm6TAAAIALkpOTC/U2MytduHBBNUJC9FtamlvGr1q1qhITE70qoSzRyWS5cuUkSUNbt5ZfqRJ9KQAAeI2s7Gwt+O47x7/jRXrurCz9lpamT6ZOVRmLE76MCxfU/amnlJWVRTJZUuTd2vYrVUr+JJMAAJQonnxErazdrrIBAZaO6a0P3JGBAQAAr+Mj62che+usZm+9bgAAAFiAyiQAAPA6VCat463XDQAAAAtQmQQAAF6HyqR1vPW6AQAAYAEqkwAAwOtQmbSOt143AAAALEBlEgAAeB0qk9YhmQQAAF7HJuvfWOOtb8Dx1iQaAAAAFqAyCQAAvA63ua3jrdcNAAAAC1CZBAAAXscm6ytqPDMJAAAAmERlEgAAeB2embSOt143AAAALEBlEgAAeB0qk9YhmQQAAF6HRcut461JNAAAACxAZRIAAHgdbnNbx1uvGwAAABYoFsnk7NmzFR4eLrvdrrZt22rr1q2eDgkAAFzDfNy0eSOPX/fy5csVGxuruLg47dixQ82bN1d0dLROnTrl6dAAAADwNzyeTM6cOVPDhw/XkCFDFBERoblz5yowMFALFizwdGgAAOAaRWXSOh697qysLG3fvl1RUVGONh8fH0VFRWnz5s35+mdmZiotLc1pAwAAgOd4NJk8ffq0cnJyFBIS4tQeEhKikydP5usfHx+v4OBgxxYWFlZUoQIAgGsIlUnrlKjrHjt2rFJTUx1bcnKyp0MCAAAlEMmkdTy6zmSlSpXk6+urlJQUp/aUlBRVrVo1X39/f3/5+/sXVXgAAAD4Gx5Nov38/NSyZUutW7fO0Zabm6t169apXbt2HowMAABcy2xu2ryRx9+AExsbq5iYGLVq1Upt2rTRrFmzlJGRoSFDhng6NAAAAPwNjyeT/fr106+//qrx48fr5MmTioyM1OrVq/NNygEAALCKTdbfnqUy6UEjR47UyJEjPR0GAAAATCoWySQAAEBRcsfsa2+dze2t1w0AAAALUJkEAABeh8qkdUgmAQCA1yGZtI63XjcAAAAsQGUSAAB4HXcsMu6tSwNRmQQAAIDLqEwCAACv42O7tFk9pjeiMgkAAACXUZkEAABex8fn0mb1mN7ISy8bAAAAVqAyCQAAvA7PTFqHZBIAAHgdbnNbx0svGwAAAFagMgkAALwOt7mtQ2USAAAALqMyCQAAvA/vU7QMlUkAAAC4jMokAADwPj6yvqTmpSU6L71sAAAAWIHKJAAA8D42WV9S89JnJq+JZHK3mquU/D0dBgAAKIRsZUra7NkgmIBjGW5zAwAAwGXXRGUSAADAFCqTlqEyCQAAAJdRmQQAAN6HpYEs46WXDQAAACtQmQQAAN6HyqRlvPSyAQAAYAUqkwAAwPswm9syJJMAAMD7kExahtvcAAAAcBmVSQAA4H2YgGMZL71sAAAAWIHKJAAA8D48M2kZKpMAAABwGZVJAADgfXhm0jJeetkAAACwApVJAADgfXhm0jJUJgEAAOAyKpMAAMD78MykZUgmAQCA9+E2t2W8NIcGAACAFahMAgAA72OT9SU1KpMAAACAOVQmAQCA9+GZSct4tDK5YcMG9ejRQ6GhobLZbFq1apUnwwEAAIBJHk0mMzIy1Lx5c82ePduTYQAAAG/j46bNC3n0Nvcdd9yhO+64w5MhAAAA4CqUqGcmMzMzlZmZ6ficlpbmwWgAAECJxTOTlilRBdn4+HgFBwc7trCwME+HBAAASiJuc1umRF322LFjlZqa6tiSk5M9HRIAAIBXK1HJpL+/v4KCgpw2AAAA02xu2lwwe/ZshYeHy263q23bttq6desV+8+aNUsNGjRQQECAwsLCNGbMGF24cMG1k1ugRCWTAAAA15Lly5crNjZWcXFx2rFjh5o3b67o6GidOnWqwP5Lly7VU089pbi4OB04cEBvvPGGli9frqeffrqII/8fjyaT6enp2rVrl3bt2iVJSkxM1K5du5SUlOTJsAAAwLWumDwzOXPmTA0fPlxDhgxRRESE5s6dq8DAQC1YsKDA/t988406dOigAQMGKDw8XF27dlX//v3/tprpTh5NJrdt26YWLVqoRYsWkqTY2Fi1aNFC48eP92RYAAAALktLS3Pa/rwSzZ9lZWVp+/btioqKcrT5+PgoKipKmzdvLvCY9u3ba/v27Y7k8fDhw/r000/VrVs36y+kkDy6NNDNN98swzA8GQIAAPBGblwa6K+rzcTFxWnChAn5up8+fVo5OTkKCQlxag8JCdHBgwcLPMWAAQN0+vRpdezYUYZhKDs7Ww899JBHb3OXqHUmAQAAirvk5GSnScL+/v6WjZ2QkKApU6bo1VdfVdu2bfXzzz9r9OjReu655/Tss89adh4zSCYBAID3cce6kP9/vMKuOFOpUiX5+voqJSXFqT0lJUVVq1Yt8Jhnn31W999/vx544AFJUtOmTZWRkaEHH3xQ48aNk49P0T/ByGxuAADgfYrB0kB+fn5q2bKl1q1b52jLzc3VunXr1K5duwKPOX/+fL6E0dfXV5I89ugglUkAAAAPiY2NVUxMjFq1aqU2bdpo1qxZysjI0JAhQyRJgwYNUvXq1RUfHy9J6tGjh2bOnKkWLVo4bnM/++yz6tGjhyOpLGokkwAAwPu48Ta3Gf369dOvv/6q8ePH6+TJk4qMjNTq1asdk3KSkpKcKpHPPPOMbDabnnnmGR0/flyVK1dWjx49NHnyZKuuwjSbUYKnU6elpSk4OFjt2j2kUqWse7gVAAC4T3Z2pjZvnqvU1NQif5tdXu6Q+sUsBZUJsHbsjD8UHPUvj1yXJ1GZBAAA3seNSwN5GybgAAAAwGVUJgEAgHfy0kqi1ahMAgAAwGVUJgEAgPcpJrO5rwUkkwAAwPuQTFrGSy8bAAAAVqAyCQAAvA9LA1mGyiQAAABcRmUSAAB4HyqTlqEyCQAAAJdRmQQAAN6H2dyW8dLLBgAAgBWoTAIAAO9DZdIyJJMAAMD7MAHHMl6aQwMAAMAKVCYBAID3oTJpGSqTAAAAcBmVSQAA4H2YgGMZL71sAAAAWIHKJAAA8D48M2kZKpMAAABwGZVJAADgfXhm0jIkkwAAwDt56W1pq3lpDg0AAAArUJkEAADeh9vclvHSywYAAIAVqEwCAADvw9JAlqEyCQAAAJdRmQQAAN6HZyYt46WXDQAAACtQmQQAAN6HZyYtQzIJAAC8D7e5LeOllw0AAAArUJkEAADeh9vclnEpmUxKStLRo0d1/vx5Va5cWY0bN5a/v7/VsQEAAKCYK3QyeeTIEc2ZM0fLli3TsWPHZBiGY5+fn586deqkBx98UHfffbd8fLh7DgAAijGembRMoS571KhRat68uRITE/X8889r//79Sk1NVVZWlk6ePKlPP/1UHTt21Pjx49WsWTN999137o4bAAAAxUChKpNlypTR4cOHdd111+XbV6VKFd1666269dZbFRcXp9WrVys5OVmtW7e2PFgAAABL8MykZQqVTMbHxxd6wNtvv93lYAAAAFCymL67f/DgwcvuW7NmzVUFAwAAUCR83LR5IdOXfcMNN2j27NlObZmZmRo5cqR69eplaqz4+Hi1bt1a5cqVU5UqVdS7d2/98MMPZkMCAAAwx+amzQuZTiYXLVqk8ePHq1u3bkpJSdGuXbvUokULffHFF9q4caOpsb766iuNGDFCW7Zs0eeff66LFy+qa9euysjIMBsWAAAAPMD0OpP33nuv2rdvryFDhqhx48bKyMjQ4MGDNWPGDAUGBpoaa/Xq1U6fFy1apCpVqmj79u266aabzIYGAABQOCwNZBmX34CTlZWlnJwc5eTkqFq1arLb7VcdTGpqqiSpYsWKBe7PzMxUZmam43NaWtpVnxMAAACuM51DL1u2TE2bNlVwcLB+/PFHffLJJ3rttdfUqVMnHT582OVAcnNz9a9//UsdOnRQkyZNCuwTHx+v4OBgxxYWFuby+QAAgJfjeUlLmE4mhw0bpilTpuijjz5S5cqVddttt2nPnj2qXr26IiMjXQ5kxIgR2rt3r5YtW3bZPmPHjlVqaqpjS05Odvl8AAAAuHqmb3Pv2LFDDRo0cGqrUKGCVqxYocWLF7sUxMiRI/Xxxx9rw4YNqlGjxmX7+fv78w5wAABw9Xhm0jKmL7tBgwbKzs7WF198oXnz5uncuXOSpF9++UV33XWXqbEMw9DIkSO1cuVKffnll6pVq5bZcAAAAOBBpiuTR48e1e23366kpCRlZmbqtttuU7ly5TRt2jRlZmZq7ty5hR5rxIgRWrp0qT788EOVK1dOJ0+elCQFBwcrICDAbGgAAACFw+sULWO6Mjl69Gi1atVKv//+u1PCd9ddd2ndunWmxpozZ45SU1N18803q1q1ao5t+fLlZsMCAACAB5iuTG7cuFHffPON/Pz8nNrDw8N1/PhxU2MZhmH29AAAAFePyqRlTCeTubm5ysnJydd+7NgxlStXzpKgAAAA3IoJOJYxfdldu3bVrFmzHJ9tNpvS09MVFxenbt26WRkbAAAAijnTlckZM2YoOjpaERERunDhggYMGKCffvpJlSpV0jvvvOOOGAEAAKxFZdIyppPJGjVqaPfu3Vq2bJm+//57paena9iwYRo4cCAzsAEAALyMS+/mLlWqlP7xj39YHQsAAEDRYAKOZQqVTH700UeFHrBnz54uBwMAAICSpVDJZO/evZ0+22y2fMv62GyX0vGCZnoDAAAUJ4bt0mb1mN6oUI+K5ubmOra1a9cqMjJSn332mc6ePauzZ8/qs88+0w033KDVq1e7O14AAAAUI6afmfzXv/6luXPnqmPHjo626OhoBQYG6sEHH9SBAwcsDRAAAMBqhs+lzeoxvZHpZPLQoUMqX758vvbg4GAdOXLEgpAAAADci2TSOqYvu3Xr1oqNjVVKSoqjLSUlRY8//rjatGljaXAAAAAo3kxXJhcsWKC77rpL119/vcLCwiRJycnJqlevnlatWmV1fAAAAJbLtV3arB7TG5lOJuvWravvv/9en3/+uQ4ePChJatSokaKiohwzugEAAOAdXFq03GazqWvXruratavV8QAAALidYfORYbP2IUerxyspXEom161bp3Xr1unUqVPKzc112rdgwQJLAgMAAEDxZzqZnDhxoiZNmqRWrVqpWrVq3NoGAAAljuFjk+FjbQ5j9Xglhelkcu7cuVq0aJHuv/9+d8QDAACAEsR0MpmVlaX27du7IxYAAIAiYcgmQxZXJi0er6Qw/aToAw88oKVLl7ojFgAAgCKRKx+3bN7IdGXywoULeu211/TFF1+oWbNmKl26tNP+mTNnWhYcAAAAijfTyeT333+vyMhISdLevXud9jEZBwAAlATc5raO6WRy/fr17ogDAAAAJZBL60wCAACUZFQmrVPoZLJPnz6F6vfBBx+4HAwAAABKlkInk8HBwe6MAwAAoMi4Y/Y1s7n/xsKFC90ZBwAAAEognpkEAABex5D1zzgalo5WcpBMAgAAr8MEHOt45819AAAAWILKJAAA8DpMwLGOd141AABAMTF79myFh4fLbrerbdu22rp16xX7nz17ViNGjFC1atXk7++v+vXr69NPPy2iaPNzKZlcvHixOnTooNDQUB09elSSNGvWLH344YeWBgcAAOAeNsdzk1ZtcuGZyeXLlys2NlZxcXHasWOHmjdvrujoaJ06darA/llZWbrtttt05MgRvffee/rhhx80f/58Va9e/Sp/Hq4znUzOmTNHsbGx6tatm86ePaucnBxJUvny5TVr1iyr4wMAALhmzZw5U8OHD9eQIUMUERGhuXPnKjAwUAsWLCiw/4IFC3TmzBmtWrVKHTp0UHh4uDp37qzmzZsXceT/YzqZfPnllzV//nyNGzdOvr6+jvZWrVppz549lgYHAADgDlZXJf88OzwtLc1py8zMLDCGrKwsbd++XVFRUY42Hx8fRUVFafPmzQUe89FHH6ldu3YaMWKEQkJC1KRJE02ZMsVR3PME08lkYmKiWrRoka/d399fGRkZlgQFAABQUoWFhSk4ONixxcfHF9jv9OnTysnJUUhIiFN7SEiITp48WeAxhw8f1nvvvaecnBx9+umnevbZZzVjxgw9//zzll9HYZmezV2rVi3t2rVLNWvWdGpfvXq1GjVqZFlgAAAA7pIrm3ItXhcyb7zk5GQFBQU52v39/a07R26uqlSpotdee02+vr5q2bKljh8/rv/7v/9TXFycZecxw3QyGRsbqxEjRujChQsyDENbt27VO++8o/j4eL3++uvuiBEAAMBShnxkWLyoTd54QUFBTsnk5VSqVEm+vr5KSUlxak9JSVHVqlULPKZatWoqXbq006OGjRo10smTJ5WVlSU/P7+ruALXmE4mH3jgAQUEBOiZZ57R+fPnNWDAAIWGhurFF1/Ufffd544YAQAArjl+fn5q2bKl1q1bp969e0u6VHlct26dRo4cWeAxHTp00NKlS5Wbmysfn0vJ648//qhq1ap5JJGUXFwaaODAgfrpp5+Unp6ukydP6tixYxo2bJjVsQEAALiFOyfgmBEbG6v58+frzTff1IEDB/Twww8rIyNDQ4YMkSQNGjRIY8eOdfR/+OGHdebMGY0ePVo//vijPvnkE02ZMkUjRoyw7Gdj1lW9AScwMFCBgYFWxQIAAOBV+vXrp19//VXjx4/XyZMnFRkZqdWrVzsm5SQlJTkqkNKlyT1r1qzRmDFj1KxZM1WvXl2jR4/Wk08+6alLkM0wDOPvOrVo0UI2W+Gy7R07dlx1UIWVlpam4OBgtWv3kEqVsu7hVgAA4D7Z2ZnavHmuUlNTC/VsoZXycocfUt9WuSBrC2Ln0s6rQfA/PHJdnlSoymTefXwAAADgzwqVTHpqqjkAAIA7uPqM49+N6Y1cfmZy27ZtOnDggCQpIiJCLVu2tCwoAAAAlAymk8ljx46pf//+2rRpk8qXLy9JOnv2rNq3b69ly5apRo0aVscIAABgqVz5KNfidSatHs+dFi9erLlz5yoxMVGbN29WzZo1NWvWLNWqVUu9evUyNZbpq37ggQd08eJFHThwQGfOnNGZM2d04MAB5ebm6oEHHjA7HAAAQJErLksDecKcOXMUGxurbt266ezZs473epcvX16zZs0yPZ7pZPKrr77SnDlz1KBBA0dbgwYN9PLLL2vDhg2mAwAAAEDRefnllzV//nyNGzfO6U06rVq10p49e0yPZzqZDAsL08WLF/O15+TkKDQ01NRYc+bMUbNmzRyvHWrXrp0+++wzsyEBAACY4s2VycTERLVo0SJfu7+/vzIyMkyPZzqZ/L//+z89+uij2rZtm6Nt27ZtGj16tKZPn25qrBo1amjq1Knavn27tm3bpltvvVW9evXSvn37zIYFAACAQqhVq5Z27dqVr3316tVq1KiR6fFMT8AZPHiwzp8/r7Zt26pUqUuHZ2dnq1SpUho6dKiGDh3q6HvmzJkrjtWjRw+nz5MnT9acOXO0ZcsWNW7c2GxoAAAAheLNE3BiY2M1YsQIXbhwQYZhaOvWrXrnnXcUHx+v119/3fR4ppNJVx7MLIycnBy9++67ysjIULt27Qrsk5mZqczMTMfntLQ0t8QCAABwrXrggQcUEBCgZ555RufPn9eAAQMUGhqqF198Uffdd5/p8UwnkzExMaZPciV79uxRu3btdOHCBZUtW1YrV65UREREgX3j4+M1ceJES88PAAC8j7cvWj5w4EANHDhQ58+fV3p6uqpUqeLyWC4vWn7q1CmdOnVKubm5Tu3NmjUzNU6DBg20a9cupaam6r333lNMTIy++uqrAhPKsWPHKjY21vE5LS1NYWFhrl0AAACAF0pMTFR2drbq1aunwMBABQZeekf5Tz/9pNKlSys8PNzUeKaTye3btysmJkYHDhyQYRhO+2w2m2OtosLy8/NT3bp1JUktW7bUd999pxdffFHz5s3L19ff31/+/v5mQwYAAHBiyPpKovH3XYqFwYMHa+jQoapXr55T+7fffqvXX39dCQkJpsYznUwOHTpU9evX1xtvvKGQkBDZbNZ+Ebm5uU7PRQIAAFjNmyfg7Ny5Ux06dMjXfuONN2rkyJGmxzOdTB4+fFjvv/++o5p4NcaOHas77rhD119/vc6dO6elS5cqISFBa9asueqxAQAAkJ/NZtO5c+fytaemppq+wyy5sM5kly5dtHv3btMnKsipU6c0aNAgNWjQQF26dNF3332nNWvW6LbbbrNkfAAAgIK5Y8HykjEB56abblJ8fLxT4piTk6P4+Hh17NjR9HimK5Ovv/66YmJitHfvXjVp0kSlS5d22t+zZ89Cj/XGG2+YPT0AAACuwrRp03TTTTepQYMG6tSpkyRp48aNSktL05dffml6PNPJ5ObNm7Vp06YCX3voygQcAACAoubNSwNFRETo+++/1yuvvKLdu3crICBAgwYN0siRI1WxYkXT45lOJh999FH94x//0LPPPquQkBDTJwQAAIBnhYaGasqUKZaMZTqZ/O233zRmzBgSSQAAUGJ582xuSTp79qy2bt1a4JrhgwYNMjWW6WSyT58+Wr9+verUqWP2UAAAAHjYf//7Xw0cOFDp6ekKCgpyWubRZrO5P5msX7++xo4dq6+//lpNmzbNNwFn1KhRZocEAAAoUt78zOS///1vDR06VFOmTHG8/eZquDSbu2zZsvrqq6/01VdfOe2z2WwkkwAAoNjz5mTy+PHjGjVqlCWJpORCMpmYmGjJiQEAAFD0oqOjtW3bNtWuXduS8UwnkwAAACWdN1cmu3fvrscff1z79+8v8JFFM2uGSy4mk8eOHdNHH32kpKQkZWVlOe2bOXOmK0MCAACgCAwfPlySNGnSpHz7XFkz3HQyuW7dOvXs2VO1a9fWwYMH1aRJEx05ckSGYeiGG24wOxwAAECRy5VNuRZXEq0ez13+uhTQ1TK9INLYsWP12GOPac+ePbLb7Xr//feVnJyszp07q2/fvpYGBwAAgOLNdGXywIEDeueddy4dXKqU/vjjD5UtW1aTJk1Sr1699PDDD1seJAAAgJUM+ciweJFxq8dzp4yMDH311VcFPrJodmUe08lkmTJlHCetVq2aDh06pMaNG0uSTp8+bXY4AAAAFKGdO3eqW7duOn/+vDIyMlSxYkWdPn1agYGBqlKliulk0nQKfeONN+rrr7+WJHXr1k3//ve/NXnyZA0dOlQ33nij2eEAAACKXN5sbqu3kmDMmDHq0aOHfv/9dwUEBGjLli06evSoWrZsqenTp5sez3RlcubMmUpPT5ckTZw4Uenp6Vq+fLnq1avHTG4AAIBibteuXZo3b558fHzk6+urzMxM1a5dWy+88IJiYmLUp08fU+OZTib/vMBlmTJlNHfuXLNDAAAAeJQ3rzNZunRp+fhcujldpUoVJSUlqVGjRgoODlZycrLp8a5q0fILFy5o+fLlOn/+vG677TbVrVv3aoYDAAAoErnyUa7FE2asHs9dWrRooe+++0716tVT586dNX78eJ0+fVqLFy9WkyZNTI9X6KuOjY3Vo48+6viclZWldu3aafjw4Ro7dqwiIyO1efNm0wEAAACg6EyZMkXVqlWTJE2ePFkVKlTQww8/rF9//VXz5s0zPV6hK5Nr167VlClTHJ+XLFmio0eP6qefftL111+voUOH6vnnn9cnn3xiOggAAICi5M23uVu1auX4c5UqVbR69eqrGq/QlcmkpCRFREQ4Pq9du1b33HOPatasKZvNptGjR2vnzp1XFQwAAADc69Zbb9XZs2fztaelpenWW281PV6hk0kfHx8ZhuH4vGXLFqelgMqXL6/ff//ddAAAAABFzZA7lgcqGRISEvItVC5dmguzceNG0+MV+jZ3o0aN9N///lexsbHat2+fkpKSdMsttzj2Hz16VCEhIaYDAAAAgPt9//33jj/v379fJ0+edHzOycnR6tWrVb16ddPjFjqZfOKJJ3Tffffpk08+0b59+9StWzfVqlXLsf/TTz9VmzZtTAcAAABQ1LxxNndkZKRsNptsNluBt7MDAgL08ssvmx630MnkXXfdpU8//VQff/yxunbt6jSzW5ICAwP1yCOPmA4AAAAA7peYmCjDMFS7dm1t3bpVlStXduzz8/NTlSpV5Ovra3pcU+tMdunSRV26dClwX1xcnOmTAwAAeIY7Xn9YvGdz16xZUxcvXlRMTIyuu+461axZ05Jxi3c9FgAAwA289d3cpUuX1sqVKy0dk2QSAADAi/Tq1UurVq2ybLyrep0iAABASeSNE3Dy1KtXT5MmTdKmTZvUsmVLlSlTxmn/qFGjTI1nKpk0DEPJycmqUqWK7Ha7qRMBAADA89544w2VL19e27dv1/bt25322Ww29yeTdevW1b59+1SvXj1TJwIAACguvPl1iomJiZaOZ6oe6+Pjo3r16um3336zNAgAAAAUPcMwnN5w6ArTN/enTp2qxx9/XHv37r2qEwMAAHiKt87mzvPWW2+padOmCggIUEBAgJo1a6bFixe7NJbpCTiDBg3S+fPn1bx5c/n5+SkgIMBp/5kzZ1wKBAAAAO43c+ZMPfvssxo5cqQ6dOggSfr666/10EMP6fTp0xozZoyp8Uwnk7NmzTJ7CAAAQLGSK5tyLa4kWj2eu7z88suaM2eOBg0a5Gjr2bOnGjdurAkTJrg/mYyJiTF7CAAAQLFiyEeGxUv5WD2eu5w4cULt27fP196+fXudOHHC9HgurTOZk5OjVatW6cCBA5Kkxo0bq2fPni69zxEAAABFp27dulqxYoWefvppp/bly5e7tFqP6WTy559/Vrdu3XT8+HE1aNBAkhQfH6+wsDB98sknqlOnjukgAAAAipI3Lw00ceJE9evXTxs2bHA8M7lp0yatW7dOK1asMD2e6XrsqFGjVKdOHSUnJ2vHjh3asWOHkpKSVKtWLdOLXAIAAKBo3X333fr2229VqVIlrVq1SqtWrVKlSpW0detW3XXXXabHM12Z/Oqrr7RlyxZVrFjR0Xbddddp6tSpjuwWAACgOPPmyqQktWzZUm+//bYlY5lOJv39/XXu3Ll87enp6fLz87MkKAAAALhPTk6OVq5c6Zj/EhERoV69eqlUKfPTaUzf5r7zzjv14IMP6ttvv3Wsmr5lyxY99NBD6tmzp+kAAAAAipo3L1q+b98+1a9fXzExMVq5cqVWrlypmJgY1atXz6WX0phOJl966SXVqVNH7dq1k91ul91uV4cOHVS3bl29+OKLpgMAAABA0XnggQfUuHFjHTt2zDH/JTk5Wc2aNdODDz5oejzTtczy5cvrww8/1M8//+wojTZq1Eh169Y1fXIAAABPyJWPci1eF9Lq8dxl165d2rZtmypUqOBoq1ChgiZPnqzWrVubHs+ldSalS2sUkUACAICSyJsn4NSvX18pKSlq3LixU/upU6dcyu0KlUJPnTpVf/zxR6EG/Pbbb/XJJ5+YDgQAAADuFx8fr1GjRum9997TsWPHdOzYMb333nv617/+pWnTpiktLc2xFUahKpP79+/X9ddfr759+6pHjx5q1aqVKleuLEnKzs7W/v379fXXX+vtt9/WL7/8orfeesv1KwQAAHAzQ9ZXEg1LR3OfO++8U5J07733yma79DMwjEvR9+jRw/HZZrMpJyfnb8crVDL51ltvaffu3XrllVc0YMAApaWlydfXV/7+/jp//rwkqUWLFnrggQc0ePBg2e1281cGAAAAt1u/fr2l4xX6mcnmzZtr/vz5mjdvnr7//nsdPXpUf/zxhypVqqTIyEhVqlTpqgKZOnWqxo4dq9GjR2vWrFlXNRYAAMCVePMEnM6dO1s6nukJOD4+PoqMjFRkZKRlQXz33XeaN2+emjVrZtmYAAAAKNiFCxf0/fff69SpU8rNzXXaZ3bdcJdnc1slPT1dAwcO1Pz58/X88897OhwAAOAV3LHIeMmYzb169WoNGjRIp0+fzrevsM9J/pnH67EjRoxQ9+7dFRUV9bd9MzMznWYYFXaWEQAAAC559NFH1bdvX504cUK5ublOm9lEUvJwZXLZsmXasWOHvvvuu0L1j4+P18SJE90cFQAAuNZ58zqTKSkpio2NVUhIiCXjeawymZycrNGjR2vJkiWFnv09duxYpaamOrbk5GQ3RwkAAK5FeRNwrN5KgnvuuUcJCQmWjXdVlcm8ZC4sLMz0sdu3b9epU6d0ww03ONpycnK0YcMGvfLKK8rMzJSvr6/TMf7+/vL397+akAEAALzaK6+8or59+2rjxo1q2rSpSpcu7bR/1KhRpsYznUxmZ2dr4sSJeumll5Seni5JKlu2rB599FHFxcXlC+hyunTpoj179ji1DRkyRA0bNtSTTz6ZL5EEAACwijff5n7nnXe0du1a2e12JSQkOBYuly5NwHF7Mvnoo4/qgw8+0AsvvKB27dpJkjZv3qwJEybot99+05w5cwo1Trly5dSkSROntjJlyui6667L1w4AAABrjBs3ThMnTtRTTz0lH5+rvzVvOplcunSpli1bpjvuuMPR1qxZM4WFhal///6FTiYBAAA8xZsrk1lZWerXr58liaTkwgQcf39/hYeH52uvVauW/Pz8riqYhIQE3n4DAADgRjExMVq+fLll45muTI4cOVLPPfecFi5c6JgMk5mZqcmTJ2vkyJGWBQYAAOAu3vw6xZycHL3wwgtas2aNmjVrlm++y8yZM02NZzqZ3Llzp9atW6caNWqoefPmkqTdu3crKytLXbp0UZ8+fRx9P/jgA7PDAwAAwI327NmjFi1aSJL27t171eOZTibLly+vu+++26nNlaWBAAAAPMWbn5lcv369peOZTiYXLlxoaQAAAABFzRuTyT/fPb4cm82m999/39S4Li1anp2drYSEBB06dEgDBgxQuXLl9MsvvygoKEhly5Z1ZUgAAAC4UXBwsFvGNZ1MHj16VLfffruSkpKUmZmp2267TeXKldO0adOUmZmpuXPnuiNOAAAAy3hjZdJdd5dNTzsaPXq0WrVqpd9//10BAQGO9rvuukvr1q2zNDgAAIBr3ezZsxUeHi673a62bdtq69athTpu2bJlstls6t27t3sD/Bumk8mNGzfqmWeeybemZHh4uI4fP25ZYAAAAO6SK5tbNrOWL1+u2NhYxcXFaceOHWrevLmio6N16tSpKx535MgRPfbYY+rUqZOrPwLLmE4mc3NzlZOTk6/92LFjKleunCVBAQAAeIOZM2dq+PDhGjJkiCIiIjR37lwFBgZqwYIFlz0mJydHAwcO1MSJE1W7du0ijLZgppPJrl27Or2lxmazKT09XXFxcerWrZuVsQEAALiFIR+3bJKUlpbmtGVmZhYYQ1ZWlrZv366oqChHm4+Pj6KiorR58+bLxj5p0iRVqVJFw4YNs/aH4iLTyeSMGTO0adMmRURE6MKFCxowYIDjFve0adPcESMAAECJERYWpuDgYMcWHx9fYL/Tp08rJydHISEhTu0hISE6efJkgcd8/fXXeuONNzR//nzL43aV6dncNWrU0O7du7V8+XLt3r1b6enpGjZsmAYOHOg0IQcAAKC4cuds7uTkZAUFBTna814/fbXOnTun+++/X/Pnz1elSpUsGdMKppPJDRs2qH379ho4cKAGDhzoaM/OztaGDRt00003WRogAACA1QxZv5SP8f//NygoyCmZvJxKlSrJ19dXKSkpTu0pKSmqWrVqvv6HDh3SkSNH1KNHD0dbbm6uJKlUqVL64YcfVKdOHdcvwEWmb3PfcsstOnPmTL721NRU3XLLLZYEBQAAcK3z8/NTy5YtnZZWzM3N1bp169SuXbt8/Rs2bKg9e/Zo165djq1nz5665ZZbtGvXLo+93tp0ZdIwDNls+TP53377TWXKlLEkKAAAAHfKlY9yzdfU/nZMs2JjYxUTE6NWrVqpTZs2mjVrljIyMjRkyBBJ0qBBg1S9enXFx8fLbrerSZMmTseXL19ekvK1F6VCJ5N573O02WwaPHiw0/3/nJwcff/992rfvr31EQIAAFyj+vXrp19//VXjx4/XyZMnFRkZqdWrVzsm5SQlJcnHx9qk12qFTibz3udoGIbKlSvnNNnGz89PN954o4YPH259hAAAABYrTq9THDlypEaOHFngvoSEhCseu2jRIpfOaaVCJ5N573MMDw/XY489xi1tAAAAmH9mMi4uzunzV199pYyMDLVr104VKlSwLDAAAAD3sb4yKcvHKxkKnUxOmzZN6enpeu655yRdut19xx13aO3atZKkKlWqaN26dWrcuLF7IgUAAECxU+gnOpcvX+40U+i9997Thg0btHHjRp0+fVqtWrXSxIkT3RIkAACAlfJmc1u9eaNCVyYTExPVrFkzx+dPP/1U99xzjzp06CBJeuaZZ9S3b1/rIwQAALCYYdhkGBZPwLF4vJKi0Cl0dna203JAmzdvdloKKDQ0VKdPn7Y2OgAAABRrhU4m69Spow0bNki6tObRjz/+6PTqxGPHjum6666zPkIAAACLGbk2t2zeqNC3uUeMGKGRI0dq48aN2rJli9q1a6eIiAjH/i+//FItWrRwS5AAAAAongqdTA4fPly+vr7673//q5tuuinfEkG//PKLhg4danmAAAAAVss1fJRrWPw6RYvHKylMrTM5dOjQyyaMr776qiUBAQAAoOQwvWg5AABASeeOZxy99ZlJ76zHAgAAwBJUJgEAgNehMmkdkkkAAOB1cnNtyrU4+bN6vJLC5dvcP//8s9asWaM//vhD0qV3dQMAAMC7mE4mf/vtN0VFRal+/frq1q2bTpw4IUkaNmyY/v3vf1seIAAAgOUMH/dsXsj0VY8ZM0alSpVSUlKSAgMDHe39+vXT6tWrLQ0OAAAAxZvpZybXrl2rNWvWqEaNGk7t9erV09GjRy0LDAAAwG0M26XN6jG9kOnKZEZGhlNFMs+ZM2fk7+9vSVAAAAAoGUwnk506ddJbb73l+Gyz2ZSbm6sXXnhBt9xyi6XBAQAAuEWuzT2bFzJ9m/uFF15Qly5dtG3bNmVlZemJJ57Qvn37dObMGW3atMkdMQIAAKCYMl2ZbNKkiX788Ud17NhRvXr1UkZGhvr06aOdO3eqTp067ogRAADAWlQmLePSouXBwcEaN26c1bEAAACghHEpmbxw4YK+//57nTp1Srm5uU77evbsaUlgAAAAbmP8/83qMb2Q6WRy9erVGjRokE6fPp1vn81mU05OjiWBAQAAuI0hKfdve5kf0wuZfmby0UcfVd++fXXixAnl5uY6bSSSAAAA3sV0ZTIlJUWxsbEKCQlxRzwAAADux21uy5iuTN5zzz1KSEhwQygAAAAoaUxXJl955RX17dtXGzduVNOmTVW6dGmn/aNGjbIsOAAAALfIlfXPTFo9XglhOpl85513tHbtWtntdiUkJMhm+9+aSjabzVQyOWHCBE2cONGprUGDBjp48KDZsAAAAOABppPJcePGaeLEiXrqqafk42P6Lnk+jRs31hdffPG/gEq5tFoRAABA4VGZtIzpzC0rK0v9+vWzJJGULiWPVatWtWQsAAAAFC3TGWFMTIyWL19uWQA//fSTQkNDVbt2bQ0cOFBJSUmX7ZuZmam0tDSnDQAAwDTDTZsXMl2ZzMnJ0QsvvKA1a9aoWbNm+SbgzJw5s9BjtW3bVosWLVKDBg104sQJTZw4UZ06ddLevXtVrly5fP3j4+PzPWMJAABgGre5LWM6mdyzZ49atGghSdq7d6/Tvj9PximMO+64w/HnZs2aqW3btqpZs6ZWrFihYcOG5es/duxYxcbGOj6npaUpLCzM1DkBAABgHdPJ5Pr1690RhySpfPnyql+/vn7++ecC9/v7+8vf399t5wcAAF6CRcstY80sGoukp6fr0KFDqlatmqdDAQAAQCEUqjLZp08fLVq0SEFBQerTp88V+37wwQeFPvljjz2mHj16qGbNmvrll18UFxcnX19f9e/fv9BjAAAAmMYzk5YpVDIZHBzseB4yODjYspMfO3ZM/fv312+//abKlSurY8eO2rJliypXrmzZOQAAAOA+hUomFy5cqEmTJumxxx7TwoULLTv5smXLLBsLAACg0KhMWqbQz0xOnDhR6enp7owFAAAAJUyhZ3MbhpdOUQIAANceZnNbxtTSQGbXkQQAACiWuM1tGVPJZP369f82oTxz5sxVBQQAAICSw1QyOXHiREtncwMAAHgEt7ktYyqZvO+++1SlShV3xQIAAIASptDJJM9LAgCAa4Yh659x9NLKZKGXBmI2NwAAAP6q0JXJ3FwvnaIEAACuPczmtkyhK5MAAADAX5magAMAAHBNYDa3ZUgmAQCA9+E2t2W4zQ0AAACXUZkEAADeh9vclqEyCQAAAJdRmQQAAN6HZyYtQ2USAAAALqMyCQAAvA+VSctQmQQAAIDLqEwCAADvw2xuy5BMAgAA78NtbstwmxsAAAAuozIJAAC8D7e5LUNlEgAAAC6jMgkAALwPz0xahsokAAAAXEZlEgAAeB9D1lcSeWYSAAAAMIfKJAAA8D7M5rYMySQAAPA+TMCxDLe5AQAA4DIqkwAAwPtwm9syVCYBAADgMiqTAADA+/DMpGWoTAIAAMBlVCYBAID3oTJpGSqTAAAAcBmVSQAA4H2YzW0ZkkkAAOB9uM1tGW5zAwAAwGVUJgEAgPehMmkZKpMAAAAeNHv2bIWHh8tut6tt27baunXrZfvOnz9fnTp1UoUKFVShQgVFRUVdsX9RIJkEAADex3DTZtLy5csVGxuruLg47dixQ82bN1d0dLROnTpVYP+EhAT1799f69ev1+bNmxUWFqauXbvq+PHj5k9uEZJJAAAAD5k5c6aGDx+uIUOGKCIiQnPnzlVgYKAWLFhQYP8lS5bokUceUWRkpBo2bKjXX39dubm5WrduXRFH/j8kkwAAwPvkummTlJaW5rRlZmYWGEJWVpa2b9+uqKgoR5uPj4+ioqK0efPmQl3G+fPndfHiRVWsWNHM1VuKZBIAAMBCYWFhCg4Odmzx8fEF9jt9+rRycnIUEhLi1B4SEqKTJ08W6lxPPvmkQkNDnRLSosZsbgAA4J3ctMh4cnKygoKCHJ/9/f3dcp6pU6dq2bJlSkhIkN1ud8s5CsPjlcnjx4/rH//4h6677joFBASoadOm2rZtm6fDAgAA1zI33uYOCgpy2i6XTFaqVEm+vr5KSUlxak9JSVHVqlWvGP706dM1depUrV27Vs2aNTN79ZbyaDL5+++/q0OHDipdurQ+++wz7d+/XzNmzFCFChU8GRYAAIDb+fn5qWXLlk6TZ/Im07Rr1+6yx73wwgt67rnntHr1arVq1aooQr0ij97mnjZtmsLCwrRw4UJHW61atTwYEQAA8ArF5N3csbGxiomJUatWrdSmTRvNmjVLGRkZGjJkiCRp0KBBql69uuO5y2nTpmn8+PFaunSpwsPDHc9Wli1bVmXLlrXsUszwaGXyo48+UqtWrdS3b19VqVJFLVq00Pz58y/bPzMzM98MKQAAgJKqX79+mj59usaPH6/IyEjt2rVLq1evdkzKSUpK0okTJxz958yZo6ysLN1zzz2qVq2aY5s+fbqnLsGzlcnDhw9rzpw5io2N1dNPP63vvvtOo0aNkp+fn2JiYvL1j4+P18SJEz0QKQAAuKYUo9cpjhw5UiNHjixwX0JCgtPnI0eOuHYSN/JoZTI3N1c33HCDpkyZohYtWujBBx/U8OHDNXfu3AL7jx07VqmpqY4tOTm5iCMGAADAn3m0MlmtWjVFREQ4tTVq1Ejvv/9+gf39/f3dNr0eAAB4kWJUmSzpPFqZ7NChg3744Qenth9//FE1a9b0UEQAAAAww6OVyTFjxqh9+/aaMmWK7r33Xm3dulWvvfaaXnvtNU+GBQAArnVUJi3j0cpk69attXLlSr3zzjtq0qSJnnvuOc2aNUsDBw70ZFgAAAAoJI+/TvHOO+/UnXfe6ekwAACANykm60xeCzyeTAIAABQ5kknLePzd3AAAACi5qEwCAADvwwQcy1CZBAAAgMuoTAIAAO9DZdIyVCYBAADgMiqTAADA+zCb2zJUJgEAAOAyKpMAAMD78MykZUgmAQCAd/LS29JW4zY3AAAAXEZlEgAAeB9uc1uGyiQAAABcRmUSAAB4HyqTlqEyCQAAAJdRmQQAAN6HRcstQ2USAAAALqMyCQAAvA/PTFqGZBIAAHgfkknLcJsbAAAALqMyCQAAvA8TcCxDZRIAAAAuI5kEAACAy0gmAQAA4DKSSQAAALiMZBIAAAAuI5kEAACAy0gmAQAA4DKSSQAAALiMRcsBAIAX4n2KVqEyCQAAAJdRmQQAAF6IyqRVqEwCAADAZVQmAQCAF6IyaRUqkwAAAHAZlUkAAOCFqExahWQSAAB4IZJJq3CbGwAAAC6jMgkAALwQlUmrUJkEAACAy6hMAgAAL2T8/83qMb0PlUkAAAC4jMokAADwQjwzaRUqkwAAAHAZlUkAAOCFqExahWQSAAB4IUPWJ39MwAEAAABM8WgyGR4eLpvNlm8bMWKEJ8MCAADXPMNNm/fx6G3u7777Tjk5OY7Pe/fu1W233aa+fft6MCoAAAAUlkeTycqVKzt9njp1qurUqaPOnTt7KCIAAOAdmIBjlWIzAScrK0tvv/22YmNjZbPZCuyTmZmpzMxMx+e0tLSiCg8AAAAFKDYTcFatWqWzZ89q8ODBl+0THx+v4OBgxxYWFlZ0AQIAgGtIrps271Nsksk33nhDd9xxh0JDQy/bZ+zYsUpNTXVsycnJRRghAAAA/qpY3OY+evSovvjiC33wwQdX7Ofv7y9/f/8iigoAAFy7eGbSKsUimVy4cKGqVKmi7t27ezoUAADgFUgmreLx29y5ublauHChYmJiVKpUschtAQAAUEgez96++OILJSUlaejQoZ4OBQAAeA0qk1bxeDLZtWtXGYZ3rhgPAABQ0nk8mQQAACh67nj9oXcWxzz+zCQAAABKLiqTAADAC/HMpFWoTAIAAMBlVCYBAIAXojJpFZJJAADghQxZn/wxAQcAAAAwhcokAADwQtzmtgqVSQAAALiMyiQAAPBCLFpuFSqTAAAAcBmVSQAA4IV4ZtIqVCYBAADgMiqTAADAC1GZtAqVSQAAALiMyiQAAPBCVCatQjIJAAC8EMmkVbjNDQAAAJeRTAIAAC+U66bNvNmzZys8PFx2u11t27bV1q1br9j/3XffVcOGDWW329W0aVN9+umnLp3XKiSTAAAAHrJ8+XLFxsYqLi5OO3bsUPPmzRUdHa1Tp04V2P+bb75R//79NWzYMO3cuVO9e/dW7969tXfv3iKO/H9IJgEAgBcy3LSZM3PmTA0fPlxDhgxRRESE5s6dq8DAQC1YsKDA/i+++KJuv/12Pf7442rUqJGee+453XDDDXrllVdMn9sqJXoCjmFc+tKys7M8HAkAACisvH+38/4d94QLFzLcNmZaWppTu7+/v/z9/fP1z8rK0vbt2zV27FhHm4+Pj6KiorR58+YCz7F582bFxsY6tUVHR2vVqlVXGb3rSnQyee7cOUnSd98VnL0DAIDi69y5cwoODi7Sc/r5+alq1ap66qnubhm/bNmyCgsLc2qLi4vThAkT8vU9ffq0cnJyFBIS4tQeEhKigwcPFjj+yZMnC+x/8uTJqwv8KpToZDI0NFTJyckqV66cbDabp8NxWVpamsLCwpScnKygoCBPh+PV+C6KD76L4oPvoni5Fr4PwzB07tw5hYaGFvm57Xa7EhMTlZXlnruahmHky0kKqkpeS0p0Munj46MaNWp4OgzLBAUFldj/Y7jW8F0UH3wXxQffRfFS0r+Poq5I/pndbpfdbvfY+fNUqlRJvr6+SklJcWpPSUlR1apVCzymatWqpvoXBSbgAAAAeICfn59atmypdevWOdpyc3O1bt06tWvXrsBj2rVr59Rfkj7//PPL9i8KJboyCQAAUJLFxsYqJiZGrVq1Ups2bTRr1ixlZGRoyJAhkqRBgwapevXqio+PlySNHj1anTt31owZM9S9e3ctW7ZM27Zt02uvveaxayCZLAb8/f0VFxd3zT9TURLwXRQffBfFB99F8cL3cW3p16+ffv31V40fP14nT55UZGSkVq9e7Zhkk5SUJB+f/91Ibt++vZYuXapnnnlGTz/9tOrVq6dVq1apSZMmnroE2QxPzssHAABAicYzkwAAAHAZySQAAABcRjIJAAAAl5FMAgAAwGUkkx5w5swZDRw4UEFBQSpfvryGDRum9PT0Qh1rGIbuuOMO2Ww2j76H81pi9vs4c+aMHn30UTVo0EABAQG6/vrrNWrUKKWmphZh1NeG2bNnKzw8XHa7XW3bttXWrVuv2P/dd99Vw4YNZbfb1bRpU3366adFFOm1z8x3MX/+fHXq1EkVKlRQhQoVFBUV9bffHQrP7N+LPMuWLZPNZlPv3r3dGyDwFySTHjBw4EDt27dPn3/+uT7++GNt2LBBDz74YKGOnTVrVol+dWRxZPb7+OWXX/TLL79o+vTp2rt3rxYtWqTVq1dr2LBhRRh1ybd8+XLFxsYqLi5OO3bsUPPmzRUdHa1Tp04V2P+bb75R//79NWzYMO3cuVO9e/dW7969tXfv3iKO/Npj9rtISEhQ//79tX79em3evFlhYWHq2rWrjh8/XsSRX3vMfhd5jhw5oscee0ydOnUqokiBPzFQpPbv329IMr777jtH22effWbYbDbj+PHjVzx2586dRvXq1Y0TJ04YkoyVK1e6Odpr39V8H3+2YsUKw8/Pz7h48aI7wrwmtWnTxhgxYoTjc05OjhEaGmrEx8cX2P/ee+81unfv7tTWtm1b45///Kdb4/QGZr+Lv8rOzjbKlStnvPnmm+4K0Wu48l1kZ2cb7du3N15//XUjJibG6NWrVxFECvwPlckitnnzZpUvX16tWrVytEVFRcnHx0fffvvtZY87f/68BgwYoNmzZ3v0/ZvXGle/j79KTU1VUFCQSpXiPQCFkZWVpe3btysqKsrR5uPjo6ioKG3evLnAYzZv3uzUX5Kio6Mv2x+F48p38Vfnz5/XxYsXVbFiRXeF6RVc/S4mTZqkKlWqcHcEHsO/fEXs5MmTqlKlilNbqVKlVLFiRZ08efKyx40ZM0bt27dXr1693B2iV3H1+/iz06dP67nnniv0owq49DPLyclxvOEhT0hIiA4ePFjgMSdPniywf2G/JxTMle/ir5588kmFhobmS/Zhjivfxddff6033nhDu3btKoIIgYJRmbTIU089JZvNdsWtsP/H/FcfffSRvvzyS82aNcvaoK9h7vw+/iwtLU3du3dXRESEJkyYcPWBAyXM1KlTtWzZMq1cuVJ2u93T4XiVc+fO6f7779f8+fNVqVIlT4cDL0Zl0iL//ve/NXjw4Cv2qV27tqpWrZrvQers7GydOXPmsrevv/zySx06dEjly5d3ar/77rvVqVMnJSQkXEXk1yZ3fh95zp07p9tvv13lypXTypUrVbp06asN22tUqlRJvr6+SklJcWpPSUm57M+9atWqpvqjcFz5LvJMnz5dU6dO1RdffKFmzZq5M0yvYPa7OHTokI4cOaIePXo42nJzcyVdusPyww8/qE6dOu4NGpCYgFPU8iZ8bNu2zdG2Zs2aK074OHHihLFnzx6nTZLx4osvGocPHy6q0K9JrnwfhmEYqampxo033mh07tzZyMjIKIpQrzlt2rQxRo4c6fick5NjVK9e/YoTcO68806ntnbt2jEBxwJmvwvDMIxp06YZQUFBxubNm4siRK9h5rv4448/8v3b0KtXL+PWW2819uzZY2RmZhZl6PBiJJMecPvttxstWrQwvv32W+Prr7826tWrZ/Tv39+x/9ixY0aDBg2Mb7/99rJjiNncljH7faSmphpt27Y1mjZtavz888/GiRMnHFt2dranLqPEWbZsmeHv728sWrTI2L9/v/Hggw8a5cuXN06ePGkYhmHcf//9xlNPPeXov2nTJqNUqVLG9OnTjQMHDhhxcXFG6dKljT179njqEq4ZZr+LqVOnGn5+fsZ7773n9Pt/7tw5T13CNcPsd/FXzOaGJ5BMesBvv/1m9O/f3yhbtqwRFBRkDBkyxOn/hBMTEw1Jxvr16y87Bsmkdcx+H+vXrzckFbglJiZ65iJKqJdfftm4/vrrDT8/P6NNmzbGli1bHPs6d+5sxMTEOPVfsWKFUb9+fcPPz89o3Lix8cknnxRxxNcuM99FzZo1C/z9j4uLK/rAr0Fm/178GckkPMFmGIZR1LfWAQAAcG1gNjcAAABcRjIJAAAAl5FMAgAAwGUkkwAAAHAZySQAAABcRjIJAAAAl5FMAgAAwGUkkwAAAHAZySQA/InNZtOqVas8HQYAlBgkk4AXGDx4sGw2W77t559/tmT8RYsWqXz58paM5arBgwerd+/eHo0BALxRKU8HAKBo3H777Vq4cKFTW+XKlT0UzeVdvHhRpUuX9nQYAIBCojIJeAl/f39VrVrVafP19ZUkffjhh7rhhhtkt9tVu3ZtTZw4UdnZ2Y5jZ86cqaZNm6pMmTIKCwvTI488ovT0dElSQkKChgwZotTUVEfFc8KECZIKvmVcvnx5LVq0SJJ05MgR2Ww2LV++XJ07d5bdbteSJUskSa+//roaNWoku92uhg0b6tVXXzV1vTfffLNGjRqlJ554QhUrVlTVqlUdceX56aefdNNNN8lutysiIkKff/55vnGSk5N17733qnz58qpYsaJ69eqlI0eOSJIOHjyowMBALV261NF/xYoVCggI0P79+03FCwAlFckk4OU2btyoQYMGafTo0dq/f7/mzZunRYsWafLkyY4+Pj4+eumll7Rv3z69+eab+vLLL/XEE09Iktq3b69Zs2YpKChIJ06c0IkTJ/TYY4+ZiuGpp57S6NGjdeDAAUVHR2vJkiUaP368Jk+erAMHDmjKlCl69tln9eabb5oa980331SZMmX07bff6oUXXtCkSZMcCWNubq769OkjPz8/ffvtt5o7d66efPJJp+MvXryo6OholStXThs3btSmTZtUtmxZ3X777crKylLDhg01ffp0PfLII0pKStKxY8f00EMPadq0aYqIiDAVKwCUWAaAa15MTIzh6+trlClTxrHdc889hmEYRpcuXYwpU6Y49V+8eLFRrVq1y4737rvvGtddd53j88KFC43g4OB8/SQZK1eudGoLDg42Fi5caBiGYSQmJhqSjFmzZjn1qVOnjrF06VKntueee85o167dFa+xV69ejs+dO3c2Onbs6NSndevWxpNPPmkYhmGsWbPGKFWqlHH8+HHH/s8++8wp5sWLFxsNGjQwcnNzHX0yMzONgIAAY82aNY627t27G506dTK6dOlidO3a1ak/AFzreGYS8BK33HKL5syZ4/hcpkwZSdLu3bu1adMmp0pkTk6OLly4oPPnzyswMFBffPGF4uPjdfDgQaWlpSk7O9tp/9Vq1aqV488ZGRk6dOiQhg0bpuHDhzvas7OzFRwcbGrcZs2aOX2uVq2aTp06JUk6cOCAwsLCFBoa6tjfrl07p/67d+/Wzz//rHLlyjm1X7hwQYcOHXJ8XrBggerXry8fHx/t27dPNpvNVJwAUJKRTAJeokyZMqpbt26+9vT0dE2cOFF9+vTJt89ut+vIkSO688479fDDD2vy5MmqWLGivv76aw0bNkxZWVlXTCZtNpsMw3Bqu3jxYoGx/TkeSZo/f77atm3r1C/vGc/C+utEHpvNptzc3EIfn56erpYtWzqe4/yzP09e2r17tzIyMuTj46MTJ06oWrVqpuIEgJKMZBLwcjfccIN++OGHAhNNSdq+fbtyc3M1Y8YM+fhcesx6xYoVTn38/PyUk5OT79jKlSvrxIkTjs8//fSTzp8/f8V4QkJCFBoaqsOHD2vgwIFmL6fQGjVqpOTkZKfkb8uWLU59brjhBi1fvlxVqlRRUFBQgeOcOXNGgwcP1rhx43TixAkNHDhQO3bsUEBAgNtiB4DihAk4gJcbP3683nrrLU2cOFH79u3TgQMHtGzZMj3zzDOSpLp16+rixYt6+eWXdfjwYS1evFhz5851GiM8PFzp6elat26dTp8+7UgYb731Vr3yyivauXOntm3bpoceeqhQy/5MnDhR8fHxeumll/Tjjz9qz549WrhwoWbOnGnZdUdFRal+/fqKiYnR7t27tXHjRo0bN86pz8CBA1WpUiX16tVLGzduVGJiohISEjRq1CgdO3ZMkvTQQw8pLCxMzzzzjGbOnKmcnBzTE5AAoCQjmQS8XHR0tD7++GOtXbtWrVu31o033qj//Oc/qlmzpiSpefPmmjlzpqZNm6YmTZpoyZIlio+Pdxqjffv2euihh9SvXz9VrlxZL7zwgiRpxowZCgsLU6dOnTRgwAA99thjhXrG8oEHHtDrr7+uhQsXqmnTpurcubMWLVqkWrVqWXbdPj4+Wrlypf744w+1adNGDzzwgNNzo5IUGBioDRs26Prrr1efPn3UqFEjDRs2TBcuXFBQUJDeeustffrpp1q8eLFKlSqlMmXK6O2339b8+fP12WefWRYrABRnNuOvDzQBAAAAhURlEgAAAC4jmQQAAIDLSCYBAADgMpJJAAAAuIxkEgAAAC4jmQQAAIDLSCYBAADgMpJJAAAAuIxkEgAAAC4jmQQAAIDLSCYBAADgsv8HwLcTsQTcpa4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aUdhTVma4yCP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}